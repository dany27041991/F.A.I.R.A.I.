{\rtf1\ansi\ansicpg1252\cocoartf2818
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fmodern\fcharset0 Courier;
\f3\fmodern\fcharset0 Courier-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1602\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1902\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid21}
{\list\listtemplateid22\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid22}
{\list\listtemplateid23\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid23}
{\list\listtemplateid24\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid24}
{\list\listtemplateid25\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid25}
{\list\listtemplateid26\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid26}
{\list\listtemplateid27\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid27}
{\list\listtemplateid28\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid28}
{\list\listtemplateid29\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid29}
{\list\listtemplateid30\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid30}
{\list\listtemplateid31\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid3001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid31}
{\list\listtemplateid32\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid32}
{\list\listtemplateid33\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid33}
{\list\listtemplateid34\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid34}
{\list\listtemplateid35\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid35}
{\list\listtemplateid36\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid36}
{\list\listtemplateid37\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid37}
{\list\listtemplateid38\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid38}
{\list\listtemplateid39\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid3801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid39}
{\list\listtemplateid40\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid3901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid40}
{\list\listtemplateid41\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid41}
{\list\listtemplateid42\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid42}
{\list\listtemplateid43\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid43}
{\list\listtemplateid44\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid44}
{\list\listtemplateid45\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid45}
{\list\listtemplateid46\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid46}
{\list\listtemplateid47\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid47}
{\list\listtemplateid48\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid48}
{\list\listtemplateid49\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid49}
{\list\listtemplateid50\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid4901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid50}
{\list\listtemplateid51\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid5001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid51}
{\list\listtemplateid52\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid5101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid52}
{\list\listtemplateid53\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid5201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid53}
{\list\listtemplateid54\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid5301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid54}
{\list\listtemplateid55\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid5401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid55}
{\list\listtemplateid56\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid5501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid56}
{\list\listtemplateid57\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid5601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid57}
{\list\listtemplateid58\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid5701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid58}
{\list\listtemplateid59\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid5801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid59}
{\list\listtemplateid60\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid5901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid60}
{\list\listtemplateid61\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid61}
{\list\listtemplateid62\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid62}
{\list\listtemplateid63\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid63}
{\list\listtemplateid64\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid64}
{\list\listtemplateid65\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid6401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid6402\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid65}
{\list\listtemplateid66\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid66}
{\list\listtemplateid67\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid6601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid67}
{\list\listtemplateid68\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid6701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid68}
{\list\listtemplateid69\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid6801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid69}
{\list\listtemplateid70\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid6901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid70}
{\list\listtemplateid71\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid7001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid71}
{\list\listtemplateid72\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid7102\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid72}
{\list\listtemplateid73\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid7201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid73}
{\list\listtemplateid74\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid74}
{\list\listtemplateid75\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid7401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid75}
{\list\listtemplateid76\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid76}
{\list\listtemplateid77\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid77}
{\list\listtemplateid78\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid78}
{\list\listtemplateid79\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid7801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid79}
{\list\listtemplateid80\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid7901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid80}
{\list\listtemplateid81\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid81}
{\list\listtemplateid82\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid8102\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid82}
{\list\listtemplateid83\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid8202\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid83}
{\list\listtemplateid84\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid8302\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid84}
{\list\listtemplateid85\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid85}
{\list\listtemplateid86\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid8501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid86}
{\list\listtemplateid87\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid87}
{\list\listtemplateid88\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid8701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid8702\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{square\}}{\leveltext\leveltemplateid8703\'01\uc0\u9642 ;}{\levelnumbers;}\fi-360\li2160\lin2160 }{\listname ;}\listid88}
{\list\listtemplateid89\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid8801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid89}
{\list\listtemplateid90\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid8901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid90}
{\list\listtemplateid91\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid9001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid91}
{\list\listtemplateid92\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid9101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid9102\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid92}
{\list\listtemplateid93\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid9201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid93}
{\list\listtemplateid94\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid9301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid9302\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid94}
{\list\listtemplateid95\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid9401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid95}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}{\listoverride\listid22\listoverridecount0\ls22}{\listoverride\listid23\listoverridecount0\ls23}{\listoverride\listid24\listoverridecount0\ls24}{\listoverride\listid25\listoverridecount0\ls25}{\listoverride\listid26\listoverridecount0\ls26}{\listoverride\listid27\listoverridecount0\ls27}{\listoverride\listid28\listoverridecount0\ls28}{\listoverride\listid29\listoverridecount0\ls29}{\listoverride\listid30\listoverridecount0\ls30}{\listoverride\listid31\listoverridecount0\ls31}{\listoverride\listid32\listoverridecount0\ls32}{\listoverride\listid33\listoverridecount0\ls33}{\listoverride\listid34\listoverridecount0\ls34}{\listoverride\listid35\listoverridecount0\ls35}{\listoverride\listid36\listoverridecount0\ls36}{\listoverride\listid37\listoverridecount0\ls37}{\listoverride\listid38\listoverridecount0\ls38}{\listoverride\listid39\listoverridecount0\ls39}{\listoverride\listid40\listoverridecount0\ls40}{\listoverride\listid41\listoverridecount0\ls41}{\listoverride\listid42\listoverridecount0\ls42}{\listoverride\listid43\listoverridecount0\ls43}{\listoverride\listid44\listoverridecount0\ls44}{\listoverride\listid45\listoverridecount0\ls45}{\listoverride\listid46\listoverridecount0\ls46}{\listoverride\listid47\listoverridecount0\ls47}{\listoverride\listid48\listoverridecount0\ls48}{\listoverride\listid49\listoverridecount0\ls49}{\listoverride\listid50\listoverridecount0\ls50}{\listoverride\listid51\listoverridecount0\ls51}{\listoverride\listid52\listoverridecount0\ls52}{\listoverride\listid53\listoverridecount0\ls53}{\listoverride\listid54\listoverridecount0\ls54}{\listoverride\listid55\listoverridecount0\ls55}{\listoverride\listid56\listoverridecount0\ls56}{\listoverride\listid57\listoverridecount0\ls57}{\listoverride\listid58\listoverridecount0\ls58}{\listoverride\listid59\listoverridecount0\ls59}{\listoverride\listid60\listoverridecount0\ls60}{\listoverride\listid61\listoverridecount0\ls61}{\listoverride\listid62\listoverridecount0\ls62}{\listoverride\listid63\listoverridecount0\ls63}{\listoverride\listid64\listoverridecount0\ls64}{\listoverride\listid65\listoverridecount0\ls65}{\listoverride\listid66\listoverridecount0\ls66}{\listoverride\listid67\listoverridecount0\ls67}{\listoverride\listid68\listoverridecount0\ls68}{\listoverride\listid69\listoverridecount0\ls69}{\listoverride\listid70\listoverridecount0\ls70}{\listoverride\listid71\listoverridecount0\ls71}{\listoverride\listid72\listoverridecount0\ls72}{\listoverride\listid73\listoverridecount0\ls73}{\listoverride\listid74\listoverridecount0\ls74}{\listoverride\listid75\listoverridecount0\ls75}{\listoverride\listid76\listoverridecount0\ls76}{\listoverride\listid77\listoverridecount0\ls77}{\listoverride\listid78\listoverridecount0\ls78}{\listoverride\listid79\listoverridecount0\ls79}{\listoverride\listid80\listoverridecount0\ls80}{\listoverride\listid81\listoverridecount0\ls81}{\listoverride\listid82\listoverridecount0\ls82}{\listoverride\listid83\listoverridecount0\ls83}{\listoverride\listid84\listoverridecount0\ls84}{\listoverride\listid85\listoverridecount0\ls85}{\listoverride\listid86\listoverridecount0\ls86}{\listoverride\listid87\listoverridecount0\ls87}{\listoverride\listid88\listoverridecount0\ls88}{\listoverride\listid89\listoverridecount0\ls89}{\listoverride\listid90\listoverridecount0\ls90}{\listoverride\listid91\listoverridecount0\ls91}{\listoverride\listid92\listoverridecount0\ls92}{\listoverride\listid93\listoverridecount0\ls93}{\listoverride\listid94\listoverridecount0\ls94}{\listoverride\listid95\listoverridecount0\ls95}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 come potrei far questo usando wikidata, stereoset per le frasi biasate e python?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Per implementare un progetto che usa 
\f0\b Wikidata
\f1\b0 , il dataset 
\f0\b Stereoset
\f1\b0  e 
\f0\b Python
\f1\b0  per rilevare frasi con bias, puoi seguire un approccio che combina i dati strutturati di Wikidata con l'analisi del linguaggio usando modelli di NLP. Ecco i passi generali per realizzare questa idea:\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Obiettivo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'obiettivo potrebbe essere quello di rilevare bias nelle frasi usando un modello pre-addestrato di NLP, come quelli di 
\f0\b Stereoset
\f1\b0 , e arricchire l'analisi con informazioni provenienti da 
\f0\b Wikidata
\f1\b0  per migliorare la rilevazione o aggiungere contesto alle frasi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fasi principali:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Raccolta dei dati da Stereoset
\f1\b0 \
\ls1\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Integrazione con Wikidata
\f1\b0 \
\ls1\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi e rilevamento del bias con Python e modelli NLP
\f1\b0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Vediamo ciascuna fase in dettaglio.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 1. Raccolta dei dati da Stereoset\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Stereoset
\f1\b0  \'e8 un dataset costruito per valutare e quantificare il bias (sia implicito che esplicito) in modelli di linguaggio come quelli basati su trasformatori (Transformer-based). \'c8 disponibile pubblicamente e fornisce frasi annotate per vari tipi di bias come 
\f0\b genere
\f1\b0 , 
\f0\b razza
\f1\b0 , 
\f0\b religione
\f1\b0 , ecc.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls2\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Puoi scaricare il dataset 
\f0\b Stereoset
\f1\b0  dal {\field{\*\fldinst{HYPERLINK "https://github.com/moinnadeem/StereoSet"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 repository ufficiale su GitHub}}.\uc0\u8232 Una volta scaricato, puoi caricarlo in Python usando Pandas:\u8232 
\f2\fs26 python\uc0\u8232 \u8232 \u8232 \u8232 \u8232 
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f2\fs26 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import pandas as pd\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 # Caricare il dataset stereoset\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 df = pd.read_json("path_to_stereoset_data.json", lines=True)\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \uc0\u8232 \u8232 \u8232 
\f1\fs24 Il dataset contiene diverse frasi con annotazioni che indicano se una frase \'e8 biasata o meno.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 2. Integrazione con Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Wikidata
\f1\b0  \'e8 un vasto database che contiene informazioni strutturate su milioni di entit\'e0 (persone, luoghi, concetti, ecc.). Puoi sfruttare 
\f0\b Wikidata
\f1\b0  per aggiungere contesto alle frasi, come ottenere informazioni aggiuntive su persone, gruppi etnici, religioni, ecc.\
Puoi usare la libreria Python 
\f0\b wikidata.client
\f1\b0  per ottenere dati da Wikidata.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Installazione della libreria:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 bash\
\
pip install wikidata\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Esempio di utilizzo:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from wikidata.client import Client\
\
client = Client()\
# Cerca entit\'e0 su Wikidata (ad esempio, il concetto "genere" o "stereotipo")\
entity = client.get('Q48324', load=True)  # Q48324 \'e8 l'ID per "genere"\
print(entity.label)  # Stampa "Gender"\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Puoi usare questo approccio per cercare entit\'e0 specifiche come 
\f0\b gruppi etnici
\f1\b0 , 
\f0\b religioni
\f1\b0 , 
\f0\b professioni
\f1\b0 , o qualsiasi altra categoria rilevante per analizzare il bias nelle frasi. Utilizzando Wikidata, puoi ottenere ulteriori informazioni su una determinata entit\'e0, come il genere di una persona, la professione, l'affiliazione religiosa, ecc., che ti aiuteranno a contestualizzare e analizzare meglio i bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 3. Analisi e rilevamento del bias con Python\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per rilevare il bias nelle frasi, puoi usare un modello NLP pre-addestrato o costruirne uno personalizzato, basato sul dataset Stereoset. Ad esempio, puoi sfruttare modelli come 
\f0\b BERT
\f1\b0  o 
\f0\b GPT-3
\f1\b0 , o utilizzare modelli di machine learning pre-addestrati.\
Ecco un esempio di come potresti utilizzare 
\f0\b Transformers
\f1\b0  di Hugging Face per valutare il bias nelle frasi:\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Installazione delle librerie necessarie:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 bash\
\
pip install transformers\
pip install torch\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Esempio di utilizzo di un modello pre-addestrato:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from transformers import pipeline\
\
# Inizializza il pipeline per l'analisi del sentimento (bias)\
classifier = pipeline('sentiment-analysis')\
\
# Esegui l'analisi su una frase dal dataset Stereoset\
frase = "The doctor is a woman."\
risultato = classifier(frase)\
print(risultato)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Puoi applicare il modello su tutte le frasi nel dataset Stereoset e categorizzare il bias in base ai risultati del modello.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Integrazione Wikidata + Stereoset\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls4\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Controllo dei bias legati a entit\'e0 Wikidata
\f1\b0 : Utilizzando l'integrazione con Wikidata, puoi estrarre ulteriori informazioni per comprendere meglio le frasi. Ad esempio, se una frase fa riferimento a una persona, puoi cercare su Wikidata il genere o l'etnia della persona e verificare se ci sono stereotipi associati.\
\ls4\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Querying per contesto
\f1\b0 : Se nel dataset Stereoset trovi una frase come "Gli italiani sono rumorosi", potresti fare una query su Wikidata per verificare le informazioni legate agli stereotipi culturali o nazionali sugli italiani, creando un contesto pi\'f9 ampio per l'analisi del bias.\
\ls4\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Costruire metriche di bias
\f1\b0 : Usando sia le annotazioni di Stereoset sia i dati ottenuti da Wikidata, puoi costruire metriche personalizzate per quantificare il bias in base a entit\'e0 specifiche (ad es., bias di genere, bias culturale, ecc.).\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Codice di esempio\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Qui c'\'e8 un esempio di codice che unisce i dati di Wikidata e Stereoset:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
import pandas as pd\
from transformers import pipeline\
from wikidata.client import Client\
\
# Carica il dataset Stereoset\
df = pd.read_json("path_to_stereoset_data.json", lines=True)\
\
# Inizializza il modello di sentiment analysis (per il bias)\
classifier = pipeline('sentiment-analysis')\
\
# Inizializza il client Wikidata\
client = Client()\
\
# Funzione per cercare entit\'e0 su Wikidata e stampare etichette\
def get_wikidata_info(entity_name):\
    results = client.search(entity_name)\
    if results:\
        entity = client.get(results[0]['id'], load=True)\
        return entity.label, entity.description\
    return None, None\
\
# Analizza le frasi per bias e ottieni informazioni Wikidata\
for index, row in df.iterrows():\
    frase = row['sentence']\
    risultato_bias = classifier(frase)\
    \
    # Esempio di ricerca di un'entit\'e0 correlata (come "dottore", "italiani", ecc.)\
    entita_interessante = "Italians"  # Sostituire con l'entit\'e0 desiderata\
    label, descrizione = get_wikidata_info(entita_interessante)\
    \
    print(f"Frase: \{frase\}")\
    print(f"Risultato bias: \{risultato_bias\}")\
    if label:\
        print(f"Entit\'e0 Wikidata: \{label\} - \{descrizione\}")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusioni\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Utilizzando 
\f0\b Stereoset
\f1\b0  per analizzare frasi potenzialmente biasate e integrando 
\f0\b Wikidata
\f1\b0  per ottenere informazioni strutturate sulle entit\'e0 menzionate, puoi costruire un sistema che analizza il linguaggio in maniera pi\'f9 contestualizzata. Questo sistema pu\'f2 rilevare bias impliciti nelle frasi e fornire ulteriori dati per capire le implicazioni di questi bias a livello sociale o culturale.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 devi essere dettagliato devo sapere come procedere passo passo\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Certamente! Ecco una guida dettagliata passo-passo per realizzare un progetto che usa 
\f0\b Wikidata
\f1\b0 , il dataset 
\f0\b Stereoset
\f1\b0  e 
\f0\b Python
\f1\b0  per rilevare frasi biasate. Ti accompagner\'f2 attraverso ogni passaggio, dall'installazione degli strumenti necessari fino all'implementazione del codice per analizzare le frasi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 1: Prerequisiti\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Assicurati di avere installato:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Python 3.x
\f1\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un ambiente virtuale (opzionale ma consigliato, per gestire le dipendenze del progetto)\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Librerie Python necessarie: 
\f2\fs26 pandas
\f1\fs24 , 
\f2\fs26 transformers
\f1\fs24 , 
\f2\fs26 torch
\f1\fs24 , 
\f2\fs26 wikidata.client
\f1\fs24 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Installazione delle librerie necessarie\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Se non le hai ancora installate, apri il terminale o il prompt dei comandi e segui questi passaggi per installare le librerie:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
pip install pandas transformers torch wikidata\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls6\ilvl0
\f0\b\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Pandas
\f1\b0 : per caricare e manipolare il dataset Stereoset.\
\ls6\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Transformers
\f1\b0 : per usare modelli di NLP pre-addestrati come BERT per l'analisi del bias.\
\ls6\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Torch
\f1\b0 : backend per i modelli basati su Transformer.\
\ls6\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Wikidata Client
\f1\b0 : per fare query su Wikidata e ottenere informazioni sulle entit\'e0.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 2: Ottenere e caricare il dataset Stereoset\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Stereoset
\f1\b0  \'e8 un dataset di frasi con annotazioni relative al bias, come il bias di genere, razza, religione, ecc. Puoi scaricarlo dal repository ufficiale:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Link del repository GitHub: {\field{\*\fldinst{HYPERLINK "https://github.com/moinnadeem/StereoSet"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 https://github.com/moinnadeem/StereoSet}}\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Scarica il dataset\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Dopo aver scaricato il dataset in formato JSON, puoi caricarlo in Python utilizzando 
\f0\b Pandas
\f1\b0 .\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio di caricamento del dataset:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
import pandas as pd\
\
# Caricare il dataset stereoset da un file locale\
df = pd.read_json("path_to_stereoset_data.json", lines=True)\
\
# Visualizzare le prime righe del dataset per capire la struttura\
print(df.head())\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Struttura del dataset\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Il dataset conterr\'e0 frasi annotate con informazioni che descrivono se la frase \'e8 biasata o no, e di che tipo di bias si tratta. Un esempio di colonna potrebbe essere:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 sentence
\f1\b0 : la frase\
\ls8\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 gold_label
\f1\b0 : se la frase contiene bias o no\
\ls8\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 target
\f1\b0 : il gruppo o entit\'e0 su cui si basa il bias (genere, razza, ecc.)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 3: Analisi delle frasi per rilevare bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Una volta caricato il dataset, puoi utilizzare un modello di linguaggio pre-addestrato per analizzare il contenuto delle frasi. 
\f0\b Transformers
\f1\b0  offre diversi modelli come 
\f0\b BERT
\f1\b0 , che pu\'f2 essere usato per classificare o analizzare frasi.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Inizializzare il modello di NLP\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Libreria Hugging Face Transformers ti permette di usare un modello pre-addestrato per fare inferenze su testo.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from transformers import pipeline\
\
# Inizializzare il pipeline per il sentiment analysis (bias detection)\
classifier = pipeline('sentiment-analysis')\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Con questo pipeline, puoi classificare una frase per determinare se contiene sentimenti positivi o negativi (in questo caso, potrebbe indicare se una frase \'e8 biasata o meno).\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Analisi del bias su una frase\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Esegui il modello su una singola frase dal dataset Stereoset:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Prendi una frase dal dataset\
frase = df.loc[0, 'sentence']  # Frase dalla prima riga del dataset\
\
# Usa il modello per rilevare bias (usando sentiment analysis come proxy)\
risultato_bias = classifier(frase)\
\
# Visualizza il risultato\
print(f"Frase: \{frase\}")\
print(f"Risultato bias: \{risultato_bias\}")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 4: Integrare Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Wikidata
\f1\b0  \'e8 un database che contiene informazioni su entit\'e0 come persone, gruppi etnici, nazioni, professioni, ecc. Puoi sfruttare queste informazioni per arricchire l'analisi delle frasi del dataset.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 4.1: Configurazione del client Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Per interrogare Wikidata, puoi usare la libreria 
\f0\b wikidata.client
\f1\b0 .\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
\
# Inizializza il client per accedere a Wikidata\
client = Client()\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 4.2: Esempio di query su Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Se una frase fa riferimento a una professione, un gruppo etnico, o un'entit\'e0 specifica, puoi cercare queste entit\'e0 su Wikidata e ottenere ulteriori informazioni.\
Esempio: Cerca il concetto di "italiani" su Wikidata.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Cerca l'entit\'e0 "Italians" su Wikidata\
entity = client.search("Italians")\
\
# Seleziona la prima entit\'e0 trovata e carica i dettagli\
if entity:\
    italians_entity = client.get(entity[0]['id'], load=True)\
    print(italians_entity.label)\
    print(italians_entity.description)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo modo, puoi ottenere informazioni su gruppi o entit\'e0 rilevanti menzionati nelle frasi del dataset.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 5: Combinare Stereoset con Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 A questo punto, puoi combinare l'analisi del bias con le informazioni ottenute da Wikidata. Ad esempio, se una frase fa riferimento agli 
\f0\b italiani
\f1\b0 , puoi usare Wikidata per verificare se ci sono stereotipi legati a questa etnia.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 5.1: Funzione per analizzare una frase e ottenere contesto\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ecco un esempio di funzione Python che combina l'analisi del bias con le informazioni estratte da Wikidata:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
def analizza_frase(frase, entita_da_cercare):\
    # Usa il modello NLP per rilevare bias\
    risultato_bias = classifier(frase)\
    \
    # Cerca informazioni aggiuntive sull'entit\'e0 specificata su Wikidata\
    results = client.search(entita_da_cercare)\
    if results:\
        entita = client.get(results[0]['id'], load=True)\
        label = entita.label\
        descrizione = entita.description\
    else:\
        label, descrizione = None, None\
    \
    # Visualizza i risultati\
    print(f"Frase: \{frase\}")\
    print(f"Risultato bias: \{risultato_bias\}")\
    if label:\
        print(f"Entit\'e0 Wikidata: \{label\} - \{descrizione\}")\
    else:\
        print("Nessuna entit\'e0 trovata su Wikidata.")\
\
# Esegui la funzione su una frase di esempio\
analizza_frase("The Italians are always loud.", "Italians")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 6: Estendere l'analisi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 A questo punto, puoi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Applicare la funzione a tutte le frasi del dataset Stereoset per rilevare bias e collegarli a Wikidata.\
\ls9\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Creare un report sulle frasi biasate e fornire contesto aggiuntivo grazie ai dati ottenuti da Wikidata.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Ecco un esempio di come applicare l'analisi a tutte le frasi del dataset:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Applica l'analisi a tutte le frasi nel dataset\
for index, row in df.iterrows():\
    frase = row['sentence']\
    target = row['target']  # Il gruppo target della frase (es. Italians, Muslims, ecc.)\
    \
    # Esegui l'analisi sulla frase\
    analizza_frase(frase, target)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 7: Creare un report finale\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Infine, puoi salvare i risultati dell'analisi in un file CSV o generare un report automatico che mostri tutte le frasi biasate con il contesto aggiuntivo ottenuto da Wikidata.\
Ecco un esempio di come salvare i risultati in un CSV:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Lista per memorizzare i risultati\
risultati = []\
\
# Itera su tutte le frasi e raccogli i risultati\
for index, row in df.iterrows():\
    frase = row['sentence']\
    target = row['target']\
    \
    # Ottieni risultato bias e entit\'e0 Wikidata\
    risultato_bias = classifier(frase)\
    label, descrizione = get_wikidata_info(target)\
    \
    risultati.append(\{\
        'frase': frase,\
        'risultato_bias': risultato_bias,\
        'entita_wikidata': label,\
        'descrizione_wikidata': descrizione\
    \})\
\
# Converti in DataFrame e salva in CSV\
df_risultati = pd.DataFrame(risultati)\
df_risultati.to_csv('risultati_bias.csv', index=False)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusioni\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Seguendo questi passaggi, hai integrato 
\f0\b Wikidata
\f1\b0  e il dataset 
\f0\b Stereoset
\f1\b0  per analizzare frasi biasate usando 
\f0\b Python
\f1\b0  e modelli NLP. Questo progetto ti permette di rilevare frasi biasate e arricchirle con informazioni contestuali da Wikidata, fornendo una visione pi\'f9 profonda sugli stereotipi presenti nel linguaggio naturale.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 A questo punto, puoi combinare l'analisi del bias con le informazioni ottenute da Wikidata. Ad esempio, se una frase fa riferimento agli italiani, puoi usare Wikidata per verificare se ci sono stereotipi legati a questa etnia. questo non \'e8 chiaro\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Capisco, e ora ti spiego meglio come combinare l'analisi del bias con le informazioni ottenute da 
\f0\b Wikidata
\f1\b0  e come verificare l'eventuale presenza di stereotipi legati a gruppi specifici, come gli italiani.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Obiettivo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'obiettivo \'e8 prendere una frase dal dataset 
\f0\b Stereoset
\f1\b0  che potrebbe contenere un bias (es. 
\f0\b "Gli italiani sono rumorosi"
\f1\b0 ), quindi usare 
\f0\b Wikidata
\f1\b0  per ottenere informazioni sul gruppo menzionato nella frase (in questo caso, gli italiani) e determinare se ci sono correlazioni con stereotipi o contesti rilevanti.\
Wikidata non contiene direttamente informazioni sugli 
\f0\b stereotipi
\f1\b0  in senso stretto, ma ti fornisce descrizioni strutturate di entit\'e0 come nazionalit\'e0, gruppi etnici, professioni, e altro, che puoi usare per arricchire la tua analisi. Il processo consiste nell'usare queste informazioni per capire il contesto della frase e valutare se ci sono stereotipi in base alle descrizioni ottenute.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Esempio Dettagliato: Frase Biasata sugli Italiani\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Supponiamo di avere la frase biasata 
\f0\b "Gli italiani sono rumorosi"
\f1\b0  dal dataset 
\f0\b Stereoset
\f1\b0 .\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi del bias con un modello NLP
\f1\b0 : La frase viene analizzata da un modello NLP per verificare se contiene bias.\
\ls10\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Query su Wikidata
\f1\b0 : Cerchiamo informazioni su 
\f0\b "italiani"
\f1\b0  in 
\f0\b Wikidata
\f1\b0  per ottenere dettagli su questa entit\'e0, come descrizioni o fatti storici.\
\ls10\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Controllo degli stereotipi
\f1\b0 : Dopo aver ottenuto informazioni su "italiani", le possiamo comparare con la frase per vedere se riflettono un potenziale stereotipo.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Passaggi dettagliati per combinare l'analisi del bias con Wikidata\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 Passo 1: Analisi del bias con un modello NLP\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Per analizzare se una frase contiene bias, puoi utilizzare modelli NLP. L'idea \'e8 usare un modello di sentiment analysis come proxy per identificare se il linguaggio nella frase \'e8 polarizzato o stereotipato. Ad esempio, puoi utilizzare un modello come 
\f0\b BERT
\f1\b0  per analizzare frasi.\
Ecco il codice per farlo:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from transformers import pipeline\
\
# Inizializza il modello di sentiment analysis\
classifier = pipeline('sentiment-analysis')\
\
# Esempio di frase da Stereoset\
frase = "Gli italiani sono rumorosi."\
\
# Usa il modello per rilevare bias (proxy per il sentiment analysis)\
risultato_bias = classifier(frase)\
\
# Visualizza il risultato\
print(f"Frase: \{frase\}")\
print(f"Risultato bias: \{risultato_bias\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo modello pu\'f2 restituire un risultato del tipo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Positive
\f1\b0  o 
\f0\b Negative
\f1\b0 , indicando se la frase potrebbe contenere bias (positivo o negativo).\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Passo 2: Query su Wikidata per ottenere informazioni contestuali\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora cerchiamo informazioni sugli 
\f0\b italiani
\f1\b0  su 
\f0\b Wikidata
\f1\b0 . Puoi farlo utilizzando il client 
\f0\b Wikidata
\f1\b0  in Python, cercando l'entit\'e0 
\f0\b Italians
\f1\b0  (che su Wikidata \'e8 identificata come l'entit\'e0 
\f0\b Q50001
\f1\b0 ).\
Ecco un esempio di query su Wikidata:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
\
# Inizializza il client di Wikidata\
client = Client()\
\
# Cerca l'entit\'e0 "Italians" su Wikidata\
entity = client.get('Q50001', load=True)  # ID per Italians su Wikidata\
\
# Stampa le informazioni ottenute da Wikidata\
print(f"Etichetta: \{entity.label\}")  # Italiani\
print(f"Descrizione: \{entity.description\}")  # Popolazione nativa dell'Italia\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 La descrizione potrebbe restituire:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Popolazione nativa dell'Italia
\f1\b0 , ma potrebbe anche includere collegamenti a ulteriori dati rilevanti per capire meglio la natura degli italiani.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Se la frase facesse riferimento a un'altra entit\'e0, come un gruppo etnico o una professione, potresti fare una query simile cercando la relativa entit\'e0.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 3: Valutare la presenza di stereotipi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora che hai l'analisi del modello NLP e le informazioni da 
\f0\b Wikidata
\f1\b0 , puoi fare un confronto. Ad esempio, la frase 
\f0\b "Gli italiani sono rumorosi"
\f1\b0  \'e8 potenzialmente stereotipata perch\'e9 etichetta un'intera nazionalit\'e0 con un comportamento specifico (rumorosit\'e0).\
Le informazioni ottenute da 
\f0\b Wikidata
\f1\b0  (es. "Popolazione nativa dell'Italia") non supportano questo stereotipo; piuttosto, descrivono semplicemente chi sono gli italiani. Quindi puoi concludere che la frase contiene un potenziale bias, basato su uno stereotipo infondato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Funzione Completa: Analisi del Bias e Query su Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Qui mettiamo insieme tutto in una funzione che:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analizza una frase per bias usando un modello NLP.\
\ls13\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cerca l'entit\'e0 associata (es. italiani) su Wikidata.\
\ls13\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fornisce il contesto per valutare se la frase contiene uno stereotipo.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 python\
\
from transformers import pipeline\
from wikidata.client import Client\
\
# Inizializza il modello NLP e il client Wikidata\
classifier = pipeline('sentiment-analysis')\
client = Client()\
\
def analizza_frase_con_wikidata(frase, entita_id_wikidata):\
    # 1. Analizzare la frase per bias\
    risultato_bias = classifier(frase)\
    \
    # 2. Cercare informazioni sull'entit\'e0 in Wikidata\
    entita = client.get(entita_id_wikidata, load=True)\
    label = entita.label\
    descrizione = entita.description\
    \
    # 3. Visualizzare i risultati\
    print(f"Frase: \{frase\}")\
    print(f"Risultato Bias (sentiment): \{risultato_bias\}")\
    print(f"Entit\'e0 Wikidata: \{label\}")\
    print(f"Descrizione Wikidata: \{descrizione\}")\
    \
    # Qui puoi valutare se la frase rappresenta uno stereotipo o meno\
    if "stereotipo" in frase.lower():\
        print("Attenzione: questa frase potrebbe contenere uno stereotipo.")\
    else:\
        print("La frase sembra neutrale rispetto all'entit\'e0.")\
\
# Esempio di utilizzo della funzione\
frase_da_analizzare = "Gli italiani sono rumorosi."\
analizza_frase_con_wikidata(frase_da_analizzare, 'Q50001')  # Q50001 \'e8 l'ID per "Italians"\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Output atteso\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Eseguendo questo codice per la frase 
\f0\b "Gli italiani sono rumorosi"
\f1\b0 , otterrai un output simile:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
Frase: Gli italiani sono rumorosi.\
Risultato Bias (sentiment): [\{'label': 'NEGATIVE', 'score': 0.99\}]\
Entit\'e0 Wikidata: Italians\
Descrizione Wikidata: Popolazione nativa dell'Italia\
Attenzione: questa frase potrebbe contenere uno stereotipo.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Espandere il Progetto\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Puoi espandere questo approccio per analizzare automaticamente molte frasi dal dataset 
\f0\b Stereoset
\f1\b0  e vedere quali contengono bias. Per ogni frase, puoi collegarla con le entit\'e0 rilevanti di 
\f0\b Wikidata
\f1\b0  (come nazionalit\'e0, gruppi etnici, professioni, ecc.) per fornire contesto aggiuntivo e rafforzare l'analisi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi del bias
\f1\b0 : Usa un modello NLP per analizzare il bias in una frase.\
\ls14\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Contesto Wikidata
\f1\b0 : Usa Wikidata per ottenere informazioni strutturate sull'entit\'e0 menzionata nella frase (ad esempio, "italiani").\
\ls14\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Valutazione
\f1\b0 : Confronta i risultati per vedere se la frase fa riferimento a stereotipi. Anche se Wikidata non fornisce direttamente informazioni sugli stereotipi, ti d\'e0 il contesto per capire se il bias \'e8 infondato o meno.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 Il processo consiste nell'usare queste informazioni per capire il contesto della frase e valutare se ci sono stereotipi in base alle descrizioni ottenute. spiega meglio\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Certamente, ti spiego meglio come usare 
\f0\b Wikidata
\f1\b0  per comprendere il contesto di una frase e valutare se essa contiene stereotipi, attraverso il confronto con le descrizioni ottenute.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Obiettivo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Quando analizzi una frase dal dataset 
\f0\b Stereoset
\f1\b0  (o qualsiasi altro testo), l'obiettivo \'e8 identificare se la frase contiene 
\f0\b stereotipi
\f1\b0  su un gruppo sociale, una professione o un'etnia. Per fare ci\'f2, possiamo combinare due fonti di informazione:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls15\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Modelli NLP (Natural Language Processing)
\f1\b0 , come quelli di Hugging Face, per rilevare potenziali bias o stereotipi attraverso l'analisi della frase stessa.\
\ls15\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Wikidata
\f1\b0 , un database che fornisce informazioni strutturate su gruppi, etnie, nazionalit\'e0, professioni, ecc., per arricchire la nostra comprensione del contesto della frase e vedere se gli stereotipi sono confermati o smentiti da fatti reali.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Cosa significa "usare Wikidata per capire il contesto della frase"?\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Wikidata
\f1\b0  contiene descrizioni neutrali e verificabili sulle entit\'e0 (persone, gruppi, etnie, professioni, ecc.). Queste descrizioni possono fornirci un quadro oggettivo su cosa \'e8 un gruppo etnico o una nazione, aiutandoci a verificare se una frase stereotipata si basa su informazioni realistiche o \'e8 frutto di pregiudizi.\
Ad esempio, se la frase \'e8 
\f0\b "Gli italiani sono rumorosi"
\f1\b0 , possiamo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analizzare la frase con un modello NLP
\f1\b0  per vedere se essa ha un carattere negativo, positivo o neutrale.\
\ls16\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cercare informazioni su "italiani" su Wikidata
\f1\b0 , che ci dar\'e0 una descrizione neutrale del gruppo, come "Popolazione nativa dell'Italia" o informazioni storiche su chi sono gli italiani. Questa descrizione oggettiva \'e8 utile per confrontarla con la frase.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Come possiamo usare queste informazioni per capire gli stereotipi?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Dopo aver ottenuto la descrizione di una certa entit\'e0 da 
\f0\b Wikidata
\f1\b0 , possiamo confrontare questa descrizione con la frase analizzata. Se la frase implica uno 
\f0\b stereotipo
\f1\b0 , spesso attribuisce un tratto generico e negativo a un gruppo intero (ad esempio, "rumorosi" nel caso degli italiani).\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio pratico:
\f1\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase: 
\f0\b "Gli italiani sono rumorosi"
\f1\b0 .\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls17\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi con il modello NLP: Il modello pu\'f2 classificare la frase come 
\f0\b negativa
\f1\b0  o 
\f0\b biasata
\f1\b0 , poich\'e9 associa un comportamento negativo (rumorosit\'e0) a un'intera nazione.\
\ls17\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Dati da Wikidata: Quando cerchiamo 
\f0\b "Italians"
\f1\b0  su Wikidata, otteniamo una descrizione come "Popolazione nativa dell'Italia" o "Un gruppo culturale e linguistico con una lunga storia". Questa descrizione non contiene informazioni su presunti comportamenti come "essere rumorosi".\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 \strokec2 Valutazione dello stereotipo:
\f1\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 A questo punto, possiamo dire che la frase 
\f0\b contiene uno stereotipo
\f1\b0 : attribuisce un tratto (rumorosit\'e0) a un gruppo intero, senza supporto dai fatti reali forniti da Wikidata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Processo dettagliato\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls19\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi del bias nella frase
\f1\b0 : Usiamo un modello NLP per analizzare la frase e determinare se ha un carattere 
\f0\b negativo
\f1\b0  o 
\f0\b stereotipato
\f1\b0 .\uc0\u8232 Esempio:\u8232 
\f2\fs26 python\uc0\u8232 \u8232 \u8232 \u8232 \u8232 
\f1\fs24 \
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 from transformers import pipeline\
\
classifier = pipeline('sentiment-analysis')\
frase = "Gli italiani sono rumorosi."\
risultato_bias = classifier(frase)\
print(risultato_bias)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo codice analizzer\'e0 la frase e potrebbe restituire un risultato come:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
\pard\pardeftab720\partightenfactor0
\cf0 [\{'label': 'NEGATIVE', 'score': 0.98\}]\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 Il modello classifica la frase come 
\f0\b negativa
\f1\b0  con un alto livello di confidenza (98%).\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Ricerca del contesto su Wikidata
\f1\b0 : Ora cerchiamo l'entit\'e0 correlata (in questo caso, 
\f0\b "italiani"
\f1\b0 ) su Wikidata. Questo ci fornir\'e0 una descrizione neutrale e accurata del gruppo menzionato nella frase.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 python\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 from wikidata.client import Client\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 client = Client()\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 italians = client.get('Q50001', load=True)  # ID di Italians su Wikidata\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 print(italians.label)  # Stampa "Italians"\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 print(italians.description)  # Stampa "Popolazione nativa dell'Italia"\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \uc0\u8232 \u8232 \u8232 
\f1\fs24 La descrizione ci dice chi sono gli italiani in modo oggettivo, senza fare riferimento a stereotipi come "rumorosit\'e0". Questa descrizione rappresenta il 
\f0\b contesto reale
\f1\b0  del gruppo.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls20\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confronto tra la frase e le informazioni da Wikidata
\f1\b0 : Confrontiamo ora la frase con le informazioni ottenute da Wikidata.\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls20\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase: 
\f0\b "Gli italiani sono rumorosi"
\f1\b0  implica che tutti gli italiani hanno questa caratteristica.\
\ls20\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Informazioni da Wikidata: 
\f0\b "Popolazione nativa dell'Italia"
\f1\b0  \'e8 una descrizione oggettiva, che non menziona tratti comportamentali generalizzati o stereotipati.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls20\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Conclusione
\f1\b0 : La frase contiene uno stereotipo, poich\'e9 attribuisce a un intero gruppo una caratteristica (rumorosit\'e0) che non \'e8 supportata dalla descrizione oggettiva ottenuta da Wikidata. Questo \'e8 un chiaro esempio di stereotipo infondato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Perch\'e9 usare Wikidata?\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Wikidata
\f1\b0  \'e8 utile in questo contesto perch\'e9 offre dati neutri e verificabili su entit\'e0 come gruppi etnici, nazionalit\'e0, e professioni. In un processo di analisi degli stereotipi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Wikidata
\f1\b0  ci fornisce il 
\f0\b contesto reale
\f1\b0  su chi o cosa \'e8 menzionato nella frase.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ci permette di confrontare la 
\f0\b realt\'e0
\f1\b0  con la 
\f0\b percezione
\f1\b0  stereotipata contenuta nella frase.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Codice completo: Analizzare bias e stereotipi usando NLP e Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Mettiamo insieme tutto in un unico esempio di codice.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from transformers import pipeline\
from wikidata.client import Client\
\
# Inizializza il modello NLP e il client Wikidata\
classifier = pipeline('sentiment-analysis')\
client = Client()\
\
def analizza_frase(frase, entita_id_wikidata):\
    # 1. Analizzare la frase per bias\
    risultato_bias = classifier(frase)\
    \
    # 2. Cercare informazioni sull'entit\'e0 in Wikidata\
    entita = client.get(entita_id_wikidata, load=True)\
    label = entita.label\
    descrizione = entita.description\
    \
    # 3. Visualizzare i risultati\
    print(f"Frase: \{frase\}")\
    print(f"Risultato Bias (sentiment): \{risultato_bias\}")\
    print(f"Entit\'e0 Wikidata: \{label\}")\
    print(f"Descrizione Wikidata: \{descrizione\}")\
    \
    # 4. Valutare se la frase \'e8 stereotipata confrontando con Wikidata\
    if risultato_bias[0]['label'] == 'NEGATIVE':\
        print(f"La frase contiene un potenziale stereotipo.")\
    else:\
        print(f"La frase sembra neutrale o non stereotipata.")\
\
# Esempio di utilizzo della funzione\
frase_da_analizzare = "Gli italiani sono rumorosi."\
analizza_frase(frase_da_analizzare, 'Q50001')  # Q50001 \'e8 l'ID per "Italians"\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\fs24 \cf0 Wikidata
\f1\b0  fornisce descrizioni oggettive che possono essere usate per confrontare le affermazioni fatte nelle frasi con i dati reali. In questo modo, possiamo capire se una frase stereotipata ha una base reale o se si basa su pregiudizi. Questo approccio consente di rilevare stereotipi in modo sistematico e supportato dai fatti.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 e se volessi sfruttare anche le ontologie aiuterebbe ulteriormente?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 S\'ec, assolutamente! 
\f0\b Sfruttare le ontologie
\f1\b0  nel contesto dell'analisi di bias e stereotipi pu\'f2 aiutarti ulteriormente a fornire una struttura semantica pi\'f9 dettagliata e significativa per comprendere il contesto delle frasi. Le ontologie, come quelle usate nel 
\f0\b Web Semantico
\f1\b0  (ad esempio, 
\f0\b OWL
\f1\b0 , 
\f0\b RDFS
\f1\b0 , o 
\f0\b SKOS
\f1\b0 ), ti permettono di rappresentare le relazioni tra concetti e fornire una base solida per ragionamenti pi\'f9 approfonditi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Perch\'e9 usare le ontologie nell'analisi di bias?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'uso delle ontologie ti permette di arricchire l'analisi aggiungendo una rete di conoscenze strutturate che descrive:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls22\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazioni tra entit\'e0
\f1\b0  (ad esempio, "Italians" come sottoclasse di "Europeans", o "Doctor" come professione nel campo della medicina).\
\ls22\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Propriet\'e0
\f1\b0  che caratterizzano entit\'e0 o concetti (ad esempio, "genere", "etnia", "nazionalit\'e0").\
\ls22\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Concetti astratti
\f1\b0  che possono essere collegati a stereotipi o bias (ad esempio, relazioni tra nazionalit\'e0 e tratti comportamentali).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Le ontologie consentono di creare un sistema semantico che rende esplicite le relazioni concettuali e le inferenze che potrebbero non essere immediatamente evidenti.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Vantaggi dell'uso delle ontologie nell'analisi di bias:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls23\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchimento del contesto
\f1\b0 : Le ontologie ti permettono di capire meglio il contesto delle entit\'e0 e delle relazioni tra di esse. Ad esempio, puoi sapere non solo che "Italians" \'e8 un'entit\'e0, ma che appartiene alla classe "Europeans", e potresti rilevare stereotipi non solo sugli italiani, ma sugli europei in generale.\
\ls23\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenze logiche
\f1\b0 : Con le ontologie, puoi fare 
\f0\b inferenze
\f1\b0  pi\'f9 complesse, come identificare stereotipi che non sono esplicitamente menzionati. Ad esempio, se una frase riguarda una professione come "dottore", puoi inferire che potrebbe esistere un bias di genere, perch\'e9 storicamente "doctor" potrebbe essere collegato alla predominanza maschile nel campo della medicina.\
\ls23\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazioni tra concetti
\f1\b0 : Puoi modellare relazioni complesse tra concetti (ad esempio, "genere", "razza", "classe sociale") che possono influenzare il modo in cui i bias vengono espressi. Le ontologie possono aiutare a collegare questi concetti e a fornire una visione pi\'f9 strutturata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio di come le ontologie aiuterebbero\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Prendiamo ancora la frase 
\f0\b "Gli italiani sono rumorosi"
\f1\b0 . Se usiamo solo un'analisi superficiale, possiamo identificarla come stereotipata grazie a modelli NLP e dati di Wikidata. Tuttavia, con un'
\f0\b ontologia
\f1\b0 , possiamo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls24\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esplicitare relazioni
\f1\b0 : Capire che "Italians" \'e8 una sottoclasse di "Europeans" e che "Europeans" ha una relazione con concetti come "culture" e "language". Questo ci permette di comprendere il contesto culturale.\
\ls24\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Collegare concetti
\f1\b0 : Collegare concetti come 
\f0\b nazionalit\'e0
\f1\b0  e 
\f0\b comportamenti stereotipati
\f1\b0  all'interno di un'ontologia per vedere se ci sono correlazioni pi\'f9 ampie tra nazionalit\'e0 e stereotipi comuni.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Ad esempio, potresti modellare un'ontologia che descrive relazioni come:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls25\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 "Italians" 
\f0\b has stereotype
\f1\b0  "rumorosit\'e0"\
\ls25\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 "Italians" 
\f0\b is subclass of
\f1\b0  "Europeans"\
\ls25\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 "Europeans" 
\f0\b has stereotype
\f1\b0  "cosmopolitan"\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questo arricchisce l'analisi perch\'e9 stai trattando il bias non solo a livello della singola frase, ma anche a livello delle relazioni tra concetti pi\'f9 ampi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Come usare le ontologie con Python\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Esistono librerie Python che ti consentono di lavorare con ontologie, come 
\f0\b rdflib
\f1\b0  o 
\f0\b Owlready2
\f1\b0 . Puoi usarle per interrogare e ragionare su un'ontologia definita in OWL o RDFS.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 1: Installare una libreria per le ontologie\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Installa 
\f0\b Owlready2
\f1\b0 , una libreria Python che permette di lavorare con ontologie OWL.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
pip install owlready2\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 2: Caricare un'ontologia e navigare le relazioni\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Supponiamo di voler usare un'ontologia che definisce relazioni tra nazionalit\'e0, stereotipi, e comportamenti. Puoi creare un'ontologia o usarne una esistente.\
Ecco un esempio di come caricare e interrogare un'ontologia con 
\f0\b Owlready2
\f1\b0 :\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from owlready2 import *\
\
# Carica l'ontologia\
onto = get_ontology("path_to_your_ontology.owl").load()\
\
# Cerca una classe come "Italians"\
italians = onto.search_one(label="Italians")\
\
# Stampa tutte le classi e relazioni associate\
print(f"Italians class: \{italians\}")\
for rel in italians.is_a:\
    print(f"Relazione di Italians: \{rel\}")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio di Ontologia OWL per gli stereotipi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Immagina un'ontologia che descriva le seguenti relazioni:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls26\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 La classe 
\f0\b Italians
\f1\b0  ha lo stereotipo 
\f0\b Rumorosit\'e0
\f1\b0 .\
\ls26\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 La classe 
\f0\b Italians
\f1\b0  \'e8 una sottoclasse di 
\f0\b Europeans
\f1\b0 .\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 In OWL, questa ontologia potrebbe essere rappresentata come:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 xml\
\
<owl:Class rdf:about="#Italians">\
  <rdfs:subClassOf rdf:resource="#Europeans"/>\
  <hasStereotype rdf:resource="#Rumorosit\'e0"/>\
</owl:Class>\
\
<owl:Class rdf:about="#Europeans">\
  <rdfs:label>Europeans</rdfs:label>\
</owl:Class>\
\
<owl:ObjectProperty rdf:about="#hasStereotype">\
  <rdfs:domain rdf:resource="#Italians"/>\
  <rdfs:range rdf:resource="#Stereotype"/>\
</owl:ObjectProperty>\
\
<owl:Class rdf:about="#Stereotype">\
  <rdfs:label>Stereotype</rdfs:label>\
</owl:Class>\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Con questa struttura, puoi fare query come:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls27\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Quali stereotipi sono collegati alla classe 
\f0\b Italians
\f1\b0 ?\
\ls27\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Quali entit\'e0 sono sottoclassi di 
\f0\b Europeans
\f1\b0  e hanno stereotipi legati a comportamenti?\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Passo 3: Fare inferenze con l'ontologia\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Owlready2 ti permette anche di fare inferenze e ragionamenti automatici. Per esempio, se una frase contiene un possibile stereotipo su una nazionalit\'e0, puoi usare l'ontologia per verificare se lo stereotipo \'e8 gi\'e0 presente.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Cerca stereotipi associati agli Italiani\
for stereotype in italians.hasStereotype:\
    print(f"Possibile stereotipo: \{stereotype.label\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Se la tua ontologia contiene una relazione come 
\f0\b "Italians" hasStereotype "Rumorosit\'e0"
\f1\b0 , questa verr\'e0 rilevata automaticamente.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Vantaggi Pratici\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Usare le ontologie ti offre questi vantaggi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls28\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza automatica
\f1\b0 : Puoi automatizzare il processo di identificazione dei bias. Se un concetto nella frase \'e8 collegato a uno stereotipo nell'ontologia, puoi identificare il bias in modo strutturato.\
\ls28\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Espansione delle relazioni
\f1\b0 : Se un concetto non \'e8 esplicitamente menzionato ma \'e8 collegato ad altri concetti attraverso l'ontologia (es. "Europeans" e "Italians"), puoi ampliare la tua analisi.\
\ls28\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Validazione del contesto
\f1\b0 : L'ontologia ti aiuta a validare il contesto della frase. Ad esempio, se un comportamento (es. "rumorosit\'e0") non \'e8 collegato all'entit\'e0 in questione (es. "Italians") nell'ontologia, \'e8 pi\'f9 probabile che sia un bias stereotipato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Come combinare il tutto: NLP + Wikidata + Ontologie\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls29\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 NLP
\f1\b0 : Analizzi la frase con un modello NLP per determinare se c'\'e8 un bias evidente.\
\ls29\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Wikidata
\f1\b0 : Usando Wikidata, ottieni contesto oggettivo sull'entit\'e0 (es. una nazionalit\'e0 o professione).\
\ls29\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ontologie
\f1\b0 : Verifichi con l'ontologia se esistono stereotipi legati al gruppo o entit\'e0 menzionata, e fai inferenze sulle relazioni tra concetti.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Usare le 
\f0\b ontologie
\f1\b0  insieme a modelli NLP e dati da 
\f0\b Wikidata
\f1\b0  ti permette di fare un'analisi del bias pi\'f9 completa e sofisticata. Le ontologie ti forniscono un modo strutturato per rappresentare le relazioni tra concetti e fare inferenze sui bias che potrebbero non essere immediatamente evidenti nel testo. Questo approccio potenzia la tua capacit\'e0 di rilevare e comprendere i bias e gli stereotipi presenti nel linguaggio.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
1/2\
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 come? Utilizza tecniche di clustering o apprendimento automatico per identificare automaticamente i tipi di bias basati sulle descrizioni di Wikidata.\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Per utilizzare tecniche di 
\f0\b clustering
\f1\b0  o 
\f0\b apprendimento automatico
\f1\b0  per identificare automaticamente i tipi di bias basati sulle descrizioni di 
\f0\b Wikidata
\f1\b0 , possiamo applicare un approccio che combina dati semantici (come le descrizioni di entit\'e0 provenienti da Wikidata) con tecniche di NLP e machine learning per estrarre informazioni e categorizzare i bias in modo pi\'f9 strutturato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Obiettivo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'idea \'e8 quella di usare le descrizioni delle entit\'e0 fornite da 
\f0\b Wikidata
\f1\b0  (ad esempio, descrizioni di nazionalit\'e0, gruppi etnici, professioni) come feature per un modello di apprendimento automatico che 
\f0\b raggruppi frasi simili
\f1\b0  o 
\f0\b identifichi automaticamente il tipo di bias
\f1\b0  (es. di genere, etnico, sociale, ecc.) presente nelle frasi.\
Ecco i passaggi principali per raggiungere questo obiettivo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls30\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estrazione delle descrizioni delle entit\'e0 da Wikidata
\f1\b0 .\
\ls30\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rappresentazione delle frasi e delle descrizioni
\f1\b0  usando tecniche di 
\f0\b embedding
\f1\b0 .\
\ls30\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Utilizzo di tecniche di clustering
\f1\b0  per raggruppare frasi simili in base al tipo di bias.\
\ls30\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Addestramento di un modello di apprendimento automatico
\f1\b0  per identificare automaticamente i bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Passo 1: Estrazione delle descrizioni delle entit\'e0 da Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per prima cosa, dobbiamo estrarre le descrizioni delle entit\'e0 da 
\f0\b Wikidata
\f1\b0  per le entit\'e0 rilevanti, come gruppi etnici, nazionalit\'e0, o professioni menzionate nelle frasi biasate. Questo passaggio pu\'f2 essere automatizzato utilizzando il client di 
\f0\b Wikidata
\f1\b0  in Python.\
Ecco come farlo:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
import pandas as pd\
\
# Inizializza il client Wikidata\
client = Client()\
\
# Lista di entit\'e0 da cercare (nazionalit\'e0, professioni, ecc.)\
entita_da_cercare = ['Italians', 'Doctors', 'Muslims', 'Women']\
\
# Dizionario per salvare le descrizioni estratte\
descrizioni_entita = \{\}\
\
# Estrarre le descrizioni da Wikidata\
for entita in entita_da_cercare:\
    risultato = client.search(entita)\
    if risultato:\
        entita_wikidata = client.get(risultato[0]['id'], load=True)\
        descrizioni_entita[entita] = entita_wikidata.description\
\
# Visualizzare le descrizioni\
print(descrizioni_entita)\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs24 \cf0 \strokec2 Output atteso
\f1\b0 :\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
\{'Italians': 'Popolazione nativa dell\\'Italia',\
 'Doctors': 'Professionista medico qualificato',\
 'Muslims': 'Seguace dell\\'Islam',\
 'Women': 'Adulto di sesso femminile'\}\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Queste descrizioni costituiranno le nostre 
\f0\b feature semantiche
\f1\b0  che useremo per classificare e identificare bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Passo 2: Rappresentazione delle frasi e delle descrizioni usando tecniche di embedding\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Una volta estratte le descrizioni, dobbiamo rappresentare sia le frasi del dataset 
\f0\b Stereoset
\f1\b0  sia le descrizioni delle entit\'e0 di Wikidata in uno spazio vettoriale che permetta il confronto. Useremo tecniche di 
\f0\b embedding
\f1\b0 , come 
\f0\b BERT
\f1\b0  o 
\f0\b Sentence-BERT
\f1\b0 , per ottenere una rappresentazione numerica delle frasi e delle descrizioni.\
Ecco un esempio di come fare embedding delle frasi e delle descrizioni:\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Installare le librerie necessarie\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 bash\
\
pip install sentence-transformers\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Codice per rappresentare frasi e descrizioni come embedding\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from sentence_transformers import SentenceTransformer\
\
# Inizializzare il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Frasi biasate dal dataset Stereoset\
frasi_biasate = ["Gli italiani sono rumorosi.", "Le donne non sono brave in matematica."]\
\
# Rappresentare frasi e descrizioni con embedding\
embedding_frasi = modello_embedding.encode(frasi_biasate)\
embedding_descrizioni = modello_embedding.encode(list(descrizioni_entita.values()))\
\
# Visualizzare gli embedding (vettori numerici)\
print(embedding_frasi)\
print(embedding_descrizioni)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo generer\'e0 vettori numerici che rappresentano sia le frasi sia le descrizioni delle entit\'e0 di 
\f0\b Wikidata
\f1\b0 . Questi vettori possono essere usati per confrontare frasi e descrizioni basate sulla loro somiglianza semantica.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Passo 3: Utilizzo di tecniche di clustering per identificare bias simili\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Con gli embedding ottenuti, possiamo usare tecniche di 
\f0\b clustering
\f1\b0  per raggruppare frasi che presentano bias simili o descrivono entit\'e0 simili. Useremo il clustering non supervisionato, come 
\f0\b K-means
\f1\b0  o 
\f0\b DBSCAN
\f1\b0 , per identificare i gruppi.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Clustering con K-means\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from sklearn.cluster import KMeans\
import numpy as np\
\
# Combinare embedding di frasi e descrizioni per fare clustering\
dati_clustering = np.vstack((embedding_frasi, embedding_descrizioni))\
\
# Applicare K-means clustering\
n_clusters = 3  # Numero di cluster (ad esempio, per diversi tipi di bias)\
modello_kmeans = KMeans(n_clusters=n_clusters, random_state=0)\
clusters = modello_kmeans.fit_predict(dati_clustering)\
\
# Visualizzare i risultati del clustering\
print(f"Clusters assegnati: \{clusters\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Il clustering raggrupper\'e0 frasi e descrizioni simili in base alla loro vicinanza semantica. Puoi quindi identificare cluster che rappresentano diversi tipi di bias, ad esempio:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls31\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cluster 1
\f1\b0 : Frasi con bias etnico (es. "Italians" descritto come rumorosi).\
\ls31\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cluster 2
\f1\b0 : Frasi con bias di genere (es. "Le donne non sono brave in matematica").\
\ls31\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cluster 3
\f1\b0 : Frasi con bias religioso (es. "I musulmani sono violenti").\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Passo 4: Addestramento di un modello di apprendimento automatico\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Ora che abbiamo i dati raggruppati, possiamo usare questi cluster per addestrare un 
\f0\b modello di classificazione supervisionato
\f1\b0 . Il modello apprender\'e0 a identificare automaticamente i bias nelle frasi in base ai dati di addestramento e alle descrizioni ottenute da 
\f0\b Wikidata
\f1\b0 .\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Preparazione dei dati etichettati per l'addestramento\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Supponiamo di avere frasi con bias etichettate. Ora addestriamo un modello di classificazione:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from sklearn.model_selection import train_test_split\
from sklearn.ensemble import RandomForestClassifier\
from sklearn.metrics import classification_report\
\
# Generare etichette per i cluster (es. 0: bias etnico, 1: bias di genere, ecc.)\
labels = [0, 1]  # Etichette di bias per le frasi nel dataset\
\
# Dividere i dati in training e test\
X_train, X_test, y_train, y_test = train_test_split(embedding_frasi, labels, test_size=0.2, random_state=42)\
\
# Addestrare un modello di classificazione\
modello = RandomForestClassifier(n_estimators=100, random_state=42)\
modello.fit(X_train, y_train)\
\
# Testare il modello\
y_pred = modello.predict(X_test)\
\
# Valutare le performance\
print(classification_report(y_test, y_pred))\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo approccio ti permetter\'e0 di 
\f0\b classificare automaticamente il bias
\f1\b0  nelle nuove frasi in base alle descrizioni ottenute da Wikidata e ai cluster identificati.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Passo 5: Identificare bias in nuove frasi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Ora puoi usare il modello addestrato per classificare nuove frasi e determinare automaticamente il tipo di bias:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Nuove frasi da analizzare\
nuove_frasi = ["Gli uomini sono pi\'f9 logici delle donne.", "I musulmani sono pericolosi."]\
\
# Rappresentare le nuove frasi come embedding\
embedding_nuove_frasi = modello_embedding.encode(nuove_frasi)\
\
# Predire i tipi di bias\
bias_predetto = modello.predict(embedding_nuove_frasi)\
\
# Visualizzare il risultato\
print(f"Bias identificati: \{bias_predetto\}")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusioni\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Combinando le descrizioni di 
\f0\b Wikidata
\f1\b0  con tecniche di 
\f0\b clustering
\f1\b0  e 
\f0\b apprendimento automatico
\f1\b0 , possiamo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls32\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rappresentare frasi e concetti
\f1\b0  in uno spazio vettoriale comune usando embedding.\
\ls32\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Clustrare le frasi
\f1\b0  per identificare tipi simili di bias.\
\ls32\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Addestrare un modello
\f1\b0  per identificare automaticamente i tipi di bias nelle frasi.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questo approccio consente di identificare i bias in modo automatico e strutturato, arricchendo l'analisi semantica con le informazioni ottenute da 
\f0\b Wikidata
\f1\b0  e potenziando l'accuratezza dell'identificazione del bias con l'uso dell'apprendimento automatico.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ma \'e8 meglio avere le ontologie di wikidata o generarle dalle frasi biasate?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 La scelta tra 
\f0\b usare le ontologie esistenti di Wikidata
\f1\b0  o 
\f0\b generare ontologie a partire dalle frasi biasate
\f1\b0  dipende dagli obiettivi del progetto e dalle risorse a disposizione. Entrambi gli approcci hanno vantaggi e svantaggi, e in molti casi potresti combinare entrambi per ottenere una soluzione pi\'f9 robusta. Vediamo ciascuna delle due opzioni nel dettaglio per capire quale sia pi\'f9 adatta al tuo scenario.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Opzione 1: Usare le ontologie di Wikidata\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 Vantaggi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls33\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ontologie esistenti e ben strutturate
\f1\b0 : Wikidata \'e8 un database di conoscenze ampiamente utilizzato e contiene ontologie ben definite per un'ampia variet\'e0 di entit\'e0, come persone, gruppi etnici, professioni, nazionalit\'e0, ecc. Le relazioni tra entit\'e0 e classi sono gi\'e0 predefinite e accurate.\
\ls33\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggiornamento costante
\f1\b0 : Essendo un database collaborativo, Wikidata \'e8 continuamente aggiornato, il che significa che otterrai informazioni attuali e ben mantenute. Non devi preoccuparti di costruire da zero le relazioni tra concetti.\
\ls33\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ragionamento semantico
\f1\b0 : Puoi utilizzare le ontologie di Wikidata per eseguire inferenze avanzate e ottenere descrizioni di entit\'e0 e relazioni complesse tra queste. Le ontologie contengono propriet\'e0 utili come 
\f0\b "sottoclasse di"
\f1\b0  o 
\f0\b "istanza di"
\f1\b0 , che aiutano a collegare concetti pi\'f9 astratti (ad esempio, "Italians" \'e8 una sottoclasse di "Europeans").\
\ls33\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Standard semantici gi\'e0 implementati
\f1\b0 : Wikidata utilizza standard RDF, OWL, e SKOS, che ti permettono di sfruttare formati di dati standardizzati e riutilizzabili con altri dataset del web semantico.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Svantaggi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls34\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Limitazioni ontologiche su stereotipi e bias
\f1\b0 : Wikidata \'e8 progettato per rappresentare fatti oggettivi e neutri. Quindi, non rappresenta direttamente concetti legati a stereotipi, pregiudizi o bias. Ad esempio, non troverai una propriet\'e0 "Italians are noisy" in Wikidata, anche se potresti trovare relazioni che aiutano a descrivere culturalmente il gruppo.\
\ls34\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Difficolt\'e0 a catturare sfumature di bias
\f1\b0 : Le ontologie di Wikidata sono ottime per fornire contesto, ma potrebbero non cogliere le sfumature nei pregiudizi espressi in linguaggio naturale. Ad esempio, le relazioni tra concetti come "Italians" e "noisy" non saranno presenti perch\'e9 \'e8 una forma di stereotipo non oggettivo.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Opzione 2: Generare ontologie a partire dalle frasi biasate\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 Vantaggi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls35\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ontologie personalizzate
\f1\b0 : Creando ontologie a partire dalle frasi biasate, puoi modellare relazioni e concetti specifici del 
\f0\b bias
\f1\b0  che non troveresti in un dataset come Wikidata. Ad esempio, potresti creare relazioni esplicite tra "Italians" e "stereotypes", collegando concetti come "Italians" e "noisy" in un contesto di bias.\
\ls35\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevanza diretta per l'analisi del bias
\f1\b0 : Poich\'e9 le ontologie sono generate a partire dalle frasi biasate, possono essere altamente specifiche per il dominio dell'analisi dei pregiudizi. Puoi creare relazioni personalizzate come "hasGenderBias", "hasRacialBias", "isStereotypeOf", e cos\'ec via, per descrivere con precisione il contesto e il tipo di bias.\
\ls35\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Miglioramento continuo
\f1\b0 : Man mano che analizzi pi\'f9 frasi, puoi arricchire e migliorare l'ontologia. Questo consente un'evoluzione dinamica della tua rappresentazione dei bias, che pu\'f2 adattarsi ai nuovi dati e alle nuove espressioni di pregiudizi.\
\ls35\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Identificazione di pattern specifici
\f1\b0 : Generare ontologie dalle frasi ti consente di catturare pattern specifici presenti nel dataset di frasi biasate. Ad esempio, potresti modellare automaticamente come certi aggettivi (es. "rumorosi", "bravi", "pericolosi") sono frequentemente associati a certi gruppi (es. "italiani", "donne", "musulmani").\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Svantaggi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls36\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Richiede pi\'f9 lavoro
\f1\b0 : Generare un'ontologia personalizzata richiede pi\'f9 tempo e sforzo, in quanto dovrai definire manualmente le relazioni e i concetti rilevanti per il bias. Questo pu\'f2 essere complesso, soprattutto se non hai a disposizione un dataset vasto e rappresentativo.\
\ls36\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Difficolt\'e0 di mantenimento
\f1\b0 : A differenza di Wikidata, la tua ontologia personalizzata non si aggiorner\'e0 automaticamente. Devi mantenerla e arricchirla manualmente o attraverso algoritmi, e questo richiede risorse aggiuntive.\
\ls36\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenze pi\'f9 limitate
\f1\b0 : Le ontologie create da zero potrebbero non avere lo stesso livello di connettivit\'e0 e relazioni semantiche che sono gi\'e0 state stabilite in Wikidata. Pu\'f2 risultare difficile gestire relazioni complesse o multiple tra concetti, come quelle offerte da una fonte come Wikidata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Approccio Ibrido: La Soluzione Migliore?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Una soluzione pratica potrebbe essere 
\f0\b combinare entrambi gli approcci
\f1\b0  per sfruttare i punti di forza di ciascuno:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls37\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Usare Wikidata come base
\f1\b0 : Puoi partire dalle ontologie di Wikidata per ottenere una solida base di conoscenze oggettive e descrittive sulle entit\'e0 (gruppi etnici, professioni, religioni). Questo ti fornisce contesto neutrale e strutturato che puoi usare come punto di partenza per l'analisi.\
\ls37\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estendere con ontologie personalizzate sui bias
\f1\b0 : Successivamente, puoi creare 
\f0\b ontologie personalizzate
\f1\b0  specifiche per descrivere e modellare i bias che non sono esplicitamente catturati da Wikidata. Ad esempio, puoi definire concetti come 
\f0\b "hasStereotype"
\f1\b0 , 
\f0\b "isBiasOf"
\f1\b0 , o relazioni specifiche come "Italians hasStereotype noisy".\
\ls37\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Addestrare un modello di apprendimento automatico
\f1\b0  per 
\f0\b generare ontologie dinamicamente
\f1\b0 : Usando tecniche di NLP, clustering, e apprendimento automatico, puoi estrarre automaticamente relazioni tra concetti nelle frasi biasate e costruire o arricchire l'ontologia man mano che analizzi pi\'f9 dati.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Ecco un possibile flusso di lavoro:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls38\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inizio con Wikidata
\f1\b0 : Estrai informazioni generali sulle entit\'e0 principali presenti nelle frasi (ad esempio, gruppi etnici, professioni).\
\ls38\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Creazione di relazioni specifiche ai bias
\f1\b0 : Usando le frasi biasate, identifica e mappa le relazioni tra le entit\'e0 di Wikidata e i pregiudizi espressi nelle frasi.\
\ls38\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchimento con apprendimento automatico
\f1\b0 : Applica tecniche di clustering e classificazione (come abbiamo visto sopra) per identificare tipi di bias e relazioni che non sono evidenti manualmente. Puoi quindi usare questi risultati per estendere la tua ontologia.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio pratico: Ontologia Ibrida Bias + Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Supponiamo di voler costruire un'ontologia che cattura sia le relazioni oggettive (provenienti da Wikidata) che quelle stereotipate (provenienti dalle frasi biasate).\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 1: Usa Wikidata per le descrizioni di base\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Usiamo le descrizioni di "Italians" e "Women" da Wikidata:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
\
client = Client()\
\
# Descrizioni di "Italians" e "Women"\
italians = client.get('Q50001', load=True)  # Italians\
women = client.get('Q467', load=True)  # Women\
\
print(f"Italians: \{italians.description\}")\
print(f"Women: \{women.description\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Output:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
Italians: Popolazione nativa dell'Italia\
Women: Adulto di sesso femminile\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 2: Arricchire con relazioni dai bias nelle frasi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora possiamo aggiungere relazioni specifiche dai bias:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls39\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase biasata: 
\f0\b "Gli italiani sono rumorosi"
\f1\b0  \uc0\u8594  Relazione 
\f0\b Italians hasStereotype noisy
\f1\b0 \
\ls39\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase biasata: 
\f0\b "Le donne non sono brave in matematica"
\f1\b0  \uc0\u8594  Relazione 
\f0\b Women hasStereotype notGoodAtMath
\f1\b0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Usiamo 
\f0\b rdflib
\f1\b0  per definire un'ontologia personalizzata che includa queste nuove relazioni:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from rdflib import Graph, Literal, RDF, URIRef, Namespace\
\
# Namespace personalizzato\
BIASES = Namespace("http://example.org/biases#")\
\
# Creare un grafo RDF\
g = Graph()\
\
# Definire le entit\'e0 e le relazioni\
italians_uri = URIRef(BIASES.Italians)\
noisy_uri = URIRef(BIASES.noisy)\
women_uri = URIRef(BIASES.Women)\
not_good_at_math_uri = URIRef(BIASES.notGoodAtMath)\
\
# Aggiungere le triple\
g.add((italians_uri, BIASES.hasStereotype, noisy_uri))\
g.add((women_uri, BIASES.hasStereotype, not_good_at_math_uri))\
\
# Salvare l'ontologia in formato RDF\
g.serialize("bias_ontology.ttl", format="turtle")\
\
print(g.serialize(format="turtle").decode("utf-8"))\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo codice genera un'ontologia che cattura non solo le descrizioni oggettive di 
\f0\b Wikidata
\f1\b0 , ma anche le relazioni specifiche ai bias estratte dalle frasi biasate.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 In sintesi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls40\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Le ontologie di Wikidata
\f1\b0  sono eccellenti per ottenere una base neutra e ben strutturata di conoscenze.\
\ls40\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Le ontologie personalizzate
\f1\b0  create dalle frasi biasate ti permettono di catturare e modellare relazioni che non sono presenti in Wikidata, come stereotipi e pregiudizi.\
\ls40\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un approccio ibrido
\f1\b0  che sfrutta entrambe le fonti \'e8 probabilmente il pi\'f9 efficace per rappresentare sia la realt\'e0 oggettiva che le distorsioni del linguaggio legate ai bias, e per potenziare l'analisi attraverso inferenze e apprendimento automatico.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 In tal modo, puoi costruire un sistema pi\'f9 robusto per identificare e classificare bias, sfruttando sia le ontologie preesistenti che quelle generate dinamicamente.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 dimmi come implementare l'approccio ibrido nel dettaglio\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Implementare un approccio ibrido che utilizza sia le 
\f0\b ontologie di Wikidata
\f1\b0  sia ontologie 
\f0\b generate dalle frasi biasate
\f1\b0  richiede diversi passaggi, suddivisi in fasi logiche che combinano l'uso di 
\f0\b dati strutturati (Wikidata)
\f1\b0  e 
\f0\b machine learning
\f1\b0  per generare e arricchire le ontologie specifiche sui bias. Ti guider\'f2 passo per passo, partendo dalla costruzione di una base ontologica con Wikidata, fino alla generazione e arricchimento delle ontologie basate sulle frasi biasate.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Passaggi chiave per implementare l'approccio ibrido\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls41\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estrazione dei dati di base da Wikidata
\f1\b0 : Usiamo Wikidata per ottenere informazioni su entit\'e0 rilevanti (gruppi etnici, professioni, ecc.) che verranno usate come base per l'ontologia.\
\ls41\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Costruzione di ontologie specifiche per i bias
\f1\b0 : Definiamo relazioni personalizzate per catturare i bias presenti nelle frasi biasate (es. "Italians hasStereotype noisy").\
\ls41\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Uso di tecniche di embedding
\f1\b0 : Rappresentiamo frasi biasate e descrizioni di Wikidata in forma numerica, utilizzando tecniche di 
\f0\b embedding
\f1\b0 .\
\ls41\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Clustering e identificazione dei bias
\f1\b0 : Utilizziamo algoritmi di clustering per raggruppare frasi con bias simili, con l\'92obiettivo di generare automaticamente nuove relazioni da aggiungere all'ontologia.\
\ls41\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchimento continuo dell'ontologia
\f1\b0 : L'ontologia personalizzata viene aggiornata dinamicamente, man mano che si analizzano nuove frasi, creando relazioni semantiche sui bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fase 1: Estrazione dei dati di base da Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Il primo passo consiste nell'ottenere una base solida di conoscenze da Wikidata su entit\'e0 come nazionalit\'e0, gruppi etnici, religioni o professioni. Queste entit\'e0 costituiranno il punto di partenza per l'ontologia.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Codice per estrarre descrizioni da Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Usiamo la libreria 
\f0\b wikidata.client
\f1\b0  per estrarre descrizioni di entit\'e0 rilevanti come "Italians", "Women", "Doctors", ecc.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
import pandas as pd\
\
# Inizializza il client di Wikidata\
client = Client()\
\
# Lista di entit\'e0 da cercare\
entita_da_cercare = ['Italians', 'Doctors', 'Muslims', 'Women']\
\
# Dizionario per salvare le descrizioni estratte\
descrizioni_entita = \{\}\
\
# Estrarre le descrizioni da Wikidata\
for entita in entita_da_cercare:\
    risultato = client.search(entita)\
    if risultato:\
        entita_wikidata = client.get(risultato[0]['id'], load=True)\
        descrizioni_entita[entita] = entita_wikidata.description\
\
# Visualizzare le descrizioni estratte\
print(descrizioni_entita)\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs24 \cf0 \strokec2 Output
\f1\b0 :\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
\{\
  'Italians': 'Popolazione nativa dell\\'Italia',\
  'Doctors': 'Professionista medico qualificato',\
  'Muslims': 'Seguace dell\\'Islam',\
  'Women': 'Adulto di sesso femminile'\
\}\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Queste descrizioni rappresentano le 
\f0\b entit\'e0 di base
\f1\b0  che useremo per costruire l'ontologia.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 2: Creazione di un'ontologia di base con le entit\'e0 di Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per costruire l'ontologia, possiamo rappresentare le entit\'e0 estratte da Wikidata con relazioni di base come 
\f0\b "subClassOf"
\f1\b0  o 
\f0\b "relatedTo"
\f1\b0 . Usiamo 
\f0\b RDF
\f1\b0  e 
\f0\b rdflib
\f1\b0  per costruire l'ontologia iniziale.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Codice per creare l'ontologia di base con RDF\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from rdflib import Graph, Literal, RDF, URIRef, Namespace\
\
# Creare un namespace per l'ontologia\
BIASES = Namespace("http://example.org/biases#")\
\
# Creare un grafo RDF per l'ontologia\
g = Graph()\
\
# Definire le entit\'e0 con URI\
italians_uri = URIRef(BIASES.Italians)\
doctors_uri = URIRef(BIASES.Doctors)\
muslims_uri = URIRef(BIASES.Muslims)\
women_uri = URIRef(BIASES.Women)\
\
# Aggiungere descrizioni come letterali\
g.add((italians_uri, RDF.type, Literal(descrizioni_entita['Italians'])))\
g.add((doctors_uri, RDF.type, Literal(descrizioni_entita['Doctors'])))\
g.add((muslims_uri, RDF.type, Literal(descrizioni_entita['Muslims'])))\
g.add((women_uri, RDF.type, Literal(descrizioni_entita['Women'])))\
\
# Aggiungere relazioni di base (subclass of, related to)\
g.add((italians_uri, RDF.type, BIASES.Europeans))  # Italians sono europei\
g.add((doctors_uri, RDF.type, BIASES.Profession))  # Doctors sono professionisti\
g.add((women_uri, RDF.type, BIASES.Gender))  # Women \'e8 legato al genere\
\
# Salvare l'ontologia in un file RDF\
g.serialize("base_ontology.ttl", format="turtle")\
\
# Visualizzare l'ontologia serializzata\
print(g.serialize(format="turtle").decode("utf-8"))\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Questo codice genera un'ontologia di base che rappresenta le entit\'e0 con le loro relazioni.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 3: Rappresentazione delle frasi biasate con embedding\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Ora rappresentiamo le 
\f0\b frasi biasate
\f1\b0  e le descrizioni delle entit\'e0 di Wikidata in uno spazio vettoriale comune utilizzando tecniche di embedding come 
\f0\b Sentence-BERT
\f1\b0 . Questo ci permetter\'e0 di confrontare frasi e descrizioni semanticamente.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Installare la libreria 
\f3\fs26 sentence-transformers
\f0\fs24 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 bash\
\
pip install sentence-transformers\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Codice per creare embedding delle frasi e delle descrizioni\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from sentence_transformers import SentenceTransformer\
\
# Inizializzare il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Frasi biasate dal dataset Stereoset\
frasi_biasate = ["Gli italiani sono rumorosi.", "Le donne non sono brave in matematica."]\
\
# Creare embedding per le frasi e le descrizioni\
embedding_frasi = modello_embedding.encode(frasi_biasate)\
embedding_descrizioni = modello_embedding.encode(list(descrizioni_entita.values()))\
\
# Visualizzare gli embedding (vettori numerici)\
print(embedding_frasi)\
print(embedding_descrizioni)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Ora abbiamo ottenuto rappresentazioni numeriche (embedding) per le frasi biasate e per le descrizioni delle entit\'e0 di Wikidata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 4: Clustering per identificare bias simili\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Utilizziamo algoritmi di clustering (es. 
\f0\b K-means
\f1\b0  o 
\f0\b DBSCAN
\f1\b0 ) per raggruppare frasi con bias simili. Il clustering ci aiuter\'e0 a identificare automaticamente tipi di bias basati su somiglianze tra frasi e descrizioni.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Clustering con K-means\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from sklearn.cluster import KMeans\
import numpy as np\
\
# Unire gli embedding di frasi e descrizioni\
dati_clustering = np.vstack((embedding_frasi, embedding_descrizioni))\
\
# Applicare K-means clustering\
n_clusters = 3  # Numero di cluster\
modello_kmeans = KMeans(n_clusters=n_clusters, random_state=0)\
clusters = modello_kmeans.fit_predict(dati_clustering)\
\
# Visualizzare i risultati del clustering\
print(f"Clusters assegnati: \{clusters\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Le frasi biasate e le descrizioni vengono raggruppate in cluster che rappresentano diversi tipi di bias (es. bias etnico, di genere, ecc.).\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 5: Generazione e arricchimento dinamico dell'ontologia\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Ora che abbiamo raggruppato le frasi, possiamo aggiungere relazioni specifiche tra entit\'e0 basate sui bias trovati nei cluster. Usiamo RDF per arricchire l'ontologia con queste nuove relazioni.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Codice per arricchire l'ontologia con bias identificati\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
# Creare relazioni specifiche sui bias\
noisy_uri = URIRef(BIASES.noisy)\
not_good_at_math_uri = URIRef(BIASES.notGoodAtMath)\
\
# Aggiungere stereotipi specifici all'ontologia\
g.add((italians_uri, BIASES.hasStereotype, noisy_uri))  # Italians ha lo stereotipo di essere rumorosi\
g.add((women_uri, BIASES.hasStereotype, not_good_at_math_uri))  # Women ha lo stereotipo di non essere brave in matematica\
\
# Salvare l'ontologia aggiornata\
g.serialize("bias_ontology.ttl", format="turtle")\
\
# Visualizzare l'ontologia arricchita\
print(g.serialize(format="turtle").decode("utf-8"))\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo modo, abbiamo arricchito l'ontologia iniziale con relazioni derivate automaticamente dalle frasi biasate e dai risultati del clustering.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Fase 6: Iterazione e miglioramento continuo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Il sistema pu\'f2 essere iterativamente migliorato, aggiungendo nuove frasi biasate e arricchendo ulteriormente l'ontologia man mano che si rilevano nuovi bias. Ogni volta che il sistema identifica nuovi bias, si possono creare nuove relazioni semantiche tra entit\'e0 e stereotipi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'approccio ibrido che combina 
\f0\b ontologie di Wikidata
\f1\b0  e 
\f0\b ontologie generate dalle frasi biasate
\f1\b0  ti permette di costruire un sistema sofisticato e dinamico per l'identificazione e la categorizzazione dei bias. I passaggi chiave includono:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls42\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estrazione delle descrizioni di Wikidata
\f1\b0  per costruire una base solida.\
\ls42\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding delle frasi biasate
\f1\b0  per rappresentare semanticamente i dati.\
\ls42\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Clustering
\f1\b0  per identificare automaticamente gruppi di bias simili.\
\ls42\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchimento dell'ontologia
\f1\b0  man mano che si analizzano nuove frasi.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questo approccio ti consente di sfruttare conoscenze esistenti e creare nuove ontologie per un sistema di rilevamento dei bias sempre pi\'f9 accurato e aggiornato.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 Ora che abbiamo raggruppato le frasi, possiamo aggiungere relazioni specifiche tra entit\'e0 basate sui bias trovati nei cluster. Usiamo RDF per arricchire l'ontologia con queste nuove relazioni. Spiega bene questo.\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Certamente! Quando diciamo che "possiamo aggiungere relazioni specifiche tra entit\'e0 basate sui bias trovati nei cluster e arricchire l'ontologia con queste nuove relazioni", ci riferiamo all'idea di catturare i 
\f0\b bias rilevati
\f1\b0  durante il processo di clustering e rappresentarli esplicitamente all'interno di un'
\f0\b ontologia
\f1\b0 .\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Cosa significa "aggiungere relazioni specifiche basate sui bias trovati nei cluster"?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Quando applichiamo tecniche di 
\f0\b clustering
\f1\b0  alle frasi biasate e alle descrizioni delle entit\'e0 (ottenute da Wikidata), otteniamo gruppi (o 
\f0\b cluster
\f1\b0 ) di frasi che presentano bias simili. Ogni cluster pu\'f2 rappresentare un certo 
\f0\b tipo di bias
\f1\b0  che viene comunemente espresso nei confronti di una determinata entit\'e0 (ad esempio, "gli italiani sono rumorosi", "le donne non sono brave in matematica").\
Una volta identificati i 
\f0\b cluster
\f1\b0 , possiamo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls43\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Interpretare i cluster
\f1\b0  per capire il tipo di bias (es. etnico, di genere, religioso).\
\ls43\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Creare relazioni semantiche
\f1\b0  che collegano le entit\'e0 menzionate nelle frasi con i bias rilevati in modo strutturato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Aggiunta delle relazioni nell'ontologia\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Dopo aver identificato i 
\f0\b bias
\f1\b0  nei cluster, rappresentiamo queste 
\f0\b relazioni semantiche
\f1\b0  nell'ontologia usando 
\f0\b RDF
\f1\b0  (Resource Description Framework), che ci consente di definire formalmente le connessioni tra le entit\'e0 e i bias.\
Ad esempio:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls44\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Se un cluster contiene frasi come "gli italiani sono rumorosi", possiamo creare una relazione che collega l'entit\'e0 "Italians" con lo stereotipo "noisy".\
\ls44\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Se un altro cluster contiene frasi come "le donne non sono brave in matematica", possiamo collegare "Women" con lo stereotipo "notGoodAtMath".\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio di ontologia arricchita con bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Supponiamo che, dopo aver applicato il clustering, abbiamo trovato che un cluster rappresenta frasi che esprimono il bias "gli italiani sono rumorosi", e un altro cluster contiene frasi che dicono "le donne non sono brave in matematica". Vogliamo aggiungere queste relazioni all'ontologia come segue:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls45\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazione 1
\f1\b0 : L'entit\'e0 
\f0\b Italians
\f1\b0  ha lo stereotipo 
\f0\b noisy
\f1\b0 .\
\ls45\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazione 2
\f1\b0 : L'entit\'e0 
\f0\b Women
\f1\b0  ha lo stereotipo 
\f0\b notGoodAtMath
\f1\b0 .\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Passaggi per arricchire l'ontologia con RDF\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls46\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Definizione delle entit\'e0
\f1\b0 : Le entit\'e0 principali (ad esempio, "Italians", "Women") sono gi\'e0 rappresentate nell'ontologia.\
\ls46\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Definizione dei bias/stereotipi
\f1\b0 : Creiamo nuove relazioni per rappresentare i bias che collegano queste entit\'e0 ai concetti di stereotipo.\
\ls46\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggiunta delle relazioni
\f1\b0 : Usiamo 
\f0\b RDF
\f1\b0  per collegare le entit\'e0 ai bias trovati.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Codice dettagliato per arricchire l'ontologia con RDF\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Supponiamo di avere le entit\'e0 
\f0\b Italians
\f1\b0  e 
\f0\b Women
\f1\b0  gi\'e0 definite nell'ontologia. Aggiungiamo le relazioni trovate durante il clustering.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from rdflib import Graph, Literal, RDF, URIRef, Namespace\
\
# Creare un namespace per l'ontologia del bias\
BIASES = Namespace("http://example.org/biases#")\
\
# Creare un grafo RDF per l'ontologia\
g = Graph()\
\
# Definire le entit\'e0 (gi\'e0 esistenti nell'ontologia)\
italians_uri = URIRef(BIASES.Italians)\
women_uri = URIRef(BIASES.Women)\
\
# Definire i bias/stereotipi trovati nei cluster\
noisy_uri = URIRef(BIASES.noisy)  # Stereotipo di "Italians"\
not_good_at_math_uri = URIRef(BIASES.notGoodAtMath)  # Stereotipo di "Women"\
\
# Aggiungere le relazioni di bias nell'ontologia\
g.add((italians_uri, BIASES.hasStereotype, noisy_uri))  # Italians ha lo stereotipo "noisy"\
g.add((women_uri, BIASES.hasStereotype, not_good_at_math_uri))  # Women ha lo stereotipo "notGoodAtMath"\
\
# Salvare l'ontologia arricchita in un file RDF\
g.serialize("bias_ontology.ttl", format="turtle")\
\
# Visualizzare l'ontologia arricchita\
print(g.serialize(format="turtle").decode("utf-8"))\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Output RDF (ontologia arricchita)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Il codice generer\'e0 un file RDF (in formato Turtle) che rappresenta l'ontologia con le nuove relazioni di bias. L'output potrebbe essere simile a questo:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 turtle\
\
@prefix biases: <http://example.org/biases#> .\
\
biases:Italians a biases:Europeans ;\
    biases:hasStereotype biases:noisy .\
\
biases:Women a biases:Gender ;\
    biases:hasStereotype biases:notGoodAtMath .\
\
biases:noisy a biases:Stereotype ;\
    rdfs:label "noisy" .\
\
biases:notGoodAtMath a biases:Stereotype ;\
    rdfs:label "not good at math" .\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Interpretazione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 In questo esempio:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls47\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Italians
\f1\b0  \'e8 collegato al concetto di 
\f0\b noisy
\f1\b0  attraverso la relazione 
\f0\b hasStereotype
\f1\b0 .\
\ls47\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Women
\f1\b0  \'e8 collegato al concetto 
\f0\b notGoodAtMath
\f1\b0  attraverso la relazione 
\f0\b hasStereotype
\f1\b0 .\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Queste relazioni sono state generate dai 
\f0\b bias trovati nei cluster
\f1\b0  e sono esplicitamente rappresentate nell'ontologia in modo da poter essere utilizzate per future inferenze o analisi semantiche.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Benefici dell'arricchimento dell'ontologia\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls48\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Modellazione strutturata dei bias
\f1\b0 : Aggiungendo esplicitamente relazioni di bias nell'ontologia, otteniamo una rappresentazione semantica strutturata dei pregiudizi espressi nelle frasi.\
\ls48\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza automatica
\f1\b0 : Poich\'e9 stiamo usando RDF per definire queste relazioni, possiamo applicare strumenti di inferenza semantica per analizzare automaticamente i collegamenti tra entit\'e0 e bias e generare nuovi insight su come i bias sono distribuiti tra diversi gruppi.\
\ls48\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Espandibilit\'e0
\f1\b0 : Man mano che aggiungiamo nuove frasi e scopriamo nuovi bias, possiamo arricchire continuamente l'ontologia, creando una rappresentazione dinamica e in continua evoluzione del pregiudizio nel linguaggio naturale.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Estendere l'analisi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Oltre a collegare entit\'e0 e stereotipi, possiamo estendere ulteriormente l'ontologia introducendo nuovi concetti e relazioni, come:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls49\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 bias di genere
\f1\b0 , 
\f0\b bias razziale
\f1\b0 , 
\f0\b bias professionale
\f1\b0 , ecc.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls49\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Collegare pi\'f9 entit\'e0 a stereotipi comuni (es. "Italians" e "Spanish" possono condividere lo stereotipo "noisy").\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Ad esempio, potresti creare una relazione di bias pi\'f9 complessa che collega pi\'f9 entit\'e0 tra loro usando RDF o OWL (Ontology Web Language).\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'idea di 
\f0\b arricchire un'ontologia con relazioni basate sui bias trovati nei cluster
\f1\b0  ti consente di strutturare le informazioni su come certi stereotipi o pregiudizi sono collegati a gruppi specifici, nazionalit\'e0, professioni, ecc. Utilizzando 
\f0\b RDF
\f1\b0  e tecnologie ontologiche, queste relazioni possono essere definite formalmente e utilizzate per inferenze automatiche, facilitando un'analisi pi\'f9 avanzata e completa del linguaggio biasato.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 e per cosa tornano utili le ontologie di wikidata?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Le 
\f0\b ontologie di Wikidata
\f1\b0  tornano utili in diversi modi quando si cerca di identificare e analizzare il bias nelle frasi o nei testi, soprattutto nell'ambito del 
\f0\b Web Semantico
\f1\b0  e dell'
\f0\b apprendimento automatico
\f1\b0 . Ecco come possono essere sfruttate nel contesto di un'analisi ibrida (come quella che abbiamo visto), dove si utilizzano sia dati strutturati (da Wikidata) sia tecniche NLP e clustering per rilevare e arricchire l'ontologia con bias trovati nelle frasi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 1. Base di Conoscenza Neutrale e Oggettiva\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di 
\f0\b Wikidata
\f1\b0  offrono una vasta quantit\'e0 di dati strutturati che descrivono milioni di entit\'e0 (persone, luoghi, gruppi etnici, nazionalit\'e0, professioni, ecc.) in modo 
\f0\b neutrale
\f1\b0  e 
\f0\b oggettivo
\f1\b0 . Queste ontologie forniscono una solida base di conoscenza su cui puoi costruire l'analisi dei bias.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se analizzi frasi che contengono riferimenti agli italiani, come "Gli italiani sono rumorosi", puoi estrarre da Wikidata informazioni oggettive sulla nazionalit\'e0 "Italians" che descrivono il gruppo come 
\f0\b "popolazione nativa dell'Italia"
\f1\b0 , senza alcun riferimento agli stereotipi. Questa informazione ti aiuta a stabilire un 
\f0\b punto di confronto oggettivo
\f1\b0  rispetto agli stereotipi che emergono nel linguaggio.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 2. Arricchimento delle Analisi Semantiche\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata utilizzano standard semantici (come 
\f0\b RDF
\f1\b0 , 
\f0\b OWL
\f1\b0 ) che definiscono relazioni complesse tra le entit\'e0, come:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls50\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 sottoclasse di
\f1\b0  (subclass of)\
\ls50\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 istanza di
\f1\b0  (instance of)\
\ls50\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 parte di
\f1\b0  (part of)\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Queste relazioni ti permettono di esplorare le connessioni tra concetti in modo pi\'f9 strutturato. Quando analizzi frasi biasate, puoi sfruttare queste ontologie per 
\f0\b arricchire l'analisi
\f1\b0  con relazioni preesistenti.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se una frase fa riferimento a un bias di genere, come "Le donne non sono brave in matematica", puoi usare l'ontologia di Wikidata per recuperare informazioni su 
\f0\b "donne"
\f1\b0  come entit\'e0 che appartiene alla classe 
\f0\b genere
\f1\b0 . In questo modo, puoi collegare meglio i bias alla struttura semantica dell'ontologia e fare inferenze pi\'f9 accurate sui bias di genere in generale.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 3. Inferenze e Ragionamento Semantico\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata non sono solo dati statici. Grazie alla loro struttura, possono essere utilizzate per eseguire 
\f0\b inferenze
\f1\b0 . Questo \'e8 particolarmente utile quando vuoi estendere la tua analisi oltre le frasi immediatamente disponibili e fare 
\f0\b ragionamenti automatici
\f1\b0  basati su informazioni implicite.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se stai cercando di analizzare bias contro un certo gruppo etnico, puoi sfruttare le relazioni tra entit\'e0 in Wikidata per fare inferenze. Supponiamo che tu stia analizzando frasi su 
\f0\b Italians
\f1\b0  e scopri che appartengono alla categoria 
\f0\b Europeans
\f1\b0 . Puoi inferire che stereotipi rivolti agli 
\f0\b Europeans
\f1\b0  potrebbero applicarsi anche agli 
\f0\b Italians
\f1\b0 , arricchendo cos\'ec l'analisi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 4. Validazione dei Bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata sono utili anche per la 
\f0\b validazione
\f1\b0  dei bias trovati nelle frasi. Se rilevi un potenziale bias in una frase, puoi usare Wikidata per confrontare il concetto descritto nella frase con la rappresentazione neutra e oggettiva dell'entit\'e0.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Una frase come "Gli italiani sono sempre pigri" potrebbe contenere un bias stereotipato. Usando l'ontologia di Wikidata per confrontare la descrizione degli 
\f0\b Italians
\f1\b0  con la realt\'e0 oggettiva (ad esempio, la storia culturale e lavorativa degli italiani), puoi confermare che l'affermazione \'e8 un pregiudizio infondato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 5. Riutilizzo e Condivisione di Conoscenze Strutturate\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata utilizzano 
\f0\b standard RDF e OWL
\f1\b0 , che sono ampiamente utilizzati nel Web Semantico. Ci\'f2 significa che le informazioni strutturate che ottieni da Wikidata sono 
\f0\b interoperabili
\f1\b0  con altre basi di conoscenza e strumenti di analisi semantica. Questo ti permette di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls51\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Riutilizzare ontologie esistenti
\f1\b0  in vari progetti di analisi del linguaggio.\
\ls51\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Integrare dati
\f1\b0  provenienti da altre fonti del Web Semantico (es. DBpedia, YAGO) per arricchire ulteriormente l'analisi dei bias.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 \strokec2 Esempio
\f1\b0 : Se stai analizzando bias su gruppi etnici o nazionalit\'e0, puoi combinare le informazioni di Wikidata con altre fonti di conoscenza (ad esempio, DBpedia) per ottenere una rappresentazione pi\'f9 completa e ricca del contesto culturale e storico del gruppo analizzato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 6. Supporto alla Generazione di Ontologie Specifiche sui Bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Wikidata ti fornisce una base di conoscenza da cui puoi partire per creare 
\f0\b ontologie personalizzate sui bias
\f1\b0 . Invece di creare tutto da zero, puoi usare le entit\'e0 e le relazioni gi\'e0 presenti in Wikidata e arricchirle con le 
\f0\b nuove relazioni di bias
\f1\b0  che emergono dall'analisi delle frasi.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se stai generando un'ontologia per descrivere stereotipi come "Italians are noisy", puoi partire dall'ontologia di Wikidata che gi\'e0 descrive chi sono gli 
\f0\b Italians
\f1\b0  e arricchirla aggiungendo una relazione come 
\f0\b hasStereotype
\f1\b0  collegata allo stereotipo 
\f0\b noisy
\f1\b0 . In questo modo, sfrutti la struttura ontologica di Wikidata e la estendi per rappresentare pregiudizi e stereotipi rilevati nei dati.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 7. Contesto Culturale e Storico\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata spesso includono 
\f0\b informazioni storiche
\f1\b0  e 
\f0\b contesto culturale
\f1\b0  per le entit\'e0, che possono essere utilizzate per analizzare pi\'f9 a fondo i bias. Questo \'e8 particolarmente utile se vuoi analizzare i 
\f0\b pregiudizi storici
\f1\b0  o capire come si sono sviluppati certi stereotipi nel tempo.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se analizzi bias contro i 
\f0\b musulmani
\f1\b0 , Wikidata potrebbe fornirti informazioni storiche sul contesto religioso e culturale dell'Islam, permettendoti di confrontare le affermazioni stereotipate con fatti oggettivi e storici.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 8. Aiuto per il Clustering e l'Identificazione Automatica dei Bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Quando applichi tecniche di 
\f0\b clustering
\f1\b0  per raggruppare frasi biasate, puoi sfruttare le ontologie di Wikidata per aggiungere contesto ai cluster trovati. Ad esempio, se un cluster di frasi contiene riferimenti a "medici", puoi usare Wikidata per capire che 
\f0\b "Doctors"
\f1\b0  appartiene alla categoria 
\f0\b "Profession"
\f1\b0  e che potrebbe esserci un bias professionale in gioco. Questo ti aiuta a 
\f0\b interpretare meglio i cluster
\f1\b0 .\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Un cluster di frasi potrebbe riguardare stereotipi di genere sui medici (ad esempio, "I medici sono sempre uomini"). Usando Wikidata, puoi estrarre informazioni sul concetto di 
\f0\b Doctors
\f1\b0  e collegarlo a 
\f0\b bias di genere
\f1\b0  per capire meglio il contesto del bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 9. Riconoscimento delle Relazioni tra Entit\'e0\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le ontologie di Wikidata possono anche aiutarti a 
\f0\b identificare relazioni implicite
\f1\b0  tra concetti. Se una frase contiene un bias contro un gruppo specifico, puoi esplorare se lo stesso stereotipo potrebbe applicarsi ad altri gruppi correlati.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 : Se trovi frasi stereotipate sugli 
\f0\b Italians
\f1\b0 , puoi usare la relazione 
\f0\b subclass of
\f1\b0  per vedere che gli 
\f0\b Italians
\f1\b0  sono una sottoclasse degli 
\f0\b Europeans
\f1\b0 , e quindi verificare se bias simili sono espressi anche contro altre nazionalit\'e0 europee.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le 
\f0\b ontologie di Wikidata
\f1\b0  sono utili principalmente come 
\f0\b base di conoscenza strutturata
\f1\b0  e 
\f0\b neutrale
\f1\b0  da cui puoi partire per confrontare, arricchire e validare i bias trovati nelle frasi. Ti offrono:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls52\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Descrizioni oggettive
\f1\b0  delle entit\'e0, ideali per confrontare stereotipi e pregiudizi.\
\ls52\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Strutture semantiche
\f1\b0  pronte all'uso che ti consentono di eseguire 
\f0\b inferenze
\f1\b0  e collegare concetti in modo pi\'f9 complesso.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls52\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un modo per 
\f0\b riutilizzare dati standardizzati
\f1\b0  e integrabili con altre fonti di conoscenza.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 In un approccio ibrido, puoi combinare le ontologie di Wikidata con ontologie personalizzate sui bias, utilizzando Wikidata come punto di partenza per arricchire la tua analisi e migliorare la comprensione e rilevamento dei bias nel linguaggio.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 come si fa questo in python? Le ontologie di Wikidata sono utili anche per la validazione dei bias trovati nelle frasi. Se rilevi un potenziale bias in una frase, puoi usare Wikidata per confrontare il concetto descritto nella frase con la rappresentazione neutra e oggettiva dell'entit\'e0.\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Per 
\f0\b validare i bias trovati nelle frasi
\f1\b0  utilizzando le 
\f0\b ontologie di Wikidata
\f1\b0  in Python, puoi seguire un flusso che integra l'analisi del linguaggio naturale (NLP) con i dati strutturati e oggettivi di 
\f0\b Wikidata
\f1\b0 . Il processo implica:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls53\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Identificazione di un potenziale bias
\f1\b0  in una frase, utilizzando un modello NLP o un approccio basato su regole.\
\ls53\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estrazione di informazioni oggettive da Wikidata
\f1\b0  sull'entit\'e0 o il concetto menzionato nella frase (ad esempio, nazionalit\'e0, professione, genere, ecc.).\
\ls53\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confronto tra la frase biasata e i dati neutri di Wikidata
\f1\b0 , per validare se la frase \'e8 stereotipata o infondata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Fasi chiave per implementare questo processo in Python\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 Fase 1: Identificazione del Bias in una Frase\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Puoi utilizzare un modello NLP, come 
\f0\b BERT
\f1\b0 , per analizzare una frase e determinare se contiene bias. Ad esempio, se la frase afferma "Gli italiani sono rumorosi", il modello potrebbe rilevare un possibile bias etnico.\
Ecco un esempio di come puoi farlo usando il modello di 
\f0\b sentiment analysis
\f1\b0  di Hugging Face come proxy per il bias:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from transformers import pipeline\
\
# Inizializzare il modello di sentiment analysis\
classifier = pipeline('sentiment-analysis')\
\
# Frase da analizzare\
frase = "Gli italiani sono rumorosi."\
\
# Identificare il bias (usando sentiment analysis come proxy per il bias)\
risultato_bias = classifier(frase)\
\
# Visualizzare il risultato\
print(f"Frase: \{frase\}")\
print(f"Risultato bias: \{risultato_bias\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo caso, una classificazione come 
\f0\b "negative"
\f1\b0  con un alto punteggio potrebbe indicare che la frase contiene un bias potenzialmente negativo verso gli italiani.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Fase 2: Estrazione di Informazioni da Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora che abbiamo rilevato un possibile bias, possiamo utilizzare le ontologie di 
\f0\b Wikidata
\f1\b0  per confrontare il concetto menzionato nella frase con la sua descrizione oggettiva. Usiamo la libreria 
\f0\b wikidata.client
\f1\b0  per ottenere descrizioni delle entit\'e0 menzionate nella frase (in questo caso, gli "italiani").\
Installiamo la libreria necessaria:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
pip install wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Poi estraiamo i dati da 
\f0\b Wikidata
\f1\b0  per confrontare la frase con informazioni oggettive:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
\
# Inizializza il client Wikidata\
client = Client()\
\
# Cerca l'entit\'e0 "Italians" su Wikidata\
italians = client.get('Q50001', load=True)  # ID di Italians su Wikidata\
\
# Ottenere descrizione oggettiva e altre informazioni\
descrizione_italians = italians.description\
\
print(f"Descrizione oggettiva di Italians su Wikidata: \{descrizione_italians\}")\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo caso, Wikidata ci fornir\'e0 una descrizione oggettiva degli 
\f0\b Italians
\f1\b0 , come "Popolazione nativa dell'Italia".\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Fase 3: Confronto della Frase con le Informazioni di Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 A questo punto, possiamo confrontare la frase che contiene il bias ("Gli italiani sono rumorosi") con la descrizione oggettiva di Wikidata. Se la descrizione di 
\f0\b Wikidata
\f1\b0  non contiene alcun riferimento alla rumorosit\'e0 o a tratti comportamentali generalizzati, possiamo concludere che la frase contiene un 
\f0\b pregiudizio stereotipato
\f1\b0 .\
Ecco come mettere insieme le due parti:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Confrontare la descrizione oggettiva con la frase biasata\
if "rumorosi" in frase.lower():\
    print(f"La frase potrebbe contenere un bias: '\{frase\}'.")\
    print(f"La descrizione di Wikidata su 'Italians' \'e8: '\{descrizione_italians\}'")\
    print("Il pregiudizio non \'e8 supportato dalla descrizione oggettiva, quindi \'e8 probabile che sia uno stereotipo.")\
else:\
    print("La frase non sembra contenere stereotipi evidenti.")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Estendere l'Analisi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls54\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estrazione Automatica delle Entit\'e0
\f1\b0 : Puoi migliorare il sistema estraendo automaticamente le entit\'e0 (nazionalit\'e0, professioni, ecc.) dalle frasi utilizzando un modello di Named Entity Recognition (NER) per individuare entit\'e0 come "Italians", "Doctors", "Women", ecc.\uc0\u8232 Esempio di Named Entity Recognition (NER) con SpaCy:\u8232 
\f2\fs26 bash\uc0\u8232 \u8232 \u8232 \u8232 \u8232 
\f1\fs24 \
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 pip install spacy\
python -m spacy download en_core_web_sm\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Ecco come usare SpaCy per estrarre entit\'e0:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
import spacy\
\
# Caricare il modello NER di SpaCy\
nlp = spacy.load("en_core_web_sm")\
\
# Frase da analizzare\
frase = "Gli italiani sono rumorosi."\
\
# Eseguire Named Entity Recognition (NER)\
doc = nlp(frase)\
for ent in doc.ents:\
    print(ent.text, ent.label_)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Output:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 graphql\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls55\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 italiani NORP  # NORP sta per Nazionalit\'e0, Gruppi Religiosi o Politici\
\ls55\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \uc0\u8232 \u8232 
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls55\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Integrazione con Ontologie per Inferenze Automatiche
\f1\b0 : Utilizzando 
\f0\b RDF
\f1\b0  e 
\f0\b ontologie
\f1\b0 , puoi arricchire il confronto tra bias e descrizioni oggettive. Ad esempio, se "Italians" \'e8 collegato a "Europeans" tramite la relazione 
\f0\b subclass of
\f1\b0 , puoi estendere il controllo per bias che si applicano a pi\'f9 entit\'e0 collegate.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio Completo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Ecco il flusso completo che integra il rilevamento del bias, l'estrazione di informazioni da Wikidata e il confronto per la validazione:\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from transformers import pipeline\
from wikidata.client import Client\
import spacy\
\
# Inizializza il modello di sentiment analysis\
classifier = pipeline('sentiment-analysis')\
\
# Inizializza il client Wikidata\
client = Client()\
\
# Carica il modello NER di SpaCy\
nlp = spacy.load("en_core_web_sm")\
\
# Frase da analizzare\
frase = "Gli italiani sono rumorosi."\
\
# Identificare il bias (usando sentiment analysis come proxy per il bias)\
risultato_bias = classifier(frase)\
print(f"Risultato bias: \{risultato_bias\}")\
\
# Eseguire Named Entity Recognition (NER) per estrarre entit\'e0\
doc = nlp(frase)\
for ent in doc.ents:\
    print(f"Entit\'e0 trovata: \{ent.text\}, Tipo: \{ent.label_\}")\
    \
    # Se l'entit\'e0 \'e8 una nazionalit\'e0, cerchiamo su Wikidata\
    if ent.label_ == "NORP":  # NORP significa Nationalities, Religious, Political Groups\
        entita_cercata = ent.text\
        risultato = client.search(entita_cercata)\
        if risultato:\
            entita_wikidata = client.get(risultato[0]['id'], load=True)\
            descrizione = entita_wikidata.description\
            print(f"Descrizione oggettiva di \{entita_cercata\} su Wikidata: \{descrizione\}")\
            \
            # Confrontare la descrizione oggettiva con la frase\
            if "rumorosi" in frase.lower():\
                print(f"La frase potrebbe contenere un bias: '\{frase\}'.")\
                print(f"La descrizione di Wikidata su '\{entita_cercata\}' \'e8: '\{descrizione\}'")\
                print("Il pregiudizio non \'e8 supportato dalla descrizione oggettiva, quindi \'e8 probabile che sia uno stereotipo.")\
            else:\
                print("La frase non sembra contenere stereotipi evidenti.")\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 In questo flusso:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls56\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Identifichi potenziali bias nella frase.\
\ls56\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Utilizzi Wikidata per ottenere descrizioni neutre dell'entit\'e0 (ad esempio, 
\f0\b Italians
\f1\b0 ).\
\ls56\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confronti il bias trovato con la descrizione oggettiva di Wikidata per validare o confutare il pregiudizio.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questo approccio combina tecniche NLP e le ontologie di Wikidata per fornire un metodo solido di 
\f0\b validazione dei bias
\f1\b0  trovati nelle frasi, confrontando stereotipi con dati strutturati e oggettivi.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 perch\'e8 \'e8 utile Integrazione con Ontologie per Inferenze Automatiche: Utilizzando RDF e ontologie, puoi arricchire il confronto tra bias e descrizioni oggettive. Ad esempio, se "Italians" \'e8 collegato a "Europeans" tramite la relazione subclass of, puoi estendere il controllo per bias che si applicano a pi\'f9 entit\'e0 collegate. ai fini di rilevare il bias\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 L'
\f0\b integrazione con ontologie per inferenze automatiche
\f1\b0  \'e8 estremamente utile per il rilevamento del 
\f0\b bias
\f1\b0  perch\'e9 permette di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls57\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ampliare il contesto semantico
\f1\b0  di ci\'f2 che viene detto in una frase, andando oltre il singolo termine o entit\'e0 menzionata.\
\ls57\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fare inferenze
\f1\b0  su concetti collegati che potrebbero non essere espliciti nella frase, ma sono rilevanti dal punto di vista semantico.\
\ls57\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Applicare il rilevamento del bias a un livello pi\'f9 generale
\f1\b0 : Se un bias viene rilevato per un'entit\'e0, come un gruppo etnico, le ontologie ti permettono di inferire che bias simili possono essere applicati ad altri gruppi correlati (ad esempio, se "Italians" ha un bias, potrebbe esserci anche un bias per altri "Europeans").\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Cos'\'e8 l'inferenza semantica?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'
\f0\b inferenza semantica
\f1\b0  sfrutta le relazioni tra entit\'e0 e concetti all'interno di un'ontologia per generare nuove informazioni o scoprire conoscenze che non sono immediatamente evidenti dal contenuto esplicito. In RDF e OWL (Ontology Web Language), le entit\'e0 sono collegate tra loro attraverso relazioni come 
\f0\b subClassOf
\f1\b0 , 
\f0\b partOf
\f1\b0 , 
\f0\b relatedTo
\f1\b0 , ecc. Questo permette di fare ragionamenti automatici su come i concetti si collegano e di rilevare correlazioni nascoste.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio con Italians ed Europeans:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls58\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Se una frase biasata contiene il concetto di 
\f0\b "Italians"
\f1\b0  (ad esempio, "Gli italiani sono rumorosi"), puoi usare l'ontologia per vedere che 
\f0\b "Italians"
\f1\b0  \'e8 una sottoclasse di 
\f0\b "Europeans"
\f1\b0 . Questo ti permette di inferire che il bias espresso nella frase potrebbe estendersi a un livello pi\'f9 generale per includere altre nazionalit\'e0 europee, anche se non sono menzionate esplicitamente.\
\ls58\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 L'ontologia potrebbe contenere la relazione 
\f0\b Italians
\f1\b0  
\f0\b subClassOf
\f1\b0  
\f0\b Europeans
\f1\b0 . In questo modo, se rilevi un bias contro gli 
\f0\b Italians
\f1\b0 , puoi considerare che lo stesso bias potrebbe essere applicato a 
\f0\b "Europeans"
\f1\b0 , oppure verificare se lo stereotipo \'e8 presente in altre sottoclassi di "Europeans" come "French", "Spanish", ecc.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Perch\'e9 \'e8 utile per rilevare il bias?\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 1. Generalizzazione del bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Se il bias \'e8 rilevato su un'entit\'e0 specifica, come 
\f0\b "Italians"
\f1\b0 , puoi generalizzare quel bias ad altre entit\'e0 correlate grazie alle relazioni ontologiche. Ad esempio, se rilevi che esiste un bias contro "Italians" che li descrive come "rumorosi", potresti scoprire che lo stesso tipo di bias esiste anche contro altre nazionalit\'e0 europee come i "Spanish" o i "Greeks". Questo ti consente di catturare bias che potrebbero non essere espliciti nella frase ma che sono impliciti in base alle relazioni concettuali.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 :\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls59\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase: 
\f0\b "Gli italiani sono rumorosi."
\f1\b0 \
\ls59\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazione ontologica: 
\f0\b Italians
\f1\b0  \'e8 una 
\f0\b sottoclasse
\f1\b0  di 
\f0\b Europeans
\f1\b0 .\
\ls59\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza: Il bias di "rumorosit\'e0" potrebbe applicarsi non solo agli Italiani, ma anche ad altre nazionalit\'e0 europee, perch\'e9 c'\'e8 una relazione tra 
\f0\b Italians
\f1\b0  e 
\f0\b Europeans
\f1\b0  nell'ontologia.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 2. Rilevamento di bias impliciti\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Alcuni bias potrebbero non essere menzionati direttamente, ma possono essere impliciti a causa delle relazioni tra concetti. Le ontologie ti aiutano a scoprire questi 
\f0\b bias nascosti
\f1\b0  o impliciti, facendo ragionamenti su concetti correlati. Ad esempio, se una frase fa riferimento ai "dottori" con un bias di genere (es. "I dottori sono sempre uomini"), puoi inferire che il bias potrebbe applicarsi anche ad altre professioni storicamente maschili (ad esempio, ingegneri, avvocati) perch\'e9 esistono relazioni semantiche tra le professioni.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 :\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls60\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase: 
\f0\b "I dottori sono sempre uomini."
\f1\b0 \
\ls60\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazione ontologica: 
\f0\b Doctors
\f1\b0  appartiene alla classe pi\'f9 generale di 
\f0\b Professionals
\f1\b0 , e storicamente, molte altre professioni (es. 
\f0\b Lawyers
\f1\b0 , 
\f0\b Engineers
\f1\b0 ) erano dominate da uomini.\
\ls60\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza: Potresti estendere l'analisi a professioni simili per verificare se lo stesso bias di genere \'e8 applicato anche ad altre professioni.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 3. Validazione del bias contro entit\'e0 correlate\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Se stai verificando la presenza di bias verso una determinata entit\'e0, come "Italians", e scopri che c'\'e8 una relazione con altre entit\'e0 (come "Europeans"), puoi confrontare la validit\'e0 del bias per queste altre entit\'e0. Ad esempio, se un bias sugli italiani viene identificato come "rumorosi", ma tale bias non esiste per altre nazionalit\'e0 europee nella tua analisi o nelle descrizioni di Wikidata, puoi concludere che il bias potrebbe essere specifico solo per una certa nazionalit\'e0, anzich\'e9 applicabile all'intero gruppo.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 4. Supporto alle inferenze basate sui concetti astratti\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Molte ontologie includono concetti pi\'f9 astratti, come 
\f0\b pregiudizi culturali
\f1\b0 , 
\f0\b bias di genere
\f1\b0 , o 
\f0\b stereotipi sociali
\f1\b0 . Utilizzando queste relazioni, puoi verificare se una determinata affermazione biasata su una professione o un gruppo etnico appartiene a un bias culturale pi\'f9 ampio. Ad esempio, se una frase biasata fa riferimento a un comportamento stereotipato come "essere pigro", potresti inferire che questo appartiene a una categoria pi\'f9 ampia di 
\f0\b stereotipi sociali
\f1\b0  che coinvolgono varie classi di persone.\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Esempio
\f1\b0 :\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls61\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase: 
\f0\b "I dottori italiani sono pigri."
\f1\b0 \
\ls61\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazione ontologica: 
\f0\b Italians
\f1\b0  appartengono a 
\f0\b Europeans
\f1\b0 , mentre 
\f0\b Doctors
\f1\b0  appartengono a 
\f0\b Professionals
\f1\b0 . Inoltre, "pigro" pu\'f2 essere collegato a 
\f0\b stereotipi sociali
\f1\b0  in una classe pi\'f9 astratta.\
\ls61\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza: L'affermazione potrebbe essere un esempio di uno 
\f0\b stereotipo culturale
\f1\b0  pi\'f9 ampio, che si applica non solo ai dottori italiani, ma anche ad altre professioni o gruppi nazionali.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Implementazione pratica in Python con RDF e OWL\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per mettere in pratica questo concetto, possiamo costruire relazioni ontologiche usando 
\f0\b RDF
\f1\b0  o 
\f0\b OWL
\f1\b0  e sfruttare strumenti per inferenza semantica, come 
\f0\b rdflib
\f1\b0 .\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio di come costruire relazioni ontologiche per fare inferenze\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from rdflib import Graph, Literal, RDF, URIRef, Namespace\
\
# Creare un namespace per le ontologie\
BIASES = Namespace("http://example.org/biases#")\
\
# Creare un grafo RDF\
g = Graph()\
\
# Definire entit\'e0 e relazioni\
italians_uri = URIRef(BIASES.Italians)\
europeans_uri = URIRef(BIASES.Europeans)\
spanish_uri = URIRef(BIASES.Spanish)\
\
# Relazione: Italians \'e8 una sottoclasse di Europeans\
g.add((italians_uri, RDF.type, europeans_uri))\
g.add((spanish_uri, RDF.type, europeans_uri))\
\
# Definire lo stereotipo (bias)\
noisy_uri = URIRef(BIASES.noisy)\
\
# Aggiungere lo stereotipo a Italians\
g.add((italians_uri, BIASES.hasStereotype, noisy_uri))\
\
# Salvare l'ontologia\
g.serialize("ontology_with_bias.ttl", format="turtle")\
\
# Visualizzare l'ontologia arricchita\
print(g.serialize(format="turtle").decode("utf-8"))\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs24 \cf0 \strokec2 Output Turtle
\f1\b0 :\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 turtle\
\
@prefix biases: <http://example.org/biases#> .\
\
biases:Italians a biases:Europeans ;\
    biases:hasStereotype biases:noisy .\
\
biases:Spanish a biases:Europeans .\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo esempio:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls62\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Abbiamo definito che 
\f0\b Italians
\f1\b0  e 
\f0\b Spanish
\f1\b0  sono entrambi sottoclassi di 
\f0\b Europeans
\f1\b0 .\
\ls62\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Abbiamo collegato lo stereotipo 
\f0\b noisy
\f1\b0  agli 
\f0\b Italians
\f1\b0 .\
\ls62\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un motore di inferenza semantica potrebbe utilizzare questa ontologia per fare deduzioni sui bias applicabili anche ad altre entit\'e0 correlate, come gli 
\f0\b Spanish
\f1\b0 .\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Utilizzo dell'inferenza semantica con OWL e RDF\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Puoi utilizzare motori di inferenza come 
\f0\b HermiT
\f1\b0 , 
\f0\b Pellet
\f1\b0  o 
\f0\b FaCT++
\f1\b0  con OWL per fare inferenze automatiche su concetti correlati, utilizzando ontologie complesse per analizzare i bias in maniera pi\'f9 sofisticata.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio di Inferenza Semantica\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Una volta definita un'ontologia, puoi usare questi strumenti per fare inferenze e rilevare automaticamente bias correlati. Questo aiuta ad ampliare l'analisi e permette di identificare bias che non sono espliciti nella frase ma che possono essere dedotti in base a relazioni concettuali.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'integrazione delle 
\f0\b ontologie
\f1\b0  con tecnologie di 
\f0\b inferenza semantica
\f1\b0  ti consente di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls63\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estendere il rilevamento del bias a concetti correlati che non sono esplicitamente menzionati.\
\ls63\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Scoprire bias impliciti basati sulle relazioni tra concetti.\
\ls63\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Applicare una 
\f0\b generalizzazione
\f1\b0  del bias a livello di gruppo (es. bias contro gli "Italians" potrebbe estendersi agli "Europeans").\
\ls63\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fare inferenze automatiche su concetti astratti come 
\f0\b stereotipi culturali
\f1\b0  o 
\f0\b bias sociali
\f1\b0 , collegando il bias espresso nelle frasi a concetti pi\'f9 generali.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questa tecnica migliora significativamente la capacit\'e0 di rilevare e analizzare bias in testi, combinando l'analisi NLP con il ragionamento semantico fornito dalle ontologie.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 come tornerebbe utile avare embedding multivettoriali partendo da quello sulla frase biasata?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Avere 
\f0\b embedding multivettoriali
\f1\b0  a partire da un singolo embedding di una frase biasata \'e8 una strategia potente che permette di 
\f0\b arricchire l'analisi del bias
\f1\b0  su pi\'f9 livelli, considerando varie dimensioni semantiche del linguaggio. In particolare, questa tecnica consente di rappresentare la frase in termini di pi\'f9 
\f0\b prospettive
\f1\b0  o 
\f0\b aspetti
\f1\b0  (ad esempio, bias etnici, di genere, di classe, ecc.), rendendo l'analisi molto pi\'f9 granulare e precisa. Vediamo in dettaglio perch\'e9 e come questo pu\'f2 essere utile.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Cos'\'e8 un embedding multivettoriale?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Un 
\f0\b embedding multivettoriale
\f1\b0  \'e8 una rappresentazione numerica che non si limita a un singolo vettore, ma utilizza 
\f0\b pi\'f9 vettori
\f1\b0  per catturare 
\f0\b diverse dimensioni
\f1\b0  o aspetti di un concetto, come una frase o una parola. A differenza di un singolo embedding che riduce tutte le informazioni in un solo spazio vettoriale, un embedding multivettoriale consente di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls64\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rappresentare pi\'f9 sfaccettature
\f1\b0  del significato della frase.\
\ls64\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Scomporre le diverse componenti semantiche
\f1\b0  della frase, come il bias di genere, etnia, o religione.\
\ls64\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Integrare pi\'f9 fonti di informazioni
\f1\b0 , come le descrizioni oggettive di Wikidata, contesto culturale, e relazioni ontologiche.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Vantaggi dell'utilizzo di embedding multivettoriali per l'analisi del bias\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rappresentazione multi-dimensionale del bias
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Una frase biasata pu\'f2 contenere 
\f0\b diversi tipi di bias
\f1\b0  contemporaneamente (ad esempio, bias di genere e razziale). Utilizzando un singolo embedding, potresti perdere alcune di queste sfaccettature. Con un embedding multivettoriale, puoi rappresentare separatamente le dimensioni di genere, razza, classe sociale, ecc.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 : La frase "Le donne nere non sono brave in matematica" contiene bias di genere e di razza. Con un embedding multivettoriale, puoi scomporre queste due dimensioni per analizzarle separatamente.\
\ls65\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchimento dell'analisi ontologica
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Puoi combinare il vettore della frase biasata con 
\f0\b altri embedding
\f1\b0 , come quelli provenienti dalle descrizioni di Wikidata o dalle ontologie, per arricchire la comprensione del contesto della frase e dei bias espressi. Questo ti permette di confrontare direttamente la rappresentazione semantica della frase con descrizioni oggettive o strutture ontologiche.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 : Un embedding per "Italians" pu\'f2 essere arricchito con descrizioni estratte da Wikidata, come "popolazione nativa dell'Italia", e con concetti stereotipati come "rumorosi". Avere questi diversi vettori consente di separare il contesto neutrale dal bias.\
\ls65\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inferenza su bias impliciti e correlati
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 L'uso di embedding multivettoriali pu\'f2 facilitare l'identificazione di 
\f0\b bias impliciti
\f1\b0 . Ad esempio, se un vettore rappresenta il bias di genere e un altro rappresenta il contesto storico o culturale, puoi dedurre correlazioni implicite che non sono evidenti solo da una singola dimensione.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 : La frase "I medici uomini sono migliori" pu\'f2 essere rappresentata da un embedding multivettoriale che separa il 
\f0\b bias di genere
\f1\b0  dalla 
\f0\b professione di medico
\f1\b0 , consentendo inferenze pi\'f9 dettagliate su come il bias di genere si manifesta in contesti professionali.\
\ls65\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Combinazione di fonti multiple
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un embedding multivettoriale ti permette di combinare informazioni da 
\f0\b fonti diverse
\f1\b0 . Ad esempio, puoi unire l'
\f0\b embedding della frase
\f1\b0  con un embedding generato dalle 
\f0\b descrizioni di Wikidata
\f1\b0  e con l'
\f0\b embedding delle relazioni ontologiche
\f1\b0  per creare un quadro pi\'f9 completo della frase biasata.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 : Supponiamo di avere una frase come "Gli italiani sono rumorosi" e di voler combinare tre tipi di embedding:\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding semantico della frase
\f1\b0 : Cattura il significato complessivo della frase.\
\ls65\ilvl1
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della descrizione di Wikidata
\f1\b0 : Fornisce una rappresentazione oggettiva del gruppo "Italians" (ad esempio, "popolazione nativa dell'Italia").\
\ls65\ilvl1
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding delle relazioni ontologiche
\f1\b0 : Cattura relazioni come "Italians" \uc0\u8594  "Europeans", per estendere l'analisi a gruppi correlati.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confronto multi-vettoriale per validazione del bias
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls65\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un approccio multivettoriale consente di confrontare i vari aspetti della frase biasata con 
\f0\b rappresentazioni neutrali
\f1\b0  o 
\f0\b ontologiche
\f1\b0 . Puoi confrontare il vettore che rappresenta il bias di genere con il vettore oggettivo derivato da Wikidata per determinare se il bias \'e8 supportato o confutato dai dati reali.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls65\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 : Nella frase "Le donne non sono brave in matematica", puoi creare due vettori separati: uno per il 
\f0\b bias di genere
\f1\b0  e uno per il 
\f0\b contesto educativo
\f1\b0  estratto da Wikidata. Se il vettore educativo non supporta lo stereotipo, puoi concludere che la frase contiene un pregiudizio infondato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Come creare embedding multivettoriali in Python\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per implementare embedding multivettoriali, puoi usare 
\f0\b Sentence-BERT
\f1\b0  per rappresentare la frase biasata e combinare questi vettori con altri embedding generati da dati ontologici o descrizioni di Wikidata.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Passo 1: Creare embedding della frase biasata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Usiamo 
\f0\b Sentence-BERT
\f1\b0  per creare l'embedding della frase biasata.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from sentence_transformers import SentenceTransformer\
\
# Inizializza il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Frase biasata\
frase_biasata = "Gli italiani sono rumorosi."\
\
# Creare l'embedding della frase biasata\
embedding_frase = modello_embedding.encode(frase_biasata)\
\
print("Embedding della frase biasata:", embedding_frase)\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 2: Creare embedding per descrizioni di Wikidata\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora, creiamo embedding per descrizioni oggettive estratte da Wikidata, come la descrizione della nazionalit\'e0 
\f0\b Italians
\f1\b0 .\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from wikidata.client import Client\
\
# Inizializza il client Wikidata\
client = Client()\
\
# Estrazione della descrizione di "Italians"\
italians = client.get('Q50001', load=True)  # ID di Italians\
descrizione_italians = italians.description\
\
# Creare l'embedding per la descrizione da Wikidata\
embedding_descrizione = modello_embedding.encode(descrizione_italians)\
\
print("Embedding della descrizione oggettiva di Italians:", embedding_descrizione)\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 3: Creare embedding per relazioni ontologiche\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Supponiamo di avere una relazione ontologica che collega 
\f0\b Italians
\f1\b0  a 
\f0\b Europeans
\f1\b0 . Possiamo creare un embedding per rappresentare questa relazione.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
relazione_ontologica = "Italians is a subclass of Europeans."\
embedding_relazione = modello_embedding.encode(relazione_ontologica)\
\
print("Embedding della relazione ontologica:", embedding_relazione)\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 4: Combinare gli embedding multivettoriali\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora possiamo combinare i vari embedding (frase biasata, descrizione oggettiva e relazioni ontologiche) in un 
\f0\b embedding multivettoriale
\f1\b0  che rappresenta diversi aspetti della frase.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
import numpy as np\
\
# Combinare gli embedding in un vettore multivettoriale\
embedding_multivettoriale = np.vstack((embedding_frase, embedding_descrizione, embedding_relazione))\
\
print("Embedding multivettoriale:\\n", embedding_multivettoriale)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Utilit\'e0 degli embedding multivettoriali per l'inferenza\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Con questo approccio, puoi fare 
\f0\b inferenze automatiche
\f1\b0  e 
\f0\b confronti semantici
\f1\b0  molto pi\'f9 ricchi. Ad esempio:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls66\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confrontare la frase biasata con la descrizione di Wikidata per 
\f0\b validare o confutare
\f1\b0  il bias.\
\ls66\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Estendere l'analisi a entit\'e0 correlate tramite le relazioni ontologiche (ad esempio, generalizzare bias su "Italians" ad altre nazionalit\'e0 europee).\
\ls66\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Individuare bias impliciti o non espliciti confrontando il significato della frase con relazioni semantiche non direttamente menzionate nel testo.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Gli 
\f0\b embedding multivettoriali
\f1\b0  ti permettono di rappresentare le frasi biasate in modo pi\'f9 complesso e completo. Grazie a questa tecnica, puoi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls67\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Separare le 
\f0\b diverse dimensioni
\f1\b0  del bias.\
\ls67\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Integrare 
\f0\b dati oggettivi
\f1\b0  e 
\f0\b ontologie
\f1\b0  per arricchire l'analisi.\
\ls67\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fare inferenze pi\'f9 dettagliate e precise sui bias impliciti.\
\ls67\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Validare il bias confrontando pi\'f9 prospettive della frase con fonti di conoscenza affidabili come Wikidata e relazioni ontologiche.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questo approccio migliora significativamente la capacit\'e0 di rilevare e analizzare bias in modo accurato e strutturato, sfruttando il meglio delle tecniche di embedding e delle ontologie.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ok come tornerebbe utile anche il clustering gerarchico?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 L'utilizzo del 
\f0\b clustering gerarchico
\f1\b0  nel contesto dell'analisi dei bias \'e8 particolarmente utile per organizzare e raggruppare le frasi biasate in una struttura ad albero, permettendo di identificare non solo 
\f0\b tipi di bias simili
\f1\b0 , ma anche di creare una gerarchia naturale dei bias. Questo approccio ti permette di 
\f0\b organizzare i bias in livelli
\f1\b0 , facilitando l'interpretazione e l'analisi delle frasi in modo pi\'f9 strutturato e stratificato.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Perch\'e9 usare il clustering gerarchico per l'analisi del bias?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Il 
\f0\b clustering gerarchico
\f1\b0  \'e8 una tecnica di 
\f0\b machine learning non supervisionata
\f1\b0  che raggruppa i dati in una struttura ad albero o dendrogramma. Ogni nodo dell'albero rappresenta un gruppo di dati (in questo caso, frasi biasate) e i livelli pi\'f9 alti rappresentano cluster pi\'f9 generali, mentre i livelli inferiori contengono cluster pi\'f9 specifici. Questo \'e8 particolarmente utile per:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls68\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Organizzare i bias in categorie e sottocategorie
\f1\b0 : Il clustering gerarchico pu\'f2 organizzare le frasi biasate in macro-categorie di bias (es. bias di genere, razziale, culturale) e successivamente suddividerle in sottocategorie pi\'f9 specifiche (es. bias contro le donne, bias contro determinate etnie).\
\ls68\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Identificare relazioni tra bias correlati
\f1\b0 : Il clustering gerarchico ti consente di visualizzare come i diversi tipi di bias sono correlati tra loro. Ad esempio, bias di genere e bias di razza possono apparire come cluster separati, ma a un certo livello possono essere raggruppati insieme, suggerendo che esiste una correlazione tra di essi.\
\ls68\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevare bias nascosti o impliciti
\f1\b0 : Poich\'e9 il clustering gerarchico organizza i dati in livelli, puoi scoprire 
\f0\b bias pi\'f9 sottili
\f1\b0  che potrebbero non essere immediatamente visibili, ma che emergono analizzando i livelli pi\'f9 profondi del dendrogramma.\
\ls68\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Visualizzazione intuitiva
\f1\b0 : Il clustering gerarchico genera un dendrogramma che consente una visualizzazione intuitiva della struttura dei bias. Questo \'e8 utile per individuare gruppi di bias correlati e per capire come questi gruppi si connettono tra loro.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Come funziona il clustering gerarchico?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Nel 
\f0\b clustering gerarchico
\f1\b0 , puoi scegliere due approcci principali:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls69\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Agglomerativo
\f1\b0  (dal basso verso l'alto): Ogni punto di partenza (frase biasata) inizia come un singolo cluster e i cluster vengono progressivamente uniti in gruppi pi\'f9 grandi fino a formare un'unica gerarchia.\
\ls69\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Divisivo
\f1\b0  (dall'alto verso il basso): Tutti i dati iniziano come un singolo cluster e vengono suddivisi progressivamente in gruppi pi\'f9 piccoli.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Applicazione pratica del clustering gerarchico per l'analisi del bias\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls70\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Creazione degli embedding delle frasi biasate
\f1\b0 : Prima di eseguire il clustering, dobbiamo rappresentare le frasi biasate come 
\f0\b embedding
\f1\b0  numerici. Utilizzeremo 
\f0\b Sentence-BERT
\f1\b0  per ottenere rappresentazioni semantiche delle frasi.\
\ls70\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esecuzione del clustering gerarchico
\f1\b0 : Utilizzeremo un algoritmo di clustering gerarchico, come 
\f0\b Agglomerative Clustering
\f1\b0 , per raggruppare frasi simili basate sugli embedding.\
\ls70\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Visualizzazione del dendrogramma
\f1\b0 : Utilizzeremo il 
\f0\b dendrogramma
\f1\b0  per visualizzare i cluster e identificare gruppi e sottogruppi di frasi biasate.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Esempio di implementazione del clustering gerarchico in Python\
\pard\pardeftab720\sa332\partightenfactor0

\fs20 \cf0 Passo 1: Creazione degli embedding delle frasi biasate\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Prima di applicare il clustering, creiamo gli embedding per un insieme di frasi biasate.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from sentence_transformers import SentenceTransformer\
import numpy as np\
\
# Inizializzare il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Frasi biasate di esempio\
frasi_biasate = [\
    "Le donne non sono brave in matematica.",\
    "Gli italiani sono rumorosi.",\
    "Gli uomini sono pi\'f9 logici delle donne.",\
    "I musulmani sono pericolosi.",\
    "I dottori sono sempre uomini."\
]\
\
# Creare gli embedding per le frasi biasate\
embedding_frasi = modello_embedding.encode(frasi_biasate)\
\
print("Embedding delle frasi biasate:", embedding_frasi)\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Passo 2: Esecuzione del clustering gerarchico\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Una volta ottenuti gli embedding, possiamo applicare il clustering gerarchico utilizzando 
\f0\b Agglomerative Clustering
\f1\b0  dalla libreria 
\f0\b scikit-learn
\f1\b0 .\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from sklearn.cluster import AgglomerativeClustering\
\
# Applicare il clustering gerarchico\
clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0)\
clustering.fit(embedding_frasi)\
\
# Visualizzare le etichette dei cluster assegnati\
print("Etichette dei cluster:", clustering.labels_)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 In questo caso, 
\f3\b\fs26 \strokec2 n_clusters=None
\f1\b0\fs24 \strokec2  e 
\f3\b\fs26 \strokec2 distance_threshold=0
\f1\b0\fs24 \strokec2  ci permettono di eseguire un clustering gerarchico completo, senza specificare a priori un numero fisso di cluster.\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 \strokec2 Passo 3: Visualizzazione del dendrogramma\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Per visualizzare i risultati del clustering gerarchico, possiamo usare il 
\f0\b dendrogramma
\f1\b0 . Questo ci aiuter\'e0 a vedere come le frasi vengono raggruppate a diversi livelli di similarit\'e0.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from scipy.cluster.hierarchy import dendrogram, linkage\
import matplotlib.pyplot as plt\
\
# Calcolare la matrice di linkage per il dendrogramma\
Z = linkage(embedding_frasi, 'ward')\
\
# Creare il dendrogramma\
plt.figure(figsize=(10, 7))\
plt.title("Dendrogramma del clustering gerarchico delle frasi biasate")\
dendrogram(Z, labels=frasi_biasate, leaf_rotation=90, leaf_font_size=12)\
plt.show()\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs24 \cf0 \strokec2 Output
\f1\b0 : Un dendrogramma che visualizza i cluster delle frasi biasate.\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 \strokec2 Interpretazione del dendrogramma\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Il 
\f0\b dendrogramma
\f1\b0  rappresenta graficamente come le frasi vengono raggruppate:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls71\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Livelli superiori
\f1\b0 : Cluster pi\'f9 generali che potrebbero rappresentare bias di alto livello, come bias di genere o razziale.\
\ls71\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Livelli inferiori
\f1\b0 : Cluster pi\'f9 specifici che raggruppano frasi con bias pi\'f9 simili (ad esempio, frasi con stereotipi simili sugli italiani e sugli spagnoli).\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 Utilit\'e0 del clustering gerarchico nell'analisi del bias\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls72\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Identificazione di macro-categorie di bias
\f1\b0 : Il clustering gerarchico ti permette di identificare 
\f0\b macro-categorie
\f1\b0  di bias, come il bias di genere o etnico. Questi cluster possono essere ulteriormente suddivisi per rivelare sottogruppi pi\'f9 specifici (es. bias contro le donne o contro una specifica nazionalit\'e0).\uc0\u8232 
\f0\b Esempio
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls72\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un livello superiore del dendrogramma potrebbe identificare un gruppo di frasi che esprimono bias di genere.\
\ls72\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un livello inferiore pu\'f2 distinguere tra bias contro le donne e bias contro gli uomini.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls72\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevamento di bias impliciti e correlati
\f1\b0 : Alcune frasi possono essere posizionate vicino ad altre nel dendrogramma, suggerendo che potrebbero condividere uno 
\f0\b stesso bias implicito
\f1\b0 . Ad esempio, se una frase sul 
\f0\b genere
\f1\b0  \'e8 raggruppata con una frase su una 
\f0\b professione
\f1\b0 , ci\'f2 potrebbe suggerire che la professione \'e8 influenzata dal bias di genere.\uc0\u8232 
\f0\b Esempio
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls72\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frasi come "I medici sono sempre uomini" e "Le donne non sono brave in matematica" possono essere raggruppate vicine, suggerendo che esiste un bias comune riguardo alle capacit\'e0 professionali basato sul genere.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls72\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Visualizzazione intuitiva dei gruppi di bias
\f1\b0 : Il dendrogramma fornisce una 
\f0\b rappresentazione visiva
\f1\b0  dei gruppi di bias, che pu\'f2 essere particolarmente utile per esplorare come i vari tipi di bias si collegano tra loro. Questo \'e8 utile quando si cerca di capire le relazioni tra stereotipi diversi.\
\ls72\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generalizzazione delle categorie di bias
\f1\b0 : I cluster a livelli superiori possono rappresentare 
\f0\b categorie generali di bias
\f1\b0  (es. bias culturale), mentre i livelli inferiori possono rappresentare bias pi\'f9 specifici (es. bias contro gli italiani). Questo consente di fare inferenze su bias applicabili a gruppi correlati.\uc0\u8232 
\f0\b Esempio
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls72\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Un bias su "gli italiani sono rumorosi" pu\'f2 essere generalizzato a "gli europei del sud sono rumorosi" se altre nazionalit\'e0 simili sono incluse nello stesso cluster.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Il 
\f0\b clustering gerarchico
\f1\b0  offre diversi vantaggi nell'analisi dei bias:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls73\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Organizza i bias in 
\f0\b livelli gerarchici
\f1\b0 , permettendo di distinguere tra bias generali e specifici.\
\ls73\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aiuta a identificare 
\f0\b bias correlati
\f1\b0  e 
\f0\b impliciti
\f1\b0  che possono emergere nei cluster pi\'f9 profondi.\
\ls73\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fornisce una 
\f0\b visualizzazione chiara
\f1\b0  del modo in cui i bias si relazionano tra loro, grazie all'uso del 
\f0\b dendrogramma
\f1\b0 .\
\ls73\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Consente di fare inferenze su 
\f0\b bias generalizzati
\f1\b0  e di creare categorie di bias a vari livelli di granularit\'e0.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Insieme agli 
\f0\b embedding multivettoriali
\f1\b0 , il clustering gerarchico pu\'f2 migliorare significativamente la capacit\'e0 di rilevare, analizzare e strutturare i bias, fornendo uno strumento potente per l'analisi delle frasi biasate.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 puo tornare utile poi addestrare una rete avversaria grazie questi embedding multivettoriali ai fini di usarla come strumento per poterlo mitigare o rilevare su nuove frasi?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 S\'ec, 
\f0\b addestrare una rete avversaria (GAN, Generative Adversarial Network)
\f1\b0  utilizzando gli 
\f0\b embedding multivettoriali
\f1\b0  pu\'f2 essere estremamente utile sia per 
\f0\b rilevare
\f1\b0  che per 
\f0\b mitigare il bias
\f1\b0  su nuove frasi. L'idea di usare una 
\f0\b rete avversaria
\f1\b0  in questo contesto pu\'f2 essere sfruttata in modo creativo per:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls74\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generare frasi
\f1\b0  con potenziale bias per migliorare la capacit\'e0 di rilevamento del bias.\
\ls74\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Allenare un rilevatore di bias
\f1\b0  migliorato, che apprenda sia dalle frasi reali che da quelle sintetiche generate dall'avversaria.\
\ls74\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigare il bias
\f1\b0  identificando le caratteristiche delle frasi biasate e producendo versioni "non biasate" delle frasi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Perch\'e9 le GAN sono utili per il rilevamento e la mitigazione del bias?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Le GAN sono costituite da due reti:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls75\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generatore
\f1\b0 : Cerca di generare esempi (in questo caso, frasi) che siano il pi\'f9 simili possibile a quelli reali.\
\ls75\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Discriminatore
\f1\b0 : Cerca di distinguere tra frasi reali (biasate) e frasi sintetiche (generate).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Nel contesto dell'
\f0\b analisi del bias
\f1\b0 , le 
\f0\b GAN
\f1\b0  possono essere utilizzate per 
\f0\b migliorare la rilevazione del bias
\f1\b0  e anche per 
\f0\b proporre strategie di mitigazione
\f1\b0  attraverso questi meccanismi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls76\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevamento del bias
\f1\b0 : Il discriminatore pu\'f2 essere allenato a rilevare il bias nelle frasi (incluse quelle generate dal generatore). Il generatore cercher\'e0 di ingannare il discriminatore, migliorando la capacit\'e0 del discriminatore di distinguere tra frasi biasate e non biasate.\
\ls76\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione del bias
\f1\b0 : Il generatore pu\'f2 essere allenato a generare frasi "neutre" o "non biasate", sfruttando gli embedding multivettoriali che catturano diverse dimensioni del bias. Il generatore pu\'f2 produrre versioni modificate delle frasi, mitigando i pregiudizi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Approccio per addestrare una GAN con embedding multivettoriali per rilevare e mitigare il bias\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls77\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generazione di embedding multivettoriali
\f1\b0 : Usa gli embedding multivettoriali delle frasi biasate per rappresentare separatamente le diverse dimensioni del bias (es. bias di genere, etnia, religione). Questi embedding verranno utilizzati sia per l'addestramento del generatore che del discriminatore.\
\ls77\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Addestramento della GAN
\f1\b0 : Il 
\f0\b generatore
\f1\b0  cercher\'e0 di creare frasi sintetiche basate sugli embedding multivettoriali, mentre il 
\f0\b discriminatore
\f1\b0  cercher\'e0 di distinguere le frasi reali (biasate) da quelle generate.\
\ls77\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevamento del bias
\f1\b0 : Dopo l'addestramento, il discriminatore potr\'e0 essere utilizzato come strumento per 
\f0\b rilevare bias
\f1\b0  su nuove frasi. Potr\'e0 identificare se una frase \'e8 biasata in base agli embedding multivettoriali delle dimensioni del bias.\
\ls77\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione del bias
\f1\b0 : Il generatore potr\'e0 essere utilizzato per 
\f0\b mitigare il bias
\f1\b0  generando nuove frasi, partendo dagli embedding multivettoriali e cercando di rimuovere o attenuare il bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Passaggi per implementare una GAN per rilevare e mitigare il bias\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 Passo 1: Preparare gli embedding multivettoriali delle frasi biasate\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Il primo passo \'e8 preparare gli embedding multivettoriali delle frasi biasate, separando le dimensioni del bias. Come abbiamo visto in precedenza, possiamo ottenere gli embedding multivettoriali usando 
\f0\b Sentence-BERT
\f1\b0  per rappresentare le frasi e arricchirle con altre informazioni, come descrizioni da 
\f0\b Wikidata
\f1\b0  o relazioni ontologiche.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
from sentence_transformers import SentenceTransformer\
import numpy as np\
\
# Inizializzare il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Frasi biasate di esempio\
frasi_biasate = [\
    "Le donne non sono brave in matematica.",\
    "Gli italiani sono rumorosi.",\
    "Gli uomini sono pi\'f9 logici delle donne.",\
    "I musulmani sono pericolosi.",\
    "I dottori sono sempre uomini."\
]\
\
# Creare gli embedding per le frasi biasate\
embedding_frasi = modello_embedding.encode(frasi_biasate)\
\
# Simuliamo embedding multivettoriali aggiungendo embedding di descrizioni di Wikidata e relazioni ontologiche\
embedding_descrizioni = np.random.rand(len(frasi_biasate), 384)  # Simuliamo con numeri casuali\
embedding_relazioni = np.random.rand(len(frasi_biasate), 384)  # Simuliamo con numeri casuali\
\
# Combinare gli embedding multivettoriali\
embedding_multivettoriali = np.hstack((embedding_frasi, embedding_descrizioni, embedding_relazioni))\
\
print("Embedding multivettoriali:\\n", embedding_multivettoriali)\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 2: Costruire una GAN con Keras per rilevare il bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora possiamo costruire una 
\f0\b GAN
\f1\b0 . Useremo la libreria 
\f0\b Keras
\f1\b0  per implementare il generatore e il discriminatore. Il generatore produrr\'e0 embedding che cercano di sembrare reali, mentre il discriminatore cercher\'e0 di distinguere tra gli embedding reali (frasi biasate) e quelli sintetici.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 bash\
\
pip install tensorflow keras\
python\
\
from keras.models import Sequential\
from keras.layers import Dense, LeakyReLU\
import numpy as np\
\
# Dimensione degli embedding multivettoriali\
input_dim = embedding_multivettoriali.shape[1]\
\
# Creare il Generatore\
def build_generator():\
    model = Sequential()\
    model.add(Dense(256, input_dim=100))  # Input casuale per generare embedding\
    model.add(LeakyReLU(alpha=0.01))\
    model.add(Dense(input_dim, activation='tanh'))  # Output: embedding multivettoriale\
    return model\
\
# Creare il Discriminatore\
def build_discriminator():\
    model = Sequential()\
    model.add(Dense(256, input_dim=input_dim))\
    model.add(LeakyReLU(alpha=0.01))\
    model.add(Dense(1, activation='sigmoid'))  # Output: probabilit\'e0 che sia reale o generato\
    return model\
\
# Inizializzare il generatore e il discriminatore\
generator = build_generator()\
discriminator = build_discriminator()\
\
# Compilare il discriminatore\
discriminator.compile(optimizer='adam', loss='binary_crossentropy')\
\
# Creare la GAN combinata\
discriminator.trainable = False  # Durante l'addestramento della GAN, il discriminatore non deve aggiornarsi\
gan = Sequential([generator, discriminator])\
\
# Compilare la GAN\
gan.compile(optimizer='adam', loss='binary_crossentropy')\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 3: Addestrare la GAN\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Adesso addestriamo la GAN. Generiamo 
\f0\b embedding sintetici
\f1\b0  dal generatore e confrontiamoli con quelli reali (le frasi biasate) per addestrare il discriminatore a distinguere tra frasi biasate e frasi neutrali.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Definire i parametri di addestramento\
epochs = 10000\
batch_size = 32\
half_batch = batch_size // 2\
\
# Iniziamo il processo di addestramento\
for epoch in range(epochs):\
    # 1. Addestrare il discriminatore\
    idx = np.random.randint(0, embedding_multivettoriali.shape[0], half_batch)\
    real_embeddings = embedding_multivettoriali[idx]\
\
    # Generare embedding sintetici\
    noise = np.random.normal(0, 1, (half_batch, 100))\
    fake_embeddings = generator.predict(noise)\
\
    # Addestrare il discriminatore (reale: 1, sintetico: 0)\
    d_loss_real = discriminator.train_on_batch(real_embeddings, np.ones((half_batch, 1)))\
    d_loss_fake = discriminator.train_on_batch(fake_embeddings, np.zeros((half_batch, 1)))\
\
    # 2. Addestrare la GAN (etichetta "reale" per il generatore)\
    noise = np.random.normal(0, 1, (batch_size, 100))\
    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\
\
    # Stampa i progressi\
    if epoch % 1000 == 0:\
        print(f"Epoch \{epoch\}, D Loss: \{d_loss_real + d_loss_fake\}, G Loss: \{g_loss\}")\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Passo 4: Utilizzare la GAN per rilevare e mitigare il bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Dopo aver addestrato la GAN, possiamo utilizzare il 
\f0\b discriminatore
\f1\b0  per rilevare il bias nelle frasi nuove e il 
\f0\b generatore
\f1\b0  per generare versioni neutrali o mitigate delle frasi biasate.\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 \strokec2 Rilevamento del bias\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
# Rilevare bias su una nuova frase\
nuova_frase = "Le donne non dovrebbero fare lavori tecnici."\
embedding_nuova_frase = modello_embedding.encode([nuova_frase])\
\
# Simulare embedding multivettoriali per la nuova frase\
embedding_descrizione = np.random.rand(1, 384)  # Simuliamo\
embedding_relazione = np.random.rand(1, 384)  # Simuliamo\
embedding_multivettoriale_nuova_frase = np.hstack((embedding_nuova_frase, embedding_descrizione, embedding_relazione))\
\
# Usare il discriminatore per rilevare il bias\
prob_bias = discriminator.predict(embedding_multivettoriale_nuova_frase)\
print(f"Probabilit\'e0 che la frase sia biasata: \{prob_bias\}")\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Mitigazione del bias\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Usiamo il 
\f0\b generatore
\f1\b0  per generare frasi non biasate basate sugli embedding multivettoriali.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Generare una versione mitigata di una frase biasata\
noise = np.random.normal(0, 1, (1, 100))\
embedding_sintetico = generator.predict(noise)\
\
print("Embedding sintetico generato:", embedding_sintetico)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'uso di 
\f0\b embedding multivettoriali
\f1\b0  combinati con una 
\f0\b rete avversaria (GAN)
\f1\b0  \'e8 una tecnica avanzata che:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls78\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Migliora il rilevamento del bias
\f1\b0 : Il discriminatore diventa molto abile a distinguere frasi biasate da frasi neutre.\
\ls78\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitiga il bias
\f1\b0 : Il generatore pu\'f2 essere utilizzato per produrre versioni neutrali delle frasi, riducendo o eliminando i pregiudizi.\
\ls78\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Genera frasi sintetiche per allenare modelli migliori
\f1\b0 : L'utilizzo delle GAN permette di generare nuove frasi che simulano i bias, migliorando il dataset per futuri modelli di rilevamento.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questa combinazione di 
\f0\b embedding multivettoriali
\f1\b0  e GAN offre una soluzione potente per il rilevamento e la mitigazione dei bias nelle frasi, rendendo l'analisi pi\'f9 completa e strutturata.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 quindi il dataset di addestramento parte dei multivettori combinati con frase biasata, descrizione oggettiva e relazioni ontologiche?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 S\'ec, esattamente! Il 
\f0\b dataset di addestramento
\f1\b0  per la 
\f0\b rete avversaria
\f1\b0  (GAN) che stiamo creando pu\'f2 essere composto da 
\f0\b multivettori
\f1\b0  che combinano diverse informazioni:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls79\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della frase biasata
\f1\b0 : Rappresentazione semantica della frase originale contenente il bias.\
\ls79\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della descrizione oggettiva
\f1\b0 : Rappresentazione semantica della descrizione neutra e oggettiva della stessa entit\'e0 o concetto estratta da una fonte come 
\f0\b Wikidata
\f1\b0 .\
\ls79\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding delle relazioni ontologiche
\f1\b0 : Rappresentazione delle relazioni concettuali e semantiche collegate all'entit\'e0, come quelle tra categorie generali e specifiche (ad esempio, 
\f0\b Italians
\f1\b0  come sottoclasse di 
\f0\b Europeans
\f1\b0 ).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Questa 
\f0\b combinazione di embedding
\f1\b0  consente alla GAN di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls80\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevare il bias
\f1\b0 : Allenando il discriminatore a riconoscere frasi biasate confrontate con rappresentazioni oggettive.\
\ls80\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigare il bias
\f1\b0 : Allenando il generatore a creare frasi meno biasate, apprendendo dalle differenze tra frasi reali e descrizioni neutre.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Struttura del dataset di addestramento\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Il dataset che fornirai alla GAN avr\'e0 quindi la seguente struttura:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls81\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della frase biasata
\f1\b0 : Un vettore che rappresenta semanticamente la frase che potrebbe contenere un bias.\
\ls81\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della descrizione oggettiva
\f1\b0 : Un vettore che rappresenta le informazioni neutre e oggettive sulla stessa entit\'e0 o concetto.\
\ls81\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding delle relazioni ontologiche
\f1\b0 : Un vettore che descrive le relazioni concettuali tra entit\'e0 collegate (es. subclass, relatedTo).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Combinando questi vettori, ottieni un 
\f0\b multivettore
\f1\b0 , che sar\'e0 l'input per il generatore e il discriminatore della GAN. Durante l'addestramento, la GAN imparer\'e0 a distinguere tra le frasi biasate e le loro versioni neutrali o mitigate, creando un sistema robusto per il rilevamento e la mitigazione del bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Esempio concreto di dataset multivettoriale\
\pard\pardeftab720\sa319\partightenfactor0

\fs24 \cf0 \strokec2 1. Frase biasata:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls82\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio: "Le donne non sono brave in matematica."\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls82\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della frase: Rappresenta semanticamente il contenuto della frase.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 2. Descrizione oggettiva (da Wikidata):\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls83\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio: Descrizione per "donne" su Wikidata: "Adulti di sesso femminile."\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls83\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della descrizione: Rappresenta semanticamente la descrizione neutra delle donne.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 3. Relazioni ontologiche:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls84\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio: Relazione ontologica tra "donne" e "umani", o "donne" e "scienziati".\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls84\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Embedding della relazione ontologica: Rappresenta la connessione concettuale tra "donne" e la classe di umani o professionisti della scienza.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Dataset multivettoriale combinato\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per ogni esempio di frase biasata, combinerai questi 
\f0\b tre vettori
\f1\b0  in un 
\f0\b multivettore
\f1\b0  che rappresenta la frase, la descrizione oggettiva e le relazioni ontologiche.\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
import numpy as np\
\
# Esempi di frasi biasate\
frasi_biasate = [\
    "Le donne non sono brave in matematica.",\
    "Gli italiani sono rumorosi.",\
    "I musulmani sono violenti."\
]\
\
# Embedding simulato per le frasi biasate, descrizioni oggettive e relazioni ontologiche\
embedding_frasi_biasate = np.random.rand(len(frasi_biasate), 384)  # Embedding delle frasi biasate\
embedding_descrizioni = np.random.rand(len(frasi_biasate), 384)  # Embedding delle descrizioni da Wikidata\
embedding_relazioni = np.random.rand(len(frasi_biasate), 384)  # Embedding delle relazioni ontologiche\
\
# Combinare gli embedding per ottenere il multivettore\
embedding_multivettoriale = np.hstack((embedding_frasi_biasate, embedding_descrizioni, embedding_relazioni))\
\
print("Dataset multivettoriale per l'addestramento:\\n", embedding_multivettoriale)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Addestramento della GAN\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Durante l'addestramento della GAN:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls85\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Il generatore
\f1\b0  cerca di creare frasi basate su questi multivettori che sembrano reali (biasate), ma cerca anche di ingannare il discriminatore producendo frasi meno biasate.\
\ls85\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Il discriminatore
\f1\b0  cerca di distinguere tra i multivettori reali (frasi biasate) e quelli generati (frasi mitigate).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 L'obiettivo \'e8 che il discriminatore diventi sempre pi\'f9 accurato nel riconoscere i bias e che il generatore impari a creare frasi che siano 
\f0\b meno biasate
\f1\b0  o addirittura 
\f0\b neutre
\f1\b0 , basate sui multivettori.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Vantaggi di usare i multivettori per il rilevamento e la mitigazione del bias\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls86\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Informazioni contestuali arricchite
\f1\b0 : Usando pi\'f9 vettori, la GAN pu\'f2 apprendere non solo dalla frase, ma anche dal contesto oggettivo e dalle relazioni concettuali, migliorando la capacit\'e0 di rilevare bias che non sono immediatamente evidenti.\
\ls86\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Maggiore accuratezza nel rilevamento
\f1\b0 : Il discriminatore sar\'e0 in grado di fare confronti pi\'f9 completi tra una frase biasata e la sua rappresentazione neutrale, migliorando la sua capacit\'e0 di rilevare bias in frasi nuove.\
\ls86\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione avanzata
\f1\b0 : Il generatore sar\'e0 in grado di apprendere come produrre frasi meno biasate, utilizzando le descrizioni oggettive e le relazioni ontologiche per guidare la generazione di frasi meno pregiudizievoli.\
\ls86\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Modellazione pi\'f9 complessa dei bias
\f1\b0 : L'uso dei multivettori consente alla GAN di modellare bias che coinvolgono pi\'f9 dimensioni (es. genere, razza, cultura), offrendo una visione pi\'f9 sfumata e dettagliata del problema del bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Addestrare una 
\f0\b rete avversaria (GAN)
\f1\b0  utilizzando un 
\f0\b dataset di multivettori
\f1\b0  che combina:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls87\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frasi biasate
\f1\b0 ,\
\ls87\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Descrizioni oggettive
\f1\b0  (da Wikidata o altre fonti),\
\ls87\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazioni ontologiche
\f1\b0 ,\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 \'e8 una strategia efficace per 
\f0\b rilevare
\f1\b0  e 
\f0\b mitigare il bias
\f1\b0  nelle frasi. Questo approccio sfrutta le diverse dimensioni semantiche fornite dai multivettori per fornire un rilevamento pi\'f9 accurato e una mitigazione pi\'f9 sofisticata del bias, creando un sistema robusto che pu\'f2 essere applicato anche a frasi nuove e non precedentemente viste.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 pu\'f2 aver senso avere anche l'embedding relativo alla descrizione di predicati, avverbi ed aggettivi nel multivettore?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 S\'ec, 
\f0\b ha assolutamente senso includere anche l'embedding relativo a predicati, avverbi e aggettivi
\f1\b0  nel multivettore! Questo approccio ti permette di catturare in modo ancora pi\'f9 accurato i 
\f0\b dettagli semantici
\f1\b0  che possono contribuire al bias di una frase. L'analisi di 
\f0\b predicati
\f1\b0 , 
\f0\b avverbi
\f1\b0  e 
\f0\b aggettivi
\f1\b0  \'e8 cruciale perch\'e9 questi elementi del linguaggio sono spesso i 
\f0\b portatori primari del bias
\f1\b0 . Aggiungendo gli embedding relativi a questi elementi, il 
\f0\b multivettore
\f1\b0  diventa una rappresentazione ancora pi\'f9 ricca e completa della frase biasata.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Perch\'e9 includere predicati, avverbi e aggettivi \'e8 utile?\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls88\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Portatori principali del bias
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Predicati
\f1\b0  (verbi e ci\'f2 che essi esprimono) spesso definiscono le azioni o qualit\'e0 che vengono attribuite alle entit\'e0 e possono essere pregiudizievoli.\
\ls88\ilvl1
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggettivi
\f1\b0  sono spesso usati per esprimere opinioni stereotipate o negative nei confronti di un soggetto o gruppo.\
\ls88\ilvl1
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avverbi
\f1\b0  possono intensificare o attenuare il bias, dando maggiore enfasi alle affermazioni stereotipate.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls88\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase
\f1\b0 : "Le donne 
\f0\b non
\f1\b0  sono 
\f0\b brave
\f1\b0  in matematica."\
\pard\tx1660\tx2160\pardeftab720\li2160\fi-2160\partightenfactor0
\ls88\ilvl2
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9642 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Predicato
\f1\b0 : "sono brave"\
\ls88\ilvl2
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9642 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggettivo
\f1\b0 : "brave"\
\ls88\ilvl2
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9642 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avverbio
\f1\b0 : "non"\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Qui, il predicato "sono brave" \'e8 modificato dall'avverbio "non", che trasforma la frase in un'affermazione negativa e stereotipata. L'inclusione di embedding specifici per queste componenti consente al modello di comprendere come certe parole possono alterare il significato di una frase e introdurre bias.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls88\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Maggiore granularit\'e0 e precisione
\f1\b0  nel rilevamento del bias:\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Considerare predicati, avverbi e aggettivi ti consente di 
\f0\b catturare sfumature
\f1\b0  nel linguaggio che altrimenti potrebbero passare inosservate. Frasi con lo stesso soggetto possono veicolare significati molto diversi a seconda degli aggettivi o degli avverbi usati.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls88\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Esempio
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase A
\f1\b0 : "Le donne 
\f0\b sono brave
\f1\b0  in matematica."\
\ls88\ilvl1
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase B
\f1\b0 : "Le donne 
\f0\b non sono brave
\f1\b0  in matematica."\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Entrambe le frasi contengono lo stesso soggetto, ma la presenza dell'avverbio "non" nella seconda frase cambia completamente il significato e introduce un bias negativo. Avere embedding separati per questi componenti permette alla rete di cogliere tali differenze.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls88\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione pi\'f9 precisa
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls88\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Se il 
\f0\b generatore
\f1\b0  della rete avversaria deve produrre una versione meno biasata di una frase, avere embedding separati per predicati, aggettivi e avverbi pu\'f2 aiutare a determinare quali componenti modificare o eliminare per ridurre il bias, senza alterare eccessivamente il significato della frase.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Struttura migliorata del multivettore\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Quindi, oltre agli embedding di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls89\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Frase biasata
\f1\b0 ,\
\ls89\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Descrizione oggettiva
\f1\b0 ,\
\ls89\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Relazioni ontologiche
\f1\b0 ,\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 potresti includere anche gli 
\f0\b embedding separati per predicati, aggettivi e avverbi
\f1\b0 . Questa struttura ti permette di isolare e rappresentare i dettagli specifici che contribuiscono al bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Come estrarre predicati, aggettivi e avverbi?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Per estrarre predicati, aggettivi e avverbi dalla frase biasata, possiamo utilizzare strumenti di 
\f0\b natural language processing (NLP)
\f1\b0  come 
\f0\b SpaCy
\f1\b0 , che permette di fare il 
\f0\b part-of-speech tagging
\f1\b0  (analisi grammaticale) di una frase. Una volta estratti, possiamo calcolare gli embedding per queste parti specifiche del discorso.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio di estrazione con SpaCy\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 bash\
\
pip install spacy\
python -m spacy download en_core_web_sm\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Estrarre predicati, aggettivi e avverbi\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
import spacy\
\
# Caricare il modello NLP di SpaCy\
nlp = spacy.load("en_core_web_sm")\
\
# Frase biasata da analizzare\
frase = "Le donne non sono brave in matematica."\
\
# Analizzare la frase\
doc = nlp(frase)\
\
# Estrarre predicati (verbi), aggettivi e avverbi\
predicati = [token.text for token in doc if token.pos_ == "VERB"]\
aggettivi = [token.text for token in doc if token.pos_ == "ADJ"]\
avverbi = [token.text for token in doc if token.pos_ == "ADV"]\
\
print("Predicati:", predicati)\
print("Aggettivi:", aggettivi)\
print("Avverbi:", avverbi)\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs24 \cf0 \strokec2 Output
\f1\b0 :\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 vbnet\
\
Predicati: ['sono']\
Aggettivi: ['brave']\
Avverbi: ['non']\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs24 \cf0 \strokec2 Ora che hai estratto questi elementi, puoi creare gli embedding per ciascuno di essi utilizzando lo stesso modello 
\f0\b Sentence-BERT
\f1\b0  che hai utilizzato per la frase principale.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Creare embedding per predicati, aggettivi e avverbi\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
# Creare embedding per predicati, aggettivi e avverbi\
embedding_predicati = modello_embedding.encode(predicati)\
embedding_aggettivi = modello_embedding.encode(aggettivi)\
embedding_avverbi = modello_embedding.encode(avverbi)\
\
# Stampa gli embedding\
print("Embedding dei predicati:", embedding_predicati)\
print("Embedding degli aggettivi:", embedding_aggettivi)\
print("Embedding degli avverbi:", embedding_avverbi)\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Costruire il multivettore completo\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Ora possiamo combinare gli embedding della frase biasata, della descrizione oggettiva, delle relazioni ontologiche e dei predicati/aggettivi/avverbi in un 
\f0\b multivettore
\f1\b0 .\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf0 \strokec2 python\
\
# Embedding della frase biasata, descrizioni oggettive, e relazioni ontologiche (gi\'e0 calcolati)\
embedding_multivettoriale = np.hstack((embedding_frasi_biasate, embedding_descrizioni, embedding_relazioni))\
\
# Includere anche gli embedding di predicati, aggettivi e avverbi\
embedding_completo = np.hstack((\
    embedding_multivettoriale,\
    embedding_predicati.flatten(),  # Aggiungi l'embedding dei predicati\
    embedding_aggettivi.flatten(),  # Aggiungi l'embedding degli aggettivi\
    embedding_avverbi.flatten()     # Aggiungi l'embedding degli avverbi\
))\
\
print("Multivettore completo con predicati, aggettivi e avverbi:\\n", embedding_completo)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Vantaggi pratici dell'aggiunta di predicati, aggettivi e avverbi\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls90\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Maggiore sensibilit\'e0 al bias linguistico
\f1\b0 : Poich\'e9 il bias viene spesso trasmesso attraverso gli 
\f0\b aggettivi
\f1\b0  o i 
\f0\b modificatori
\f1\b0  come gli 
\f0\b avverbi
\f1\b0 , avere embedding separati per queste componenti ti permette di catturare pi\'f9 efficacemente il contributo semantico di questi elementi.\
\ls90\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Migliore capacit\'e0 di mitigazione
\f1\b0 : Il 
\f0\b generatore
\f1\b0  nella rete avversaria potrebbe usare questi embedding per produrre frasi alternative meno biasate. Ad esempio, potrebbe sostituire un aggettivo offensivo o attenuare l'effetto di un avverbio negativo, creando una versione pi\'f9 neutra della frase.\
\ls90\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Maggiore granularit\'e0 nel rilevamento del bias
\f1\b0 : Avere embedding distinti per questi elementi consente al 
\f0\b discriminatore
\f1\b0  di fare distinzioni pi\'f9 precise tra frasi che potrebbero sembrare simili ma differiscono nei dettagli importanti che trasmettono bias.\
\ls90\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analisi pi\'f9 approfondita del linguaggio
\f1\b0 : Puoi ottenere una comprensione pi\'f9 profonda di come il linguaggio venga usato per veicolare pregiudizi. Ad esempio, potresti scoprire che determinati avverbi o aggettivi sono pi\'f9 frequentemente associati a stereotipi o bias in particolari contesti.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 L'inclusione degli embedding relativi a 
\f0\b predicati
\f1\b0 , 
\f0\b aggettivi
\f1\b0  e 
\f0\b avverbi
\f1\b0  nel multivettore per il rilevamento e la mitigazione del bias offre diversi vantaggi:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls91\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cattura pi\'f9 dettagli e sfumature che influenzano il significato di una frase.\
\ls91\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Migliora la precisione del 
\f0\b discriminatore
\f1\b0  nel rilevare bias sottili.\
\ls91\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aumenta la capacit\'e0 del 
\f0\b generatore
\f1\b0  di creare versioni alternative meno biasate delle frasi.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 In definitiva, aggiungere questi componenti rende il 
\f0\b multivettore
\f1\b0  ancora pi\'f9 ricco e completo, fornendo un'analisi del bias pi\'f9 robusta e dettagliata e migliorando la capacit\'e0 di un sistema GAN di rilevare e mitigare il bias linguistico in modo pi\'f9 efficace.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\sa332\partightenfactor0

\f0\b\fs20 \cf0 Hai detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 no ma io mi riferisco ad includere gli embedding della descrizione di wikidata relativa a questi predicati aggettivi ed avverbi. Essi sono gi\'e0 presenti nell'embedding della frase biasata come mai vuoi aggiungere gli embedding separati al multivettore?\
\pard\pardeftab720\sa419\partightenfactor0

\f0\b\fs18 \cf0 ChatGPT ha detto:\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 ChatGPT\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Ah, ho capito! Grazie per la precisazione. Quando ti riferisci a 
\f0\b includere gli embedding della descrizione di Wikidata relativa ai predicati, aggettivi e avverbi
\f1\b0 , ha perfettamente senso e potrebbe aggiungere un ulteriore 
\f0\b livello di contesto semantico
\f1\b0  per migliorare il rilevamento e la mitigazione del bias.\
In pratica, questo approccio sfrutta 
\f0\b Wikidata
\f1\b0  non solo per ottenere le descrizioni oggettive delle entit\'e0 principali della frase (ad esempio, "donne", "italiani", ecc.), ma anche per ottenere informazioni semantiche aggiuntive sui 
\f0\b predicati
\f1\b0 , 
\f0\b aggettivi
\f1\b0  e 
\f0\b avverbi
\f1\b0  utilizzati nella frase, se disponibili in Wikidata. Questo aggiungerebbe una dimensione di 
\f0\b conoscenza strutturata e neutrale
\f1\b0  anche per le componenti linguistiche pi\'f9 piccole, che spesso veicolano il bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Perch\'e9 includere le descrizioni di Wikidata relative a predicati, aggettivi e avverbi?\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls92\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggiungere contesto semantico oggettivo
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls92\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Le descrizioni oggettive provenienti da 
\f0\b Wikidata
\f1\b0  possono fornire un contesto neutrale anche per 
\f0\b verbi
\f1\b0 , 
\f0\b aggettivi
\f1\b0  e 
\f0\b avverbi
\f1\b0 . Questi elementi sono fondamentali per il 
\f0\b tono
\f1\b0  e il 
\f0\b senso
\f1\b0  della frase, e le informazioni strutturate di Wikidata possono aiutare a capire meglio se la frase usa termini che tendono ad essere 
\f0\b neutri
\f1\b0  o che possono avere 
\f0\b connotazioni stereotipate
\f1\b0 .\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls92\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Arricchire la rappresentazione dei bias
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls92\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Predicati, aggettivi e avverbi contribuiscono fortemente al bias nella frase. Ottenere una rappresentazione oggettiva di questi elementi da Wikidata potrebbe aiutare a confrontare il loro uso nella frase biasata con il loro 
\f0\b significato reale
\f1\b0  o la loro rappresentazione neutrale, aiutando il modello a identificare se il loro uso nella frase \'e8 potenzialmente distorto o negativo.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls92\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione del bias pi\'f9 accurata
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls92\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avere una descrizione oggettiva di come 
\f0\b dovrebbe essere interpretato un aggettivo o un verbo
\f1\b0  pu\'f2 aiutare il 
\f0\b generatore
\f1\b0  a mitigare meglio il bias, suggerendo sostituzioni o modifiche basate su contesti pi\'f9 neutri e oggettivi.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Esempio pratico di come ottenere descrizioni per predicati, aggettivi e avverbi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Supponiamo di avere la frase: 
\f0\b "Le donne non sono brave in matematica."
\f1\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls93\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Predicato
\f1\b0 : "sono brave"\
\ls93\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aggettivo
\f1\b0 : "brave"\
\ls93\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avverbio
\f1\b0 : "non"\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Oltre a estrarre gli embedding per questi elementi, possiamo cercare di ottenere informazioni su di essi da 
\f0\b Wikidata
\f1\b0 . Ad esempio, possiamo cercare una descrizione per il concetto di "brave" (corrispondente all'aggettivo "competente", "capace") su Wikidata.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Esempio di descrizione di aggettivi su Wikidata\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
from wikidata.client import Client\
\
# Inizializzare il client di Wikidata\
client = Client()\
\
# Esempio di ricerca per il concetto di "brave" (competente, capace)\
risultato = client.search('competent')  # Cerca su Wikidata\
if risultato:\
    aggettivo_wikidata = client.get(risultato[0]['id'], load=True)\
    descrizione_aggettivo = aggettivo_wikidata.description\
\
    print(f"Descrizione oggettiva di 'brave' (competente) su Wikidata: \{descrizione_aggettivo\}")\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs24 \cf0 Estendere a predicati e avverbi\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 \strokec2 Analogamente, puoi cercare 
\f0\b verbi
\f1\b0  (predicati) e 
\f0\b avverbi
\f1\b0  su Wikidata. Se non trovi una corrispondenza esatta per alcune parti del discorso (come gli avverbi), potresti concentrarti sui verbi principali (predicati) e sugli aggettivi, che spesso giocano un ruolo chiave nell'espressione del bias.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 Includere gli embedding delle descrizioni di Wikidata nel multivettore\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Una volta che hai ottenuto le descrizioni oggettive di predicati, aggettivi e avverbi, puoi calcolare gli 
\f0\b embedding
\f1\b0  per queste descrizioni e includerli nel 
\f0\b multivettore
\f1\b0 .\
Ecco un esempio completo che integra gli embedding delle descrizioni Wikidata nel multivettore.\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf0 \strokec2 Codice per creare embedding delle descrizioni di Wikidata per predicati, aggettivi e avverbi\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs26 \cf0 python\
\
# Inizializza il modello di embedding\
modello_embedding = SentenceTransformer('paraphrase-MiniLM-L6-v2')\
\
# Supponiamo di aver trovato la descrizione oggettiva di "brave" (competent) su Wikidata\
descrizione_brave = "Having the necessary ability, knowledge, or skill to do something successfully."\
\
# Creare embedding per la descrizione oggettiva di "brave"\
embedding_descrizione_aggettivo = modello_embedding.encode(descrizione_brave)\
\
# Creare embedding per la frase biasata\
frase_biasata = "Le donne non sono brave in matematica."\
embedding_frase_biasata = modello_embedding.encode([frase_biasata])\
\
# Supponiamo di aver trovato descrizioni per gli altri elementi (predicati e avverbi)\
descrizione_predicato = "To have a particular quality or ability."  # Descrizione per "essere"\
embedding_descrizione_predicato = modello_embedding.encode(descrizione_predicato)\
\
descrizione_avverbio = "Not."  # Descrizione per "non"\
embedding_descrizione_avverbio = modello_embedding.encode(descrizione_avverbio)\
\
# Costruire il multivettore combinando la frase biasata e le descrizioni oggettive\
embedding_multivettoriale = np.hstack((\
    embedding_frase_biasata,                  # Embedding della frase biasata\
    embedding_descrizione_aggettivo.flatten(),  # Embedding descrizione oggettiva dell'aggettivo\
    embedding_descrizione_predicato.flatten(),  # Embedding descrizione oggettiva del predicato\
    embedding_descrizione_avverbio.flatten()    # Embedding descrizione oggettiva dell'avverbio\
))\
\
print("Multivettore completo con descrizioni di predicati, aggettivi e avverbi:\\n", embedding_multivettoriale)\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Vantaggi di includere descrizioni di predicati, aggettivi e avverbi nel multivettore\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls94\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confronto semantico pi\'f9 approfondito
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls94\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avere la rappresentazione oggettiva di 
\f0\b verbi, aggettivi e avverbi
\f1\b0  utilizzati nella frase permette un confronto pi\'f9 dettagliato tra il significato effettivo di questi elementi e il modo in cui sono stati usati nella frase biasata. Questo rende il rilevamento del bias pi\'f9 accurato.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls94\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Rilevamento di bias sottili
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls94\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Gli aggettivi e i predicati spesso trasmettono i bias in modo sottile. Includere le descrizioni di questi elementi nel multivettore consente alla rete avversaria di identificare pi\'f9 facilmente il 
\f0\b carattere stereotipato
\f1\b0  o 
\f0\b distorto
\f1\b0  di una frase, rispetto a come questi concetti sono rappresentati in modo neutrale.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls94\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Mitigazione pi\'f9 precisa
\f1\b0 :\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls94\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Quando il 
\f0\b generatore
\f1\b0  deve creare una frase meno biasata, avere embedding separati per predicati, aggettivi e avverbi, insieme alle loro descrizioni oggettive, pu\'f2 aiutare il generatore a 
\f0\b sostituire
\f1\b0  o 
\f0\b modificare
\f1\b0  solo le parti della frase che sono problematiche, senza alterare il significato complessivo della frase.\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs28 \cf0 \strokec2 Conclusione\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 Includere gli 
\f0\b embedding relativi alle descrizioni di Wikidata
\f1\b0  per 
\f0\b predicati, aggettivi e avverbi
\f1\b0  nel multivettore \'e8 un approccio molto potente per arricchire il rilevamento e la mitigazione del bias. Questo consente di:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls95\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Catturare il significato oggettivo e neutrale delle parole chiave che veicolano il bias.\
\ls95\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Offrire una rappresentazione semantica pi\'f9 precisa che permette alla rete avversaria di identificare bias anche in elementi grammaticali apparentemente neutri.\
\ls95\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Migliorare la capacit\'e0 del generatore di produrre frasi meno biasate, mantenendo al contempo il significato originale delle frasi.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Quindi, s\'ec, includere le descrizioni di 
\f0\b predicati
\f1\b0 , 
\f0\b aggettivi
\f1\b0  e 
\f0\b avverbi
\f1\b0  da Wikidata fornisce un ulteriore livello di contesto utile per una mitigazione pi\'f9 accurata e per un sistema GAN pi\'f9 robusto.}