{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c1267e-906f-46f0-b746-b0332c96139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'stereoset_with_multivectors_for_clustering.json' generato con successo.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer\n",
    "from neo4j import GraphDatabase\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "import torch  # Aggiungi import torch per gestire CUDA\n",
    "\n",
    "# Configurazione del modello SBERT e del tokenizzatore\n",
    "# Sposta il modello su GPU se disponibile\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sbert_model = SentenceTransformer('multi-qa-mpnet-base-dot-v1').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "class Neo4jHandler:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def get_entity_info_from_neo4j(self, term):\n",
    "        query = \"\"\"\n",
    "        MATCH (n:Entity {id: $term})\n",
    "        OPTIONAL MATCH (n)-[:INSTANCE_OF]->(instance)\n",
    "        OPTIONAL MATCH (n)-[:SUBCLASS_OF]->(subclass)\n",
    "        RETURN n.description AS description, collect(DISTINCT instance.id) AS instance_of, collect(DISTINCT subclass.id) AS subclass_of\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, term=term).single()\n",
    "        \n",
    "        return {\n",
    "            'description': result['description'] if result and result['description'] else \"\",\n",
    "            'instance_of': result['instance_of'] if result and result['instance_of'] else [],\n",
    "            'subclass_of': result['subclass_of'] if result and result['subclass_of'] else []\n",
    "        }\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_embedding(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    clean_text = tokenizer.decode(tokens, clean_up_tokenization_spaces=True)\n",
    "    embedding = sbert_model.encode(clean_text, convert_to_tensor=True, device=device)  # Usa il device GPU\n",
    "    return embedding\n",
    "\n",
    "def load_stereoset_from_file(filename=\"stereoset_enriched.json\"):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_batch_entity_info(terms, neo4j_handler):\n",
    "    term_info = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(neo4j_handler.get_entity_info_from_neo4j, terms))\n",
    "        for term, result in zip(terms, results):\n",
    "            term_info[term] = result\n",
    "    return term_info\n",
    "\n",
    "def enrich_with_multivectors(dataset, neo4j_handler, similarity_threshold=0.5):\n",
    "    enriched_data = []\n",
    "    description_cache = {}\n",
    "\n",
    "    def process_item(item):\n",
    "        complete_sentence = str()\n",
    "        type = None\n",
    "        context = item[\"Contesto\"]\n",
    "        sentence = item[\"Frase\"]\n",
    "\n",
    "        if \"BLANK\" in context: \n",
    "            type = 1\n",
    "            complete_sentence = sentence\n",
    "        else:\n",
    "            type = 2\n",
    "            complete_sentence = context + \" \" + sentence\n",
    "            \n",
    "        context_embedding = get_embedding(complete_sentence)\n",
    "\n",
    "        # Recupera tutte le parole chiave da Soggetti, Oggetti e Sostantivi\n",
    "        keywords = set(item[\"Soggetti\"] + item[\"Oggetti\"] + item[\"Sostantivi\"] + item[\"Aggettivi\"] + item[\"Avverbi\"])\n",
    "        term_info = get_batch_entity_info(keywords, neo4j_handler)\n",
    "\n",
    "        # Calcola la similarità e aggiunge descrizioni rilevanti\n",
    "        relevant_descriptions = []\n",
    "        relevant_embeddings = []\n",
    "        for term in keywords:\n",
    "            entity_info = term_info.get(term)\n",
    "            description = entity_info['description']\n",
    "            if description:\n",
    "                # Usa la cache per evitare ricomputazioni\n",
    "                if term not in description_cache:\n",
    "                    description_cache[term] = get_embedding(description)\n",
    "                \n",
    "                # Calcola la similarità direttamente su GPU\n",
    "                similarity = util.cos_sim(context_embedding, description_cache[term]).item()\n",
    "                if similarity >= similarity_threshold:\n",
    "                    relevant_descriptions.append(description)\n",
    "                    relevant_embeddings.append(description_cache[term])\n",
    "\n",
    "        # Creazione del multivettore combinato\n",
    "        if relevant_embeddings:\n",
    "            combined_embedding = context_embedding + torch.sum(torch.stack(relevant_embeddings), dim=0)\n",
    "        else:\n",
    "            combined_embedding = context_embedding\n",
    "\n",
    "        # Aggiunge il campo Multivettore al JSON\n",
    "        item[\"Frase filtrata\"] = {\n",
    "            \"Frase completa\": {\n",
    "                \"Testo\": complete_sentence,\n",
    "                \"Tipo\": type,\n",
    "                \"Descrizioni rilevanti\": relevant_descriptions,\n",
    "                \"Multivettore\": combined_embedding.cpu().tolist()  # Converti il vettore in lista per il JSON\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return item\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        enriched_data = list(executor.map(process_item, dataset))\n",
    "\n",
    "    return enriched_data\n",
    "\n",
    "# Configurazione e connessione a Neo4j\n",
    "neo4j_handler = Neo4jHandler(\"bolt://localhost:7687\", \"neo4j\", \"10086832\")\n",
    "\n",
    "# Carica il dataset e aggiunge i multivettori\n",
    "stereoset_data = load_stereoset_from_file()\n",
    "enriched_data = enrich_with_multivectors(stereoset_data, neo4j_handler)\n",
    "\n",
    "# Salva il file JSON aggiornato\n",
    "with open(\"stereoset_with_multivectors_for_clustering.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(enriched_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Chiudi la connessione a Neo4j\n",
    "neo4j_handler.close()\n",
    "print(\"File 'stereoset_with_multivectors_for_clustering.json' generato con successo.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
