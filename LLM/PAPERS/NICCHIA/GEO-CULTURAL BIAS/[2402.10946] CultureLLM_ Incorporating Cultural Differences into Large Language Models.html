<!DOCTYPE html>
<html lang="en" data-theme="dark"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.10946] CultureLLM: Incorporating Cultural Differences into Large Language Models</title><meta property="og:description" content="Large language models (LLMs) are reported to be partial to certain cultures owing to the training data dominance from the English corpora. Since multilingual cultural data are often expensive to collect, existing efforâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CultureLLM: Incorporating Cultural Differences into Large Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="CultureLLM: Incorporating Cultural Differences into Large Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.10946">

<!--Generated on Tue Mar  5 17:57:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">CultureLLM: Incorporating Cultural Differences into Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cheng Li<sup id="id14.8.id1" class="ltx_sup"><span id="id14.8.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Work done during Chengâ€™s internship at MSRA. Contact: chenglicat0228@gmail.com.</span></span></span>, Mengzhuo Chen<sup id="id15.9.id2" class="ltx_sup"><span id="id15.9.id2.1" class="ltx_text ltx_font_italic">2</span></sup>, Jindong Wang<sup id="id16.10.id3" class="ltx_sup"><span id="id16.10.id3.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Corresponding author: Jindong Wang (jindong.wang@microsoft.com).</span></span></span>, Sunayana Sitaram<sup id="id17.11.id4" class="ltx_sup"><span id="id17.11.id4.1" class="ltx_text ltx_font_italic">1</span></sup>, Xing Xie<sup id="id18.12.id5" class="ltx_sup"><span id="id18.12.id5.1" class="ltx_text ltx_font_italic">1</span></sup>
<br class="ltx_break"><sup id="id19.13.id6" class="ltx_sup"><span id="id19.13.id6.1" class="ltx_text ltx_font_italic">1</span></sup>Microsoft Research â€ƒ<sup id="id20.14.id7" class="ltx_sup"><span id="id20.14.id7.1" class="ltx_text ltx_font_italic">2</span></sup>Institute of Software, CAS
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id12.5" class="ltx_p"><span id="id12.5.5" class="ltx_text">Large 
language models (LLMs) are reported to be partial to certain cultures 
owing to the training data dominance from the English corpora. Since 
multilingual cultural data are often expensive to collect, existing 
efforts handle this by prompt engineering or culture-specific 
pre-training. However, they might overlook the knowledge deficiency of 
low-resource culture and require extensive computing resources. In this 
paper, we propose <span id="id12.5.5.1" class="ltx_text ltx_font_bold">CultureLLM</span>,
 a cost-effective solution to incorporate cultural differences into 
LLMs. CultureLLM adopts World Value Survey (WVS) as seed data and 
generates semantically equivalent training data via the proposed 
semantic data augmentation. Using only <math id="id8.1.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="id8.1.1.m1.1a"><mn id="id8.1.1.m1.1.1" xref="id8.1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="id8.1.1.m1.1b"><cn type="integer" id="id8.1.1.m1.1.1.cmml" xref="id8.1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="id8.1.1.m1.1c">50</annotation></semantics></math> seed samples from WVS with augmented data, we fine-tune culture-specific LLMs and one unified model (CultureLLM-One) for <math id="id9.2.2.m2.1" class="ltx_Math" alttext="9" display="inline"><semantics id="id9.2.2.m2.1a"><mn id="id9.2.2.m2.1.1" xref="id9.2.2.m2.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="id9.2.2.m2.1b"><cn type="integer" id="id9.2.2.m2.1.1.cmml" xref="id9.2.2.m2.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="id9.2.2.m2.1c">9</annotation></semantics></math> cultures covering rich and low-resource languages. Extensive experiments on <math id="id10.3.3.m3.1" class="ltx_Math" alttext="60" display="inline"><semantics id="id10.3.3.m3.1a"><mn id="id10.3.3.m3.1.1" xref="id10.3.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="id10.3.3.m3.1b"><cn type="integer" id="id10.3.3.m3.1.1.cmml" xref="id10.3.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="id10.3.3.m3.1c">60</annotation></semantics></math> culture-related datasets demonstrate that CultureLLM significantly outperforms various counterparts such as GPT-3.5 (by <math id="id11.4.4.m4.1" class="ltx_Math" alttext="8.1" display="inline"><semantics id="id11.4.4.m4.1a"><mn id="id11.4.4.m4.1.1" xref="id11.4.4.m4.1.1.cmml">8.1</mn><annotation-xml encoding="MathML-Content" id="id11.4.4.m4.1b"><cn type="float" id="id11.4.4.m4.1.1.cmml" xref="id11.4.4.m4.1.1">8.1</cn></annotation-xml><annotation encoding="application/x-tex" id="id11.4.4.m4.1c">8.1</annotation></semantics></math>%) and Gemini Pro (by <math id="id12.5.5.m5.1" class="ltx_Math" alttext="9.5" display="inline"><semantics id="id12.5.5.m5.1a"><mn id="id12.5.5.m5.1.1" xref="id12.5.5.m5.1.1.cmml">9.5</mn><annotation-xml encoding="MathML-Content" id="id12.5.5.m5.1b"><cn type="float" id="id12.5.5.m5.1.1.cmml" xref="id12.5.5.m5.1.1">9.5</cn></annotation-xml><annotation encoding="application/x-tex" id="id12.5.5.m5.1c">9.5</annotation></semantics></math>%)
 with comparable performance to GPT-4 or even better. Our human study 
shows that the generated samples are semantically equivalent to the 
original samples, providing an effective solution for LLMs augmentation.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Culture is a complex construct that 
encodes various identities, including but not limited to, language, 
nationality, region, religion, and gender identity.
Cultural bias is widely present around the world, which refers to the 
tendency to favor specific cultural perspectives, values, and norms that
 lead to subjective opinions and can offend people of other cultures.
For example, according to the World Value Survey&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Survey, <a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>, Arabic culture believes that men are better political leaders than women, while people in the United States disagree.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We respect all opinions in different cultures.</span></span></span>
As large language models (LLMs)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib59" title="" class="ltx_ref">2023b</a>; Google, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>
 become prevalent, they are reported to suffer cultural bias and are 
specifically partial to Western culture, as English corpora dominate 
training data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2023b</a>; Cao et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Masoud et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Naous et&nbsp;al., <a href="#bib.bib54" title="" class="ltx_ref">2023</a>; Wang et&nbsp;al., <a href="#bib.bib80" title="" class="ltx_ref">2023d</a>; Johnson et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>.
Low-resource cultures exist widely due to the lack of training data from other cultures.
LLMsâ€™ cultural bias presents a major bottleneck in human-AI collaboration and significantly hinders AI democracy.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="231" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview
 of CultureLLM. CultureLLM consists of three steps: sampling, semantic 
data augmentation, and fine-tuning. Both culture-specific and unified 
CultureLLM can be fine-tuned.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Tackling cultural bias requires an LLM to embrace cultural differences&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hofstede, <a href="#bib.bib27" title="" class="ltx_ref">1984</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">KovaÄ et&nbsp;al. (<a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib80" title="" class="ltx_ref">2023d</a>)</cite>
 thought LLMs have enough knowledge of all cultures and devised prompt 
engineering technologies to induce LLMs to exhibit specific cultural 
perspectives.
However, they are not effective, especially in low-resource cultures 
with limited data.
Another line of work pre-trained culturally-aware LLMs and then 
fine-tuned on specific datasets&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chan et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Nguyen et&nbsp;al., <a href="#bib.bib56" title="" class="ltx_ref">2023b</a>; Pipatanakul et&nbsp;al., <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Abbasi et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2023</a>; Lin and Chen, <a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>.
They require the collection of large-scale pre-training and fine-tuning 
datasets and extensive computing resources, thus are not affordable to 
ordinary researchers and cannot handle low-resource culture.
To date, training culturally-aware LLMs at affordable costs remains a 
challenge.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.2" class="ltx_p">In this paper, we propose <span id="S1.p3.2.1" class="ltx_text ltx_font_bold">CultureLLM</span>, a cost-effective<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Fine-tuning a CultureLLM only costs $6 via OpenAI API.</span></span></span> solution to incorporate cultural differences into LLMs. To be specific, we focus on cultural values in this work.
As shown in <a href="#S1.F1" title="In 1 Introduction â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>, CultureLLM consists of three steps: sampling, semantic data augmentation, and fine-tuning.
Inspired by Attitude-Behavior Consistency theory&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fazio and Zanna, <a href="#bib.bib21" title="" class="ltx_ref">1981</a>)</cite> which emphasizes that peopleâ€™s opinion is consistent with their behaviors, we use the World Values Survey (WVS)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Survey, <a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>
 as seed data.
Then, we devise a semantic data augmentation approach to generate 
semantically equivalent samples. The aim is to generate semantic 
equivalent inputs, thus we can get the ground-truth from seed data 
directly.
Finally, CultureLLM is obtained by fine-tuning on both the seed and the 
generated data.
WVS is a public opinion poll that contains peopleâ€™s opinions on cultural
 topics from different countries.
To be specific, we select <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S1.p3.1.m1.1a"><mn id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><cn type="integer" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">50</annotation></semantics></math> seed samples from WVS, covering <math id="S1.p3.2.m2.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S1.p3.2.m2.1a"><mn id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><cn type="integer" id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">7</annotation></semantics></math>
 topics: â€œsocial values", â€œmigration", â€œsecurity", â€œscience and 
technology", â€œreligious values", â€œethical values and norms", and 
â€œpolitical interest and political participation".
Using these generated samples and answers from people in different 
cultures, we fine-tune specific and unified LLMs: specific LLMs are 
tailored for each culture such as CultureLLM-Ar for Arabic and 
CultureLLM-Tr for Turkish; unified LLMs (CultureLLM-One) are one LLM 
that fits all cultures.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>The bound of culture is unclear, and we use the main spoken language to distinguish cultures in this work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Delanoy, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>.</span></span></span></p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.7" class="ltx_p">We build <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S1.p4.1.m1.1a"><mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><cn type="integer" id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">9</annotation></semantics></math>
 specific CultureLLM and a CultureLLM-One covering both high- and 
low-resource cultures: Arabic culture, Bengali culture, Chinese culture,
 English culture, German culture, Korean culture, Portuguese culture, 
Spanish culture, and Turkish culture.
Then we evaluated them on <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S1.p4.2.m2.1a"><mn id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><cn type="integer" id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">8</annotation></semantics></math>
 culture-related downstream tasks: offensive language detection, hate 
speech detection, stance detection, toxicity detection, threat 
detection, bias detection, abusive detection, spam detection, and an 
open-ended generative task.
We have <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S1.p4.3.m3.1a"><mn id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><cn type="integer" id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">60</annotation></semantics></math> test sets, which contain <math id="S1.p4.4.m4.2" class="ltx_Math" alttext="68,672" display="inline"><semantics id="S1.p4.4.m4.2a"><mrow id="S1.p4.4.m4.2.3.2" xref="S1.p4.4.m4.2.3.1.cmml"><mn id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml">68</mn><mo id="S1.p4.4.m4.2.3.2.1" xref="S1.p4.4.m4.2.3.1.cmml">,</mo><mn id="S1.p4.4.m4.2.2" xref="S1.p4.4.m4.2.2.cmml">672</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.2b"><list id="S1.p4.4.m4.2.3.1.cmml" xref="S1.p4.4.m4.2.3.2"><cn type="integer" id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1">68</cn><cn type="integer" id="S1.p4.4.m4.2.2.cmml" xref="S1.p4.4.m4.2.2">672</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.2c">68,672</annotation></semantics></math> test samples in total.
Experiments show that CultureLLM fine-tuned on GPT-3.5 significantly outperforms GPT-3.5 by <math id="S1.p4.5.m5.1" class="ltx_Math" alttext="8.1" display="inline"><semantics id="S1.p4.5.m5.1a"><mn id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml">8.1</mn><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.1b"><cn type="float" id="S1.p4.5.m5.1.1.cmml" xref="S1.p4.5.m5.1.1">8.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">8.1</annotation></semantics></math>% and outperforms Gemini pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Google, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite> by <math id="S1.p4.6.m6.1" class="ltx_Math" alttext="9.5" display="inline"><semantics id="S1.p4.6.m6.1a"><mn id="S1.p4.6.m6.1.1" xref="S1.p4.6.m6.1.1.cmml">9.5</mn><annotation-xml encoding="MathML-Content" id="S1.p4.6.m6.1b"><cn type="float" id="S1.p4.6.m6.1.1.cmml" xref="S1.p4.6.m6.1.1">9.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.6.m6.1c">9.5</annotation></semantics></math>% on average F1 score, achieving comparable or even better performance with GPT-4.
Our human study of <math id="S1.p4.7.m7.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S1.p4.7.m7.1a"><mn id="S1.p4.7.m7.1.1" xref="S1.p4.7.m7.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S1.p4.7.m7.1b"><cn type="integer" id="S1.p4.7.m7.1.1.cmml" xref="S1.p4.7.m7.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.7.m7.1c">50</annotation></semantics></math> people demonstrates that the augmentation method can generate semantically equivalent samples.
We further interpret the rationale behind its effectiveness by exploring the fine-tuning data size and case studies.
Finally, results on Big-Bench Hard&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib73" title="" class="ltx_ref">2022</a>)</cite> and GSM8K&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Cobbe et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite> indicate that CultureLLM is resistant to catastrophic forgetting.
CultureLLM also supports open-source fine-tuning.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our contributions are three-fold:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We presented CultureLLM, a cost-effective fine-tuning solution to build culturally-aware LLMs.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We proposed semantic data augmentation, an augmentation approach to generate high-quality and diverse training data for LLMs.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We conducted extensive experiments 
across a wide range of cultures and LLMs, showing that LLMs performs 
consistently well in all downstream tasks.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Cultural Problem and Solution in LLMs</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Previous efforts have shown that LLMs exhibit the same cultural problems as in human society.
<cite class="ltx_cite ltx_citemacro_citet">Niszczota and Janczak (<a href="#bib.bib57" title="" class="ltx_ref">2023</a>)</cite> proved that GPT-4 can replicate the cross-cultural differences for each personality factor through large-scale experiments.
Meanwhile, other works also found that LLMs can reflect cultural bias and dominance in human society&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2023b</a>; Cao et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Masoud et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Naous et&nbsp;al., <a href="#bib.bib54" title="" class="ltx_ref">2023</a>; Wang et&nbsp;al., <a href="#bib.bib80" title="" class="ltx_ref">2023d</a>; Johnson et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, e.g., Western culture dominance, since the major training corpus such as Pile&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> is in English.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The ideal solution is to enhance the cultural awareness of LLMs.
There are mainly two types of approach: prompt engineering and pre-training.
<cite class="ltx_cite ltx_citemacro_citet">KovaÄ et&nbsp;al. (<a href="#bib.bib39" title="" class="ltx_ref">2023</a>); Wang et&nbsp;al. (<a href="#bib.bib80" title="" class="ltx_ref">2023d</a>)</cite> thought LLMs as superpositions of cultural perspectives, which can be prompted to targeted cultural perspectives. while <cite class="ltx_cite ltx_citemacro_citet">Rao et&nbsp;al. (<a href="#bib.bib64" title="" class="ltx_ref">2023</a>)</cite>
 encoded cultural values in the prompts.
Although PE is cheap, its effectiveness is challenged, especially in 
low-resource cultures where LLMs lack such cultural knowledge due to 
lack of representation in pre-training data.
Another line of research is pre-training and fine-tuning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chan et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Nguyen et&nbsp;al., <a href="#bib.bib56" title="" class="ltx_ref">2023b</a>; Pipatanakul et&nbsp;al., <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Abbasi et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2023</a>; Lin and Chen, <a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>
 that trains culturally-aware LLMs for different cultures by collecting 
large-scale pre-training datasets and then performed fine-tuning for 
better alignment.
While they achieved great performance, this approach is too expensive 
and time-consuming, thus it is difficult to apply to more cultures and 
countries.
They still suffer from a low-resource culture problem where the 
pre-training data are difficult to collect. MaLA-500&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a href="#bib.bib44" title="" class="ltx_ref">2024</a>)</cite> trained a new LLM on Llama 2 to cover <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="534" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">534</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><cn type="integer" id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">534</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">534</annotation></semantics></math> languages, which is resource intensive.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Augmentation for LLMs</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Human-annotated data are high-quality but expensive.
Due to the strong generation ability of LLMs, many works focused on data augmentation leveraging LLMs.
&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Yu et&nbsp;al. (<a href="#bib.bib85" title="" class="ltx_ref">2023</a>); Liu et&nbsp;al. (<a href="#bib.bib46" title="" class="ltx_ref">2023a</a>)</cite> used LLMs to augment the math data and then fine-tuned with those data.
<cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> synthesized data with two devised modules: self-augmentation and self-curation.
<cite class="ltx_cite ltx_citemacro_citet">Chen et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2024</a>)</cite>
 introduced a self-play mechanism, where LLM generates its own training 
data from its previous iterations, refining its policy by discerning 
these self-generated responses from those obtained from human-annotated 
data. There are also other uses for synthetic data, such as knowledge 
distillation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib79" title="" class="ltx_ref">2023c</a>)</cite> and improving text embedding tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib77" title="" class="ltx_ref">2023a</a>)</cite>.
Our data augmentation approach also adopts LLMs for data generation, but
 we add controllable modules such as template editing, synonym 
replacement, and semantic filter to ensure the diversity and semantic 
equivalence of the generated samples.
Our approach can also be used as a general augmentation method in other 
applications.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Culture-related Research and Value Alignment</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Efforts in cultural datasets&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Nguyen et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>; Fung et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>
 focus on cultural common sense and norms, respectively.
However, they generate data from only the English or Chinese corpus and 
thus may contain cultural bias toward other cultures. In contrast, World
 Values Survey (WVS)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Survey, <a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>
 is a large-scale pool that contains answers from vast people of 
different cultures, thus providing more objective cultural values from 
specific cultures.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">This work is also related to value alignment&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ji et&nbsp;al., <a href="#bib.bib30" title="" class="ltx_ref">2023</a>; Shen et&nbsp;al., <a href="#bib.bib70" title="" class="ltx_ref">2023</a>; Yao et&nbsp;al., <a href="#bib.bib84" title="" class="ltx_ref">2023</a>)</cite>,
 which focuses on aligning the values of LLMs with humanâ€™s by designing 
algorithms for value measurement and behavior alignment.
In contrast, this work primarily emphasizes value understanding with the
 potential to be extended for value alignment.
For instance, semantic augmentation can be used to generate training 
data for alignment-related tasks.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>CultureLLM</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we introduce how to build CultureLLM by fine-tuning existing LLMs via semantic data augmentation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Cultural differences are prevalent in 
various cultures and backgrounds, leading to an impact on outcomes in 
downstream applications such as hate speech and biased language.
To address the gap between low-source cultural data collection and its 
wide applications, we design CultureLLM by fine-tuning an LLM on data 
generated by our novel semantic data augmentation approach.
<a href="#S1.F1" title="In 1 Introduction â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>
 presents an overview of CultureLLM, where the first step is to sample a
 subset of data from an existing World Value Survey (WVS)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Survey, <a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite> that represents different opinions (answers) towards the same value questions given by native users.
The adoption of WVS is inspired by Attitude-Behavior Consistency theory&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fazio and Zanna, <a href="#bib.bib21" title="" class="ltx_ref">1981</a>)</cite>, which emphasizes the strong relationship between attitude and behavior.
Therefore, WVS serves as an ideal seed for data augmentation.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>WVS
 is only one feasible option for seed and other surveys can also be 
used. But, as we discussed, the cultural survey data is extremely rare 
and WVS could be the most comprehensive one.</span></span></span>
After sampling, the second step is to generate augmented data using our proposed semantic augmentation approach (<a href="#S3.SS3" title="3.3 Semantic Data Augmentation â€£ 3 CultureLLM â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.3</span></a>)
 and then fine-tune a CultureLLM for each specific culture such as 
CultureLLM-Ar for Arabic culture and CultureLLM-Tr for Turkish culture.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.18" class="ltx_p">Generally speaking, we use <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{d}=\{(x_{j},y_{j}^{d})\}_{j=1}^{n}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><msub id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">d</mi></msub><mo id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml"><mrow id="S3.SS1.p2.1.m1.1.1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.4" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">j</mi><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.5" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p2.1.m1.1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.SS1.p2.1.m1.1.1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p2.1.m1.1.1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p2.1.m1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><eq id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2"></eq><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">ğ‘‘</ci></apply><apply id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.1.m1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1">subscript</csymbol><set id="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1"><interval closure="open" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2"><apply id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.3">ğ‘‘</ci></apply></interval></set><apply id="S3.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.3"><eq id="S3.SS1.p2.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S3.SS1.p2.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p2.1.m1.1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{D}_{d}=\{(x_{j},y_{j}^{d})\}_{j=1}^{n}</annotation></semantics></math> to denote the seed and <math id="S3.SS1.p2.2.m2.2" class="ltx_Math" alttext="\mathcal{D}^{\prime}_{d}=g(\mathcal{D}_{d})=\{(x^{\prime}_{j},y_{j}^{d})\}_{j=1}^{n^{\prime}}" display="inline"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.2" xref="S3.SS1.p2.2.m2.2.2.cmml"><msubsup id="S3.SS1.p2.2.m2.2.2.4" xref="S3.SS1.p2.2.m2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.2.2.4.2.2" xref="S3.SS1.p2.2.m2.2.2.4.2.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p2.2.m2.2.2.4.3" xref="S3.SS1.p2.2.m2.2.2.4.3.cmml">d</mi><mo id="S3.SS1.p2.2.m2.2.2.4.2.3" xref="S3.SS1.p2.2.m2.2.2.4.2.3.cmml">â€²</mo></msubsup><mo id="S3.SS1.p2.2.m2.2.2.5" xref="S3.SS1.p2.2.m2.2.2.5.cmml">=</mo><mrow id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.1.3" xref="S3.SS1.p2.2.m2.1.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.1.1.2" xref="S3.SS1.p2.2.m2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p2.2.m2.1.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.1.1.1.1.1.2" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.2.m2.1.1.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.1.1.1.1.1.1.2" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.p2.2.m2.1.1.1.1.1.1.3" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.3.cmml">d</mi></msub><mo stretchy="false" id="S3.SS1.p2.2.m2.1.1.1.1.1.3" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p2.2.m2.2.2.6" xref="S3.SS1.p2.2.m2.2.2.6.cmml">=</mo><msubsup id="S3.SS1.p2.2.m2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.cmml"><mrow id="S3.SS1.p2.2.m2.2.2.2.1.1.1" xref="S3.SS1.p2.2.m2.2.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.2" xref="S3.SS1.p2.2.m2.2.2.2.1.1.2.cmml">{</mo><mrow id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.3.cmml">(</mo><msubsup id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.2" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.3.cmml">j</mi><mo id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.3.cmml">â€²</mo></msubsup><mo id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.4" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.3.cmml">,</mo><msubsup id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.3.cmml">j</mi><mi id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.5" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.3" xref="S3.SS1.p2.2.m2.2.2.2.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p2.2.m2.2.2.2.1.3" xref="S3.SS1.p2.2.m2.2.2.2.1.3.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.1.3.2" xref="S3.SS1.p2.2.m2.2.2.2.1.3.2.cmml">j</mi><mo id="S3.SS1.p2.2.m2.2.2.2.1.3.1" xref="S3.SS1.p2.2.m2.2.2.2.1.3.1.cmml">=</mo><mn id="S3.SS1.p2.2.m2.2.2.2.1.3.3" xref="S3.SS1.p2.2.m2.2.2.2.1.3.3.cmml">1</mn></mrow><msup id="S3.SS1.p2.2.m2.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.2.3.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.3.2" xref="S3.SS1.p2.2.m2.2.2.2.3.2.cmml">n</mi><mo id="S3.SS1.p2.2.m2.2.2.2.3.3" xref="S3.SS1.p2.2.m2.2.2.2.3.3.cmml">â€²</mo></msup></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><apply id="S3.SS1.p2.2.m2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2"><and id="S3.SS1.p2.2.m2.2.2a.cmml" xref="S3.SS1.p2.2.m2.2.2"></and><apply id="S3.SS1.p2.2.m2.2.2b.cmml" xref="S3.SS1.p2.2.m2.2.2"><eq id="S3.SS1.p2.2.m2.2.2.5.cmml" xref="S3.SS1.p2.2.m2.2.2.5"></eq><apply id="S3.SS1.p2.2.m2.2.2.4.cmml" xref="S3.SS1.p2.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.4.1.cmml" xref="S3.SS1.p2.2.m2.2.2.4">subscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.4.2.cmml" xref="S3.SS1.p2.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.4.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.4">superscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.4.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.4.2.2">ğ’Ÿ</ci><ci id="S3.SS1.p2.2.m2.2.2.4.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.4.2.3">â€²</ci></apply><ci id="S3.SS1.p2.2.m2.2.2.4.3.cmml" xref="S3.SS1.p2.2.m2.2.2.4.3">ğ‘‘</ci></apply><apply id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"><times id="S3.SS1.p2.2.m2.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.1.2"></times><ci id="S3.SS1.p2.2.m2.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.1.3">ğ‘”</ci><apply id="S3.SS1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.1.1.3">ğ‘‘</ci></apply></apply></apply><apply id="S3.SS1.p2.2.m2.2.2c.cmml" xref="S3.SS1.p2.2.m2.2.2"><eq id="S3.SS1.p2.2.m2.2.2.6.cmml" xref="S3.SS1.p2.2.m2.2.2.6"></eq><share href="#S3.SS1.p2.2.m2.1.1.1.cmml" id="S3.SS1.p2.2.m2.2.2d.cmml" xref="S3.SS1.p2.2.m2.2.2"></share><apply id="S3.SS1.p2.2.m2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2">subscript</csymbol><set id="S3.SS1.p2.2.m2.2.2.2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1"><interval closure="open" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2"><apply id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.2.3">â€²</ci></apply><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2">superscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.1.1.1.2.2.3">ğ‘‘</ci></apply></interval></set><apply id="S3.SS1.p2.2.m2.2.2.2.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.3"><eq id="S3.SS1.p2.2.m2.2.2.2.1.3.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.3.1"></eq><ci id="S3.SS1.p2.2.m2.2.2.2.1.3.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.3.2">ğ‘—</ci><cn type="integer" id="S3.SS1.p2.2.m2.2.2.2.1.3.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.1.3.3">1</cn></apply></apply><apply id="S3.SS1.p2.2.m2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.3">superscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.2.3.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.3.2">ğ‘›</ci><ci id="S3.SS1.p2.2.m2.2.2.2.3.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.3.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">\mathcal{D}^{\prime}_{d}=g(\mathcal{D}_{d})=\{(x^{\prime}_{j},y_{j}^{d})\}_{j=1}^{n^{\prime}}</annotation></semantics></math> as the augmented data with <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="g(\cdot)" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.2" xref="S3.SS1.p2.3.m3.1.2.cmml"><mi id="S3.SS1.p2.3.m3.1.2.2" xref="S3.SS1.p2.3.m3.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.2.1" xref="S3.SS1.p2.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.3.m3.1.2.3.2" xref="S3.SS1.p2.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.3.m3.1.2.3.2.1" xref="S3.SS1.p2.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.SS1.p2.3.m3.1.2.3.2.2" xref="S3.SS1.p2.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.2.cmml" xref="S3.SS1.p2.3.m3.1.2"><times id="S3.SS1.p2.3.m3.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.2.1"></times><ci id="S3.SS1.p2.3.m3.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.2.2">ğ‘”</ci><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">g(\cdot)</annotation></semantics></math> the augmentation algorithm.
Note that the question <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">x</annotation></semantics></math> here is the <em id="S3.SS1.p2.18.1" class="ltx_emph ltx_font_italic">same</em> in all cultures in WVS and <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">d</annotation></semantics></math> is the cultural index denoting <em id="S3.SS1.p2.18.2" class="ltx_emph ltx_font_italic">different</em> answers to the same question <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">x</annotation></semantics></math>.
For example, for a question <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">x</annotation></semantics></math>=â€œDo you agree with on the whole, men make better political leaders than women do?â€, the answer <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="y=\text{Disagree}" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mrow id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">y</mi><mo id="S3.SS1.p2.8.m8.1.1.1" xref="S3.SS1.p2.8.m8.1.1.1.cmml">=</mo><mtext id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3a.cmml">Disagree</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><eq id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1"></eq><ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">ğ‘¦</ci><ci id="S3.SS1.p2.8.m8.1.1.3a.cmml" xref="S3.SS1.p2.8.m8.1.1.3"><mtext id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">Disagree</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">y=\text{Disagree}</annotation></semantics></math> if <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="d=\text{English}" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mrow id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml"><mi id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml">d</mi><mo id="S3.SS1.p2.9.m9.1.1.1" xref="S3.SS1.p2.9.m9.1.1.1.cmml">=</mo><mtext id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3a.cmml">English</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1"><eq id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1.1"></eq><ci id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2">ğ‘‘</ci><ci id="S3.SS1.p2.9.m9.1.1.3a.cmml" xref="S3.SS1.p2.9.m9.1.1.3"><mtext id="S3.SS1.p2.9.m9.1.1.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3">English</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">d=\text{English}</annotation></semantics></math>; and <math id="S3.SS1.p2.10.m10.1" class="ltx_Math" alttext="y=\text{Strongly agree}" display="inline"><semantics id="S3.SS1.p2.10.m10.1a"><mrow id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml"><mi id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">y</mi><mo id="S3.SS1.p2.10.m10.1.1.1" xref="S3.SS1.p2.10.m10.1.1.1.cmml">=</mo><mtext id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3a.cmml">Strongly agree</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1"><eq id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1.1"></eq><ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">ğ‘¦</ci><ci id="S3.SS1.p2.10.m10.1.1.3a.cmml" xref="S3.SS1.p2.10.m10.1.1.3"><mtext id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3">Strongly agree</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">y=\text{Strongly agree}</annotation></semantics></math> if <math id="S3.SS1.p2.11.m11.1" class="ltx_Math" alttext="d=\text{Arabic}" display="inline"><semantics id="S3.SS1.p2.11.m11.1a"><mrow id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml"><mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">d</mi><mo id="S3.SS1.p2.11.m11.1.1.1" xref="S3.SS1.p2.11.m11.1.1.1.cmml">=</mo><mtext id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3a.cmml">Arabic</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1"><eq id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1.1"></eq><ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">ğ‘‘</ci><ci id="S3.SS1.p2.11.m11.1.1.3a.cmml" xref="S3.SS1.p2.11.m11.1.1.3"><mtext id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">Arabic</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">d=\text{Arabic}</annotation></semantics></math>.
Therefore, we only augment the question <math id="S3.SS1.p2.12.m12.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p2.12.m12.1a"><mi id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><ci id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">x</annotation></semantics></math> to be <math id="S3.SS1.p2.13.m13.1" class="ltx_Math" alttext="x^{\prime}" display="inline"><semantics id="S3.SS1.p2.13.m13.1a"><msup id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml"><mi id="S3.SS1.p2.13.m13.1.1.2" xref="S3.SS1.p2.13.m13.1.1.2.cmml">x</mi><mo id="S3.SS1.p2.13.m13.1.1.3" xref="S3.SS1.p2.13.m13.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b"><apply id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">superscript</csymbol><ci id="S3.SS1.p2.13.m13.1.1.2.cmml" xref="S3.SS1.p2.13.m13.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.13.m13.1.1.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">x^{\prime}</annotation></semantics></math> but retain the same opinion <math id="S3.SS1.p2.14.m14.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS1.p2.14.m14.1a"><mi id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b"><ci id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">y</annotation></semantics></math> as the original <math id="S3.SS1.p2.15.m15.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p2.15.m15.1a"><mi id="S3.SS1.p2.15.m15.1.1" xref="S3.SS1.p2.15.m15.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m15.1b"><ci id="S3.SS1.p2.15.m15.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.15.m15.1c">x</annotation></semantics></math>.
We further denote vanilla LLM and CultureLLM as <math id="S3.SS1.p2.16.m16.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS1.p2.16.m16.1a"><mi id="S3.SS1.p2.16.m16.1.1" xref="S3.SS1.p2.16.m16.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m16.1b"><ci id="S3.SS1.p2.16.m16.1.1.cmml" xref="S3.SS1.p2.16.m16.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.16.m16.1c">f</annotation></semantics></math> and <math id="S3.SS1.p2.17.m17.1" class="ltx_Math" alttext="f^{\star}" display="inline"><semantics id="S3.SS1.p2.17.m17.1a"><msup id="S3.SS1.p2.17.m17.1.1" xref="S3.SS1.p2.17.m17.1.1.cmml"><mi id="S3.SS1.p2.17.m17.1.1.2" xref="S3.SS1.p2.17.m17.1.1.2.cmml">f</mi><mo id="S3.SS1.p2.17.m17.1.1.3" xref="S3.SS1.p2.17.m17.1.1.3.cmml">â‹†</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m17.1b"><apply id="S3.SS1.p2.17.m17.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.17.m17.1.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1">superscript</csymbol><ci id="S3.SS1.p2.17.m17.1.1.2.cmml" xref="S3.SS1.p2.17.m17.1.1.2">ğ‘“</ci><ci id="S3.SS1.p2.17.m17.1.1.3.cmml" xref="S3.SS1.p2.17.m17.1.1.3">â‹†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.17.m17.1c">f^{\star}</annotation></semantics></math>, respectively.
Then, denoting <math id="S3.SS1.p2.18.m18.1" class="ltx_Math" alttext="\ell" display="inline"><semantics id="S3.SS1.p2.18.m18.1a"><mi mathvariant="normal" id="S3.SS1.p2.18.m18.1.1" xref="S3.SS1.p2.18.m18.1.1.cmml">â„“</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.18.m18.1b"><ci id="S3.SS1.p2.18.m18.1.1.cmml" xref="S3.SS1.p2.18.m18.1.1">â„“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.18.m18.1c">\ell</annotation></semantics></math> as the loss function, our learning objective is formulated as:</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.2" class="ltx_Math" alttext="f^{\star}=\arg\min_{f}\mathbb{E}_{\begin{subarray}{c}(x_{j},y_{j}^{d})\in\mathcal{D}_{d}\\
(x^{\prime}_{j},y_{j}^{d})\in g(\mathcal{D}_{d})\end{subarray}}[\ell(f(x_{j}),y_{j}^{d})+\ell(f(x^{\prime}_{j}),y_{j}^{d})]." display="block"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.2.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><msup id="S3.Ex1.m1.2.2.1.1.3" xref="S3.Ex1.m1.2.2.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.3.2.cmml">f</mi><mo id="S3.Ex1.m1.2.2.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.3.3.cmml">â‹†</mo></msup><mo id="S3.Ex1.m1.2.2.1.1.2" xref="S3.Ex1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.2.2.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.3.1" xref="S3.Ex1.m1.2.2.1.1.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S3.Ex1.m1.2.2.1.1.1.3a" xref="S3.Ex1.m1.2.2.1.1.1.3.cmml">â¡</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.cmml"><munder id="S3.Ex1.m1.2.2.1.1.1.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.1.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1.2.cmml">min</mi><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.1.3" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1.3.cmml">f</mi></munder><mo lspace="0.167em" id="S3.Ex1.m1.2.2.1.1.1.3.2a" xref="S3.Ex1.m1.2.2.1.1.1.3.2.cmml">â¡</mo><msub id="S3.Ex1.m1.2.2.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2.2.cmml">ğ”¼</mi><mtable rowspacing="0pt" id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.2.cmml"><mtr id="S3.Ex1.m1.1.1.1.1.1.1a" xref="S3.Ex1.m1.1.1.1.2.cmml"><mtd id="S3.Ex1.m1.1.1.1.1.1.1b" xref="S3.Ex1.m1.1.1.1.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.4" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.3.cmml">j</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.5" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml">)</mo></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">âˆˆ</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.2.cmml">ğ’Ÿ</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.3.cmml">d</mi></msub></mrow></mtd></mtr><mtr id="S3.Ex1.m1.1.1.1.1.1.1c" xref="S3.Ex1.m1.1.1.1.2.cmml"><mtd id="S3.Ex1.m1.1.1.1.1.1.1d" xref="S3.Ex1.m1.1.1.1.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.3.cmml">(</mo><msubsup id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.3.cmml">j</mi><mo id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.3.cmml">â€²</mo></msubsup><mo id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.4" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.3.cmml">j</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.5" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.3.cmml">)</mo></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.4" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.4.cmml">âˆˆ</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.cmml">(</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.3.cmml">d</mi></msub><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr></mtable></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.4.cmml">â„“</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml">,</mo><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.cmml">y</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3.cmml">j</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.5" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.5" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.5.cmml">+</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.cmml"><mi mathvariant="normal" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.4.cmml">â„“</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.3.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.3.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.3.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.3.cmml">j</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.3.cmml">â€²</mo></msubsup><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.3.cmml">,</mo><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.2.cmml">y</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.3.cmml">j</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.3.cmml">d</mi></msubsup><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.5" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.Ex1.m1.2.2.1.2" xref="S3.Ex1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1"><eq id="S3.Ex1.m1.2.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.2"></eq><apply id="S3.Ex1.m1.2.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3.2">ğ‘“</ci><ci id="S3.Ex1.m1.2.2.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3">â‹†</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.2"></times><apply id="S3.Ex1.m1.2.2.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3"><arg id="S3.Ex1.m1.2.2.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.1"></arg><apply id="S3.Ex1.m1.2.2.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2"><apply id="S3.Ex1.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.3.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1">subscript</csymbol><min id="S3.Ex1.m1.2.2.1.1.1.3.2.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1.2"></min><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.1.3">ğ‘“</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.3.2.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2.2">ğ”¼</ci><list id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><matrix id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><matrixrow id="S3.Ex1.m1.1.1.1.1.1.1a.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><apply id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2"><in id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.3"></in><interval closure="open" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2"><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.2.3">ğ‘—</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.2.2.2.3">ğ‘‘</ci></apply></interval><apply id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.2">ğ’Ÿ</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.2.2.4.3">ğ‘‘</ci></apply></apply></matrixrow><matrixrow id="S3.Ex1.m1.1.1.1.1.1.1b.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><apply id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3"><in id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.4.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.4"></in><interval closure="open" id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2"><apply id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1">subscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.2.3">â€²</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3.3.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.2.3">ğ‘—</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.4.4.2.2.2.2.2.3">ğ‘‘</ci></apply></interval><apply id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3"><times id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.2"></times><ci id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.3">ğ‘”</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.2">ğ’Ÿ</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.5.5.3.3.3.1.1.1.3">ğ‘‘</ci></apply></apply></apply></matrixrow></matrix></list></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1"><plus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.5.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.5"></plus><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.3"></times><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.4.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.4">â„“</ci><interval closure="open" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2"><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">ğ‘“</ci><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2">superscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3">ğ‘—</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.2.2.2.2.3">ğ‘‘</ci></apply></interval></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.3"></times><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.4.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.4">â„“</ci><interval closure="open" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2"><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.2"></times><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.3">ğ‘“</ci><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.2.3">â€²</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.3.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2">superscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.2">ğ‘¦</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.2.3">ğ‘—</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.4.2.2.2.3">ğ‘‘</ci></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">f^{\star}=\arg\min_{f}\mathbb{E}_{\begin{subarray}{c}(x_{j},y_{j}^{d})\in\mathcal{D}_{d}\\
(x^{\prime}_{j},y_{j}^{d})\in g(\mathcal{D}_{d})\end{subarray}}[\ell(f(x_{j}),y_{j}^{d})+\ell(f(x^{\prime}_{j}),y_{j}^{d})].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Details
 of semantic data augmentation. First, semantic templates are generated 
via rephrasing, semantic filtering, and sentence parsing. Then, training
 samples are generated by context-aware synonyms replacement and 
semantic filtering.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sampling</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">The sampling process should follow two
 principles: 1) cover as many cultural topics as possible and 2) sample 
questions that can be clearly answered by LLMs.
Based on the two principles, we manually select <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="n=50" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">n=50</annotation></semantics></math> questions and rewrite them into the Question-Answer (QA) format, covering <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">7</annotation></semantics></math>
 topics, namely social values, security, science and technology, 
religious values, ethical values and norms, political interest and 
political participation, and migration.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Semantic Data Augmentation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">The samples from WVS are not enough to fine-tune, which are then augmented by our semantic data augmentation approach.
In a formal sense, semantic augmentation retains the original ground-truth opinions (<math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="y_{d}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">y</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ‘¦</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">y_{d}</annotation></semantics></math>) from different cultures and only generates semantically equivalent questions (<math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">x</annotation></semantics></math>).
A naive augmentation approach is to directly use strong LLMs such as GPT-4 to generate new samples <cite class="ltx_cite ltx_citemacro_citep">(Walters and Wilder, <a href="#bib.bib76" title="" class="ltx_ref">2023</a>)</cite>,
 which could introduce mode collapse, as generation quality can only be 
controlled by prompts.
Furthermore, since LLMs could suffer from cultural bias, directly 
generating cultural data using prompts could lead to unexpected or even 
erroneous outputs.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">As shown in <a href="#S3.F2" title="In 3.1 Overview â€£ 3 CultureLLM â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>,
 the augmentation consists of two stages: semantic template generation 
and intact sentence generation.
The first stage generates several semantically equivalent but 
stylistically different sentences and parses them into semantic 
templates.
The second stage then generates samples by replacing certain words in 
the semantic templates.
Such an augmentation introduces more diversities: The first stage 
introduces sentence-level diversities, and the second one introduces 
word-level diversities.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Semantic Template Generation</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.3" class="ltx_p">This stage generates semantically equivalent question templates <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}=\{t_{i}\}_{i=1}^{k}" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mrow id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml">ğ’¯</mi><mo id="S3.SS3.SSS1.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.SS3.SSS1.p1.1.m1.1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml"><mrow id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS3.SSS1.p1.1.m1.1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.3.cmml">k</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><apply id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1"><eq id="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.2"></eq><ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3">ğ’¯</ci><apply id="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1">superscript</csymbol><apply id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1">subscript</csymbol><set id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1"><apply id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3"><eq id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.1"></eq><ci id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS3.SSS1.p1.1.m1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">\mathcal{T}=\{t_{i}\}_{i=1}^{k}</annotation></semantics></math> based on <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="x\in\mathcal{D}_{d}" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mrow id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS3.SSS1.p1.2.m2.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msub id="S3.SS3.SSS1.p1.2.m2.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.2.m2.1.1.3.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.SS3.SSS1.p1.2.m2.1.1.3.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.cmml">d</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><apply id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1"><in id="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1"></in><ci id="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.2">ğ‘¥</ci><apply id="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS3.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">x\in\mathcal{D}_{d}</annotation></semantics></math>.
The generation process is nontrivial since there are two challenges 
ahead: 1) the naturalness and diversities and 2) the semantic 
preservation.
We solve the first challenge by leveraging GPT-4 as the generator with 
certain prompts to ensure naturalness and diversity.
Then, we solve the second challenge by introducing a semantic 
preservation filter <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">\mathcal{P}</annotation></semantics></math> to measure the similarity between the original and generated sentences.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>For computational efficiency, we use BERT embedding as <math id="footnote7.m1.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="footnote7.m1.1b"><mi class="ltx_font_mathcaligraphic" id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><ci id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">\mathcal{P}</annotation></semantics></math> while other models can also be used.</span></span></span></p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.8" class="ltx_p">Specifically, we first use the prompt â€œ<span id="S3.SS3.SSS1.p2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Could you please generate [<math id="S3.SS3.SSS1.p2.1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.SSS1.p2.1.1.m1.1a"><mi id="S3.SS3.SSS1.p2.1.1.m1.1.1" xref="S3.SS3.SSS1.p2.1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.1.m1.1b"><ci id="S3.SS3.SSS1.p2.1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.1.m1.1c">n</annotation></semantics></math>] sentences that (1) have different sentence structures and (2) have the same meaning with the following sentence: <math id="S3.SS3.SSS1.p2.2.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS3.SSS1.p2.2.2.m2.1a"><msub id="S3.SS3.SSS1.p2.2.2.m2.1.1" xref="S3.SS3.SSS1.p2.2.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p2.2.2.m2.1.1.2" xref="S3.SS3.SSS1.p2.2.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS3.SSS1.p2.2.2.m2.1.1.3" xref="S3.SS3.SSS1.p2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.2.2.m2.1b"><apply id="S3.SS3.SSS1.p2.2.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p2.2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p2.2.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS3.SSS1.p2.2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.2.2.m2.1c">x_{i}</annotation></semantics></math></span>â€ to generate <math id="S3.SS3.SSS1.p2.3.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.SSS1.p2.3.m1.1a"><mi id="S3.SS3.SSS1.p2.3.m1.1.1" xref="S3.SS3.SSS1.p2.3.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.3.m1.1b"><ci id="S3.SS3.SSS1.p2.3.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.3.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.3.m1.1c">n</annotation></semantics></math> sentences using GPT-4.
Then, we denote the embedding of the original sentence and the generated sentences as <math id="S3.SS3.SSS1.p2.4.m2.1" class="ltx_Math" alttext="z=\mathcal{P}(x)" display="inline"><semantics id="S3.SS3.SSS1.p2.4.m2.1a"><mrow id="S3.SS3.SSS1.p2.4.m2.1.2" xref="S3.SS3.SSS1.p2.4.m2.1.2.cmml"><mi id="S3.SS3.SSS1.p2.4.m2.1.2.2" xref="S3.SS3.SSS1.p2.4.m2.1.2.2.cmml">z</mi><mo id="S3.SS3.SSS1.p2.4.m2.1.2.1" xref="S3.SS3.SSS1.p2.4.m2.1.2.1.cmml">=</mo><mrow id="S3.SS3.SSS1.p2.4.m2.1.2.3" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p2.4.m2.1.2.3.2" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.2.cmml">ğ’«</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p2.4.m2.1.2.3.1" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS3.SSS1.p2.4.m2.1.2.3.3.2" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p2.4.m2.1.2.3.3.2.1" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.cmml">(</mo><mi id="S3.SS3.SSS1.p2.4.m2.1.1" xref="S3.SS3.SSS1.p2.4.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS3.SSS1.p2.4.m2.1.2.3.3.2.2" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.4.m2.1b"><apply id="S3.SS3.SSS1.p2.4.m2.1.2.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2"><eq id="S3.SS3.SSS1.p2.4.m2.1.2.1.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2.1"></eq><ci id="S3.SS3.SSS1.p2.4.m2.1.2.2.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2.2">ğ‘§</ci><apply id="S3.SS3.SSS1.p2.4.m2.1.2.3.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2.3"><times id="S3.SS3.SSS1.p2.4.m2.1.2.3.1.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.1"></times><ci id="S3.SS3.SSS1.p2.4.m2.1.2.3.2.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.2.3.2">ğ’«</ci><ci id="S3.SS3.SSS1.p2.4.m2.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m2.1.1">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.4.m2.1c">z=\mathcal{P}(x)</annotation></semantics></math> and <math id="S3.SS3.SSS1.p2.5.m3.1" class="ltx_Math" alttext="z^{\prime}=\mathcal{P}(t)" display="inline"><semantics id="S3.SS3.SSS1.p2.5.m3.1a"><mrow id="S3.SS3.SSS1.p2.5.m3.1.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.cmml"><msup id="S3.SS3.SSS1.p2.5.m3.1.2.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.2.cmml"><mi id="S3.SS3.SSS1.p2.5.m3.1.2.2.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.2.2.cmml">z</mi><mo id="S3.SS3.SSS1.p2.5.m3.1.2.2.3" xref="S3.SS3.SSS1.p2.5.m3.1.2.2.3.cmml">â€²</mo></msup><mo id="S3.SS3.SSS1.p2.5.m3.1.2.1" xref="S3.SS3.SSS1.p2.5.m3.1.2.1.cmml">=</mo><mrow id="S3.SS3.SSS1.p2.5.m3.1.2.3" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p2.5.m3.1.2.3.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.2.cmml">ğ’«</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p2.5.m3.1.2.3.1" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS3.SSS1.p2.5.m3.1.2.3.3.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p2.5.m3.1.2.3.3.2.1" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.cmml">(</mo><mi id="S3.SS3.SSS1.p2.5.m3.1.1" xref="S3.SS3.SSS1.p2.5.m3.1.1.cmml">t</mi><mo stretchy="false" id="S3.SS3.SSS1.p2.5.m3.1.2.3.3.2.2" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.5.m3.1b"><apply id="S3.SS3.SSS1.p2.5.m3.1.2.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2"><eq id="S3.SS3.SSS1.p2.5.m3.1.2.1.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.1"></eq><apply id="S3.SS3.SSS1.p2.5.m3.1.2.2.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.5.m3.1.2.2.1.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.2">superscript</csymbol><ci id="S3.SS3.SSS1.p2.5.m3.1.2.2.2.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.2.2">ğ‘§</ci><ci id="S3.SS3.SSS1.p2.5.m3.1.2.2.3.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.2.3">â€²</ci></apply><apply id="S3.SS3.SSS1.p2.5.m3.1.2.3.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.3"><times id="S3.SS3.SSS1.p2.5.m3.1.2.3.1.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.1"></times><ci id="S3.SS3.SSS1.p2.5.m3.1.2.3.2.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.2.3.2">ğ’«</ci><ci id="S3.SS3.SSS1.p2.5.m3.1.1.cmml" xref="S3.SS3.SSS1.p2.5.m3.1.1">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.5.m3.1c">z^{\prime}=\mathcal{P}(t)</annotation></semantics></math>, respectively. Then we compute their similarity score <math id="S3.SS3.SSS1.p2.6.m4.3" class="ltx_Math" alttext="c=\cos(z,z^{,})" display="inline"><semantics id="S3.SS3.SSS1.p2.6.m4.3a"><mrow id="S3.SS3.SSS1.p2.6.m4.3.3" xref="S3.SS3.SSS1.p2.6.m4.3.3.cmml"><mi id="S3.SS3.SSS1.p2.6.m4.3.3.3" xref="S3.SS3.SSS1.p2.6.m4.3.3.3.cmml">c</mi><mo id="S3.SS3.SSS1.p2.6.m4.3.3.2" xref="S3.SS3.SSS1.p2.6.m4.3.3.2.cmml">=</mo><mrow id="S3.SS3.SSS1.p2.6.m4.3.3.1.1" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml"><mi id="S3.SS3.SSS1.p2.6.m4.1.1" xref="S3.SS3.SSS1.p2.6.m4.1.1.cmml">cos</mi><mo id="S3.SS3.SSS1.p2.6.m4.3.3.1.1a" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml">â¡</mo><mrow id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.2" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml">(</mo><mi id="S3.SS3.SSS1.p2.6.m4.2.2" xref="S3.SS3.SSS1.p2.6.m4.2.2.cmml">z</mi><mo id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.3" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml">,</mo><msup id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.cmml"><mi id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.2" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.2.cmml">z</mi><mo id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.3" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.3.cmml">,</mo></msup><mo stretchy="false" id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.4" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.6.m4.3b"><apply id="S3.SS3.SSS1.p2.6.m4.3.3.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3"><eq id="S3.SS3.SSS1.p2.6.m4.3.3.2.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.2"></eq><ci id="S3.SS3.SSS1.p2.6.m4.3.3.3.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.3">ğ‘</ci><apply id="S3.SS3.SSS1.p2.6.m4.3.3.1.2.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1"><cos id="S3.SS3.SSS1.p2.6.m4.1.1.cmml" xref="S3.SS3.SSS1.p2.6.m4.1.1"></cos><ci id="S3.SS3.SSS1.p2.6.m4.2.2.cmml" xref="S3.SS3.SSS1.p2.6.m4.2.2">ğ‘§</ci><apply id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p2.6.m4.3.3.1.1.1.1.3">,</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.6.m4.3c">c=\cos(z,z^{,})</annotation></semantics></math>.
If <math id="S3.SS3.SSS1.p2.7.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS3.SSS1.p2.7.m5.1a"><mi id="S3.SS3.SSS1.p2.7.m5.1.1" xref="S3.SS3.SSS1.p2.7.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.7.m5.1b"><ci id="S3.SS3.SSS1.p2.7.m5.1.1.cmml" xref="S3.SS3.SSS1.p2.7.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.7.m5.1c">c</annotation></semantics></math> passes the threshold value <math id="S3.SS3.SSS1.p2.8.m6.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS3.SSS1.p2.8.m6.1a"><mi id="S3.SS3.SSS1.p2.8.m6.1.1" xref="S3.SS3.SSS1.p2.8.m6.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.8.m6.1b"><ci id="S3.SS3.SSS1.p2.8.m6.1.1.cmml" xref="S3.SS3.SSS1.p2.8.m6.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.8.m6.1c">\tau</annotation></semantics></math>, the generated sentence will be reserved:</p>
<table id="S3.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex2.m1.2" class="ltx_Math" alttext="\mathcal{T}=\{t_{i}|\cos(\mathcal{P}(t_{i}),\mathcal{P}(x_{j}))&gt;\tau\},\forall x_{j}\in\mathcal{D}_{d}." display="block"><semantics id="S3.Ex2.m1.2a"><mrow id="S3.Ex2.m1.2.2.1"><mrow id="S3.Ex2.m1.2.2.1.1.2" xref="S3.Ex2.m1.2.2.1.1.3.cmml"><mrow id="S3.Ex2.m1.2.2.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.2.2.1.1.1.1.4" xref="S3.Ex2.m1.2.2.1.1.1.1.4.cmml">ğ’¯</mi><mo id="S3.Ex2.m1.2.2.1.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.3.cmml">=</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.3.1.cmml">{</mo><msub id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo lspace="0em" rspace="0.167em" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.4" xref="S3.Ex2.m1.2.2.1.1.1.1.2.3.1.cmml">|</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.cmml"><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml">cos</mi><mo id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2a" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml">â¡</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml">(</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.3.cmml">ğ’«</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.4" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml">,</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.3.cmml">ğ’«</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.2.cmml">â€‹</mo><mrow id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.cmml">(</mo><msub id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.cmml"><mi id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.5" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.3" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.3.cmml">&gt;</mo><mi id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.4" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.4.cmml">Ï„</mi></mrow><mo stretchy="false" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.5" xref="S3.Ex2.m1.2.2.1.1.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo id="S3.Ex2.m1.2.2.1.1.2.3" xref="S3.Ex2.m1.2.2.1.1.3a.cmml">,</mo><mrow id="S3.Ex2.m1.2.2.1.1.2.2" xref="S3.Ex2.m1.2.2.1.1.2.2.cmml"><mrow id="S3.Ex2.m1.2.2.1.1.2.2.2" xref="S3.Ex2.m1.2.2.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.Ex2.m1.2.2.1.1.2.2.2.1" xref="S3.Ex2.m1.2.2.1.1.2.2.2.1.cmml">âˆ€</mo><msub id="S3.Ex2.m1.2.2.1.1.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2.cmml"><mi id="S3.Ex2.m1.2.2.1.1.2.2.2.2.2" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2.2.cmml">x</mi><mi id="S3.Ex2.m1.2.2.1.1.2.2.2.2.3" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2.3.cmml">j</mi></msub></mrow><mo id="S3.Ex2.m1.2.2.1.1.2.2.1" xref="S3.Ex2.m1.2.2.1.1.2.2.1.cmml">âˆˆ</mo><msub id="S3.Ex2.m1.2.2.1.1.2.2.3" xref="S3.Ex2.m1.2.2.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.2.2.1.1.2.2.3.2" xref="S3.Ex2.m1.2.2.1.1.2.2.3.2.cmml">ğ’Ÿ</mi><mi id="S3.Ex2.m1.2.2.1.1.2.2.3.3" xref="S3.Ex2.m1.2.2.1.1.2.2.3.3.cmml">d</mi></msub></mrow></mrow><mo lspace="0em" id="S3.Ex2.m1.2.2.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.2b"><apply id="S3.Ex2.m1.2.2.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3a.cmml" xref="S3.Ex2.m1.2.2.1.1.2.3">formulae-sequence</csymbol><apply id="S3.Ex2.m1.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1"><eq id="S3.Ex2.m1.2.2.1.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.3"></eq><ci id="S3.Ex2.m1.2.2.1.1.1.1.4.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.4">ğ’¯</ci><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2"><csymbol cd="latexml" id="S3.Ex2.m1.2.2.1.1.1.1.2.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.3">conditional-set</csymbol><apply id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2"><gt id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.3"></gt><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2"><cos id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1"></cos><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1"><times id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.2"></times><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.3">ğ’«</ci><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2"><times id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.2"></times><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.3">ğ’«</ci><apply id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.2.2.2.2.1.1.1.3">ğ‘—</ci></apply></apply></apply><ci id="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.4.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1.2.2.2.4">ğœ</ci></apply></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2"><in id="S3.Ex2.m1.2.2.1.1.2.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.1"></in><apply id="S3.Ex2.m1.2.2.1.1.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2"><csymbol cd="latexml" id="S3.Ex2.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2.1">for-all</csymbol><apply id="S3.Ex2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2.2">ğ‘¥</ci><ci id="S3.Ex2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.2.2.3">ğ‘—</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.2.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.3">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.3.2">ğ’Ÿ</ci><ci id="S3.Ex2.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2.3.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.2c">\mathcal{T}=\{t_{i}|\cos(\mathcal{P}(t_{i}),\mathcal{P}(x_{j}))&gt;\tau\},\forall x_{j}\in\mathcal{D}_{d}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.3" class="ltx_p">Specifically, for sample â€œ<span id="S3.SS3.SSS1.p3.3.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with One of my main goals in life has been to make my parents proud</span>?â€, we generate <math id="S3.SS3.SSS1.p3.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS3.SSS1.p3.1.m1.1a"><mi id="S3.SS3.SSS1.p3.1.m1.1.1" xref="S3.SS3.SSS1.p3.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.1.m1.1b"><ci id="S3.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.1.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.1.m1.1c">m</annotation></semantics></math> samples using GPT-4, which are then go through the semantic filter <math id="S3.SS3.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS3.SSS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p3.2.m2.1.1" xref="S3.SS3.SSS1.p3.2.m2.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.2.m2.1b"><ci id="S3.SS3.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p3.2.m2.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.2.m2.1c">\mathcal{P}</annotation></semantics></math> to eventually retain <math id="S3.SS3.SSS1.p3.3.m3.1" class="ltx_Math" alttext="k(k\leq m)" display="inline"><semantics id="S3.SS3.SSS1.p3.3.m3.1a"><mrow id="S3.SS3.SSS1.p3.3.m3.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p3.3.m3.1.1.3" xref="S3.SS3.SSS1.p3.3.m3.1.1.3.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.3.m3.1.1.2" xref="S3.SS3.SSS1.p3.3.m3.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.SSS1.p3.3.m3.1.1.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.2" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.2" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.2.cmml">k</mi><mo id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.1" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">â‰¤</mo><mi id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.3" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.3.cmml">m</mi></mrow><mo stretchy="false" id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.3" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.3.m3.1b"><apply id="S3.SS3.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1"><times id="S3.SS3.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.2"></times><ci id="S3.SS3.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.3">ğ‘˜</ci><apply id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1"><leq id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.1"></leq><ci id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.2">ğ‘˜</ci><ci id="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p3.3.m3.1.1.1.1.1.3">ğ‘š</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.3.m3.1c">k(k\leq m)</annotation></semantics></math> semantically equivalent sentences, e.g. â€œ<span id="S3.SS3.SSS1.p3.3.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with Making my parents dignified has always been one of my primary objectives in life</span>?" and â€œ<span id="S3.SS3.SSS1.p3.3.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with The goal to bring vanity to my parents has been a central life goal of mine</span>?"</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.3" class="ltx_p">To make the generated data more diverse, we then parse the <math id="S3.SS3.SSS1.p4.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.SSS1.p4.1.m1.1a"><mi id="S3.SS3.SSS1.p4.1.m1.1.1" xref="S3.SS3.SSS1.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.1.m1.1b"><ci id="S3.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.1.m1.1c">n</annotation></semantics></math> sentences to find the proper components to replace, which construct the templates.
For efficiency and cost-saving, we use NLTK&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Loper and Bird, <a href="#bib.bib48" title="" class="ltx_ref">2002</a>)</cite> to find replaceable words, such as adjectives, adverbs, nouns and verbs.
The semantic templates are like â€œ<span id="S3.SS3.SSS1.p4.3.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with The [x] to bring [x] to my parents has been a [x] life [x] of mine</span>?" where â€œ<span id="S3.SS3.SSS1.p4.3.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">[x]</span>â€ is the replaceable part.
In total, we generate <math id="S3.SS3.SSS1.p4.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS1.p4.2.m2.1a"><mi id="S3.SS3.SSS1.p4.2.m2.1.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.2.m2.1b"><ci id="S3.SS3.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.2.m2.1c">k</annotation></semantics></math> templates for each sample <math id="S3.SS3.SSS1.p4.3.m3.1" class="ltx_Math" alttext="x_{j}\in\mathcal{D}_{d}" display="inline"><semantics id="S3.SS3.SSS1.p4.3.m3.1a"><mrow id="S3.SS3.SSS1.p4.3.m3.1.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.cmml"><msub id="S3.SS3.SSS1.p4.3.m3.1.1.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.cmml"><mi id="S3.SS3.SSS1.p4.3.m3.1.1.2.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.2.cmml">x</mi><mi id="S3.SS3.SSS1.p4.3.m3.1.1.2.3" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS3.SSS1.p4.3.m3.1.1.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.1.cmml">âˆˆ</mo><msub id="S3.SS3.SSS1.p4.3.m3.1.1.3" xref="S3.SS3.SSS1.p4.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p4.3.m3.1.1.3.2" xref="S3.SS3.SSS1.p4.3.m3.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.SS3.SSS1.p4.3.m3.1.1.3.3" xref="S3.SS3.SSS1.p4.3.m3.1.1.3.3.cmml">d</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.3.m3.1b"><apply id="S3.SS3.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1"><in id="S3.SS3.SSS1.p4.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.1"></in><apply id="S3.SS3.SSS1.p4.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.3.m3.1.1.2.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS1.p4.3.m3.1.1.2.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.SSS1.p4.3.m3.1.1.2.3.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS3.SSS1.p4.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.3.m3.1.1.3.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.SSS1.p4.3.m3.1.1.3.2.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS3.SSS1.p4.3.m3.1.1.3.3.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.3.m3.1c">x_{j}\in\mathcal{D}_{d}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Intact Sample Generation</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.4" class="ltx_p">This step is to randomly replace 
synonyms in templates to generate fine-tuning samples.
Synonyms are diverse in different contexts, and existing synonym tables 
could ignore their contexts, thus we apply GPT-4 to generate 
context-aware synonyms for words in the templates and randomly replace 
some of them.
To further preserve semantics, we also use the semantic preservation 
filter in this step. After filtering, we generate <math id="S3.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">m</annotation></semantics></math> samples for each template <math id="S3.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="t_{i}\in\mathcal{T}" display="inline"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mrow id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml"><msub id="S3.SS3.SSS2.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS3.SSS2.p1.2.m2.1.1.2.2" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.2.cmml">t</mi><mi id="S3.SS3.SSS2.p1.2.m2.1.1.2.3" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS3.SSS2.p1.2.m2.1.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><apply id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1"><in id="S3.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.1"></in><apply id="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.2">ğ‘¡</ci><ci id="S3.SS3.SSS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.3">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">t_{i}\in\mathcal{T}</annotation></semantics></math>, and get <math id="S3.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="n^{\prime}=mnk" display="inline"><semantics id="S3.SS3.SSS2.p1.3.m3.1a"><mrow id="S3.SS3.SSS2.p1.3.m3.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.cmml"><msup id="S3.SS3.SSS2.p1.3.m3.1.1.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS3.SSS2.p1.3.m3.1.1.2.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.2.cmml">n</mi><mo id="S3.SS3.SSS2.p1.3.m3.1.1.2.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.3.cmml">â€²</mo></msup><mo id="S3.SS3.SSS2.p1.3.m3.1.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S3.SS3.SSS2.p1.3.m3.1.1.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml"><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.p1.3.m3.1.1.3.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.p1.3.m3.1.1.3.1a" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3.4" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.4.cmml">k</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m3.1b"><apply id="S3.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1"><eq id="S3.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.1"></eq><apply id="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS3.SSS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.2">ğ‘›</ci><ci id="S3.SS3.SSS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.3">â€²</ci></apply><apply id="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3"><times id="S3.SS3.SSS2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.1"></times><ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.2">ğ‘š</ci><ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.3">ğ‘›</ci><ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.4.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.4">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m3.1c">n^{\prime}=mnk</annotation></semantics></math> samples for all <math id="S3.SS3.SSS2.p1.4.m4.1" class="ltx_Math" alttext="x_{j}\in\mathcal{D}_{d}" display="inline"><semantics id="S3.SS3.SSS2.p1.4.m4.1a"><mrow id="S3.SS3.SSS2.p1.4.m4.1.1" xref="S3.SS3.SSS2.p1.4.m4.1.1.cmml"><msub id="S3.SS3.SSS2.p1.4.m4.1.1.2" xref="S3.SS3.SSS2.p1.4.m4.1.1.2.cmml"><mi id="S3.SS3.SSS2.p1.4.m4.1.1.2.2" xref="S3.SS3.SSS2.p1.4.m4.1.1.2.2.cmml">x</mi><mi id="S3.SS3.SSS2.p1.4.m4.1.1.2.3" xref="S3.SS3.SSS2.p1.4.m4.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS3.SSS2.p1.4.m4.1.1.1" xref="S3.SS3.SSS2.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msub id="S3.SS3.SSS2.p1.4.m4.1.1.3" xref="S3.SS3.SSS2.p1.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p1.4.m4.1.1.3.2" xref="S3.SS3.SSS2.p1.4.m4.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.SS3.SSS2.p1.4.m4.1.1.3.3" xref="S3.SS3.SSS2.p1.4.m4.1.1.3.3.cmml">d</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.4.m4.1b"><apply id="S3.SS3.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1"><in id="S3.SS3.SSS2.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.1"></in><apply id="S3.SS3.SSS2.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.4.m4.1.1.2.1.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS2.p1.4.m4.1.1.2.2.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.SSS2.p1.4.m4.1.1.2.3.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS3.SSS2.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS3.SSS2.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS3.SSS2.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.SSS2.p1.4.m4.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.4.m4.1c">x_{j}\in\mathcal{D}_{d}</annotation></semantics></math> in total.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">For instance, the intact samples for template â€œ<span id="S3.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with The [x] to bring [x] to my parents has been a [x] life [x] of mine</span>?" could be â€œ<span id="S3.SS3.SSS2.p2.1.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with The goal to bring pride to my parents has been a central life goal of mine</span>?" and â€œ<span id="S3.SS3.SSS2.p2.1.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Do you agree with The hope to bring vanity to my parents has been a central life goal of mine</span>?"</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">Our human study in <a href="#S4.SS6" title="4.6 The Effectiveness of the Augmented Data: A Human Study â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.6</span></a> shows that semantic data augmentation can generate high-quality and semantically equivalent sentences.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Converting WVS opinions to groundtruth</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Since culture is a complex construct, 
we use languages spoken by geographical cultures (represented by 
countries) in WVS to represent broader cultures and arrive at a set of <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mn id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><cn type="integer" id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">9</annotation></semantics></math>
 cultures in total. In cases where a language is spoken by more than one
 geographical culture, we pick representative countries and use the 
average of all answers as groundtruth. Our final set of cultures 
represented as described above is Arabic (for which we select Jordan and
 Iraq), Spanish (for which we select Mexico and Argentina), Bengali, 
Chinese, English, German, Korean, Portuguese, and Turkish.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Fine-tuning</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.5" class="ltx_p">Finally, CultureLLM is obtained by 
fine-tuning an LLM on the combination of the seed and the generated 
data.
Specifically, we fine-tune two types of CultureLLM: 1) culture-specific 
LLMs for each language such as CultureLLM-Ar and CultureLLM-Bn, and 2) 
one unified LLM for all languages, denoted as CultureLLM-One.
Culture-specific LLMs are tailored for one specific culture by setting <math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">d</annotation></semantics></math>, namely, <math id="S3.SS5.p1.2.m2.2" class="ltx_Math" alttext="\{\mathcal{D}_{d},\mathcal{D}^{\prime}_{d}\}" display="inline"><semantics id="S3.SS5.p1.2.m2.2a"><mrow id="S3.SS5.p1.2.m2.2.2.2" xref="S3.SS5.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.p1.2.m2.2.2.2.3" xref="S3.SS5.p1.2.m2.2.2.3.cmml">{</mo><msub id="S3.SS5.p1.2.m2.1.1.1.1" xref="S3.SS5.p1.2.m2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.2.m2.1.1.1.1.2" xref="S3.SS5.p1.2.m2.1.1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS5.p1.2.m2.1.1.1.1.3" xref="S3.SS5.p1.2.m2.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS5.p1.2.m2.2.2.2.4" xref="S3.SS5.p1.2.m2.2.2.3.cmml">,</mo><msubsup id="S3.SS5.p1.2.m2.2.2.2.2" xref="S3.SS5.p1.2.m2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.2.m2.2.2.2.2.2.2" xref="S3.SS5.p1.2.m2.2.2.2.2.2.2.cmml">ğ’Ÿ</mi><mi id="S3.SS5.p1.2.m2.2.2.2.2.3" xref="S3.SS5.p1.2.m2.2.2.2.2.3.cmml">d</mi><mo id="S3.SS5.p1.2.m2.2.2.2.2.2.3" xref="S3.SS5.p1.2.m2.2.2.2.2.2.3.cmml">â€²</mo></msubsup><mo stretchy="false" id="S3.SS5.p1.2.m2.2.2.2.5" xref="S3.SS5.p1.2.m2.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.2b"><set id="S3.SS5.p1.2.m2.2.2.3.cmml" xref="S3.SS5.p1.2.m2.2.2.2"><apply id="S3.SS5.p1.2.m2.1.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS5.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS5.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS5.p1.2.m2.1.1.1.1.3">ğ‘‘</ci></apply><apply id="S3.SS5.p1.2.m2.2.2.2.2.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.2.2.2.2.1.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2">subscript</csymbol><apply id="S3.SS5.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2">superscript</csymbol><ci id="S3.SS5.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2.2.2">ğ’Ÿ</ci><ci id="S3.SS5.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2.2.3">â€²</ci></apply><ci id="S3.SS5.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2.3">ğ‘‘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.2c">\{\mathcal{D}_{d},\mathcal{D}^{\prime}_{d}\}</annotation></semantics></math>.
On the other hand, CultureLLM-One is trained on all datasets: <math id="S3.SS5.p1.3.m3.2" class="ltx_Math" alttext="\{\mathcal{D}_{d},\mathcal{D}^{\prime}_{d}\}_{d\in\text{all language}}" display="inline"><semantics id="S3.SS5.p1.3.m3.2a"><msub id="S3.SS5.p1.3.m3.2.2" xref="S3.SS5.p1.3.m3.2.2.cmml"><mrow id="S3.SS5.p1.3.m3.2.2.2.2" xref="S3.SS5.p1.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.p1.3.m3.2.2.2.2.3" xref="S3.SS5.p1.3.m3.2.2.2.3.cmml">{</mo><msub id="S3.SS5.p1.3.m3.1.1.1.1.1" xref="S3.SS5.p1.3.m3.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.3.m3.1.1.1.1.1.2" xref="S3.SS5.p1.3.m3.1.1.1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS5.p1.3.m3.1.1.1.1.1.3" xref="S3.SS5.p1.3.m3.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS5.p1.3.m3.2.2.2.2.4" xref="S3.SS5.p1.3.m3.2.2.2.3.cmml">,</mo><msubsup id="S3.SS5.p1.3.m3.2.2.2.2.2" xref="S3.SS5.p1.3.m3.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.3.m3.2.2.2.2.2.2.2" xref="S3.SS5.p1.3.m3.2.2.2.2.2.2.2.cmml">ğ’Ÿ</mi><mi id="S3.SS5.p1.3.m3.2.2.2.2.2.3" xref="S3.SS5.p1.3.m3.2.2.2.2.2.3.cmml">d</mi><mo id="S3.SS5.p1.3.m3.2.2.2.2.2.2.3" xref="S3.SS5.p1.3.m3.2.2.2.2.2.2.3.cmml">â€²</mo></msubsup><mo stretchy="false" id="S3.SS5.p1.3.m3.2.2.2.2.5" xref="S3.SS5.p1.3.m3.2.2.2.3.cmml">}</mo></mrow><mrow id="S3.SS5.p1.3.m3.2.2.4" xref="S3.SS5.p1.3.m3.2.2.4.cmml"><mi id="S3.SS5.p1.3.m3.2.2.4.2" xref="S3.SS5.p1.3.m3.2.2.4.2.cmml">d</mi><mo id="S3.SS5.p1.3.m3.2.2.4.1" xref="S3.SS5.p1.3.m3.2.2.4.1.cmml">âˆˆ</mo><mtext id="S3.SS5.p1.3.m3.2.2.4.3" xref="S3.SS5.p1.3.m3.2.2.4.3a.cmml">all language</mtext></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.2b"><apply id="S3.SS5.p1.3.m3.2.2.cmml" xref="S3.SS5.p1.3.m3.2.2"><csymbol cd="ambiguous" id="S3.SS5.p1.3.m3.2.2.3.cmml" xref="S3.SS5.p1.3.m3.2.2">subscript</csymbol><set id="S3.SS5.p1.3.m3.2.2.2.3.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2"><apply id="S3.SS5.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS5.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1.3">ğ‘‘</ci></apply><apply id="S3.SS5.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p1.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2">subscript</csymbol><apply id="S3.SS5.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p1.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2">superscript</csymbol><ci id="S3.SS5.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2.2.2">ğ’Ÿ</ci><ci id="S3.SS5.p1.3.m3.2.2.2.2.2.2.3.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2.2.3">â€²</ci></apply><ci id="S3.SS5.p1.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS5.p1.3.m3.2.2.2.2.2.3">ğ‘‘</ci></apply></set><apply id="S3.SS5.p1.3.m3.2.2.4.cmml" xref="S3.SS5.p1.3.m3.2.2.4"><in id="S3.SS5.p1.3.m3.2.2.4.1.cmml" xref="S3.SS5.p1.3.m3.2.2.4.1"></in><ci id="S3.SS5.p1.3.m3.2.2.4.2.cmml" xref="S3.SS5.p1.3.m3.2.2.4.2">ğ‘‘</ci><ci id="S3.SS5.p1.3.m3.2.2.4.3a.cmml" xref="S3.SS5.p1.3.m3.2.2.4.3"><mtext mathsize="70%" id="S3.SS5.p1.3.m3.2.2.4.3.cmml" xref="S3.SS5.p1.3.m3.2.2.4.3">all language</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.2c">\{\mathcal{D}_{d},\mathcal{D}^{\prime}_{d}\}_{d\in\text{all language}}</annotation></semantics></math> to serve as a unified LLM for all cultures.
Note that since all languages have the same input question <math id="S3.SS5.p1.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS5.p1.4.m4.1a"><mi id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><ci id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">x</annotation></semantics></math> but different answers <math id="S3.SS5.p1.5.m5.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS5.p1.5.m5.1a"><mi id="S3.SS5.p1.5.m5.1.1" xref="S3.SS5.p1.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.5.m5.1b"><ci id="S3.SS5.p1.5.m5.1.1.cmml" xref="S3.SS5.p1.5.m5.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.5.m5.1c">y</annotation></semantics></math>, we need to manually write different prompts in the instruction to distinguish them.
For example, we add â€œ<span id="S3.SS5.p1.5.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">You are an Arabic chatbot that know Arabic very well</span> " before Arabic samples.
CultureLLM can be used in culture-related downstream applications.
In the following, we use CultureLLM to denote specific CultureLLM and CultureLLM-One for unified LLM.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p"><span id="S3.SS5.p2.1.1" class="ltx_text ltx_font_bold">Remark:</span> Note that WVS is all in English, where we focus on cultural differences in <em id="S3.SS5.p2.1.2" class="ltx_emph ltx_font_italic">opinions</em>
 regardless of their native language.
Thus, we do not perform fine-tuning for other languages due to the 
shortage of their training data and rely on cross-lingual transfer.
Multilingual tasks for cultures can still benefit from fine-tuned models
 in English, since the models can learn the basic values from the 
opinions&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(MoussaÃ¯d et&nbsp;al., <a href="#bib.bib52" title="" class="ltx_ref">2013</a>; Jin et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>.
Our experiments in <a href="#S5.SS1" title="5.1 Augmenting Multilingual Data vs. English Data â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.1</span></a>
 further demonstrate that fine-tuning on English data can outperform 
fine-tuning on native data that are translated from the original English
 version.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">We fine-tuned a CultureLLM-One and <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">9</annotation></semantics></math> specific CultureLLM for <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">9</annotation></semantics></math>
 languages: Arabic (Ar), Bengali (Bn), Chinese (Zh), English (En), 
German (De), Korean (Ko), Portuguese (Pt), Spanish (Es), and Turkish 
(Tr).
These cultures are diverse and represent both high- and low-resource 
regimes and thus can serve as representative evaluation.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p"><span id="S4.SS1.p1.5.1" class="ltx_text ltx_font_bold">Datasets.</span>
We adopt culture-related public datasets in specific languages for evaluation.
In total, we have <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="59" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">59</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">59</annotation></semantics></math> test sets, covering <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">9</annotation></semantics></math> languages and containing <math id="S4.SS1.p1.3.m3.2" class="ltx_Math" alttext="68,607" display="inline"><semantics id="S4.SS1.p1.3.m3.2a"><mrow id="S4.SS1.p1.3.m3.2.3.2" xref="S4.SS1.p1.3.m3.2.3.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">68</mn><mo id="S4.SS1.p1.3.m3.2.3.2.1" xref="S4.SS1.p1.3.m3.2.3.1.cmml">,</mo><mn id="S4.SS1.p1.3.m3.2.2" xref="S4.SS1.p1.3.m3.2.2.cmml">607</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.2b"><list id="S4.SS1.p1.3.m3.2.3.1.cmml" xref="S4.SS1.p1.3.m3.2.3.2"><cn type="integer" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">68</cn><cn type="integer" id="S4.SS1.p1.3.m3.2.2.cmml" xref="S4.SS1.p1.3.m3.2.2">607</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.2c">68,607</annotation></semantics></math> test samples.
We test on <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="56" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">56</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn type="integer" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">56</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">56</annotation></semantics></math> binary classification and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mn id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><cn type="integer" id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">3</annotation></semantics></math> multi-classification tasks to detect: offensive language, hate speech, stance, toxicity, threat, bias, abusive, and spam.
For example, we ask LLMs to judge whether the sentence contains offensive language, hate speech, or biased speech.
Details are shown in <a href="#A2.T3" title="In Appendix B Dataset â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#A2" title="Appendix B Dataset â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">B</span></a>.
Furthermore, we generate an open-ended generation dataset for evaluation in <a href="#S4.SS3" title="4.3 Results on Open-ended Generation Tasks â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">Baselines and implementation details.</span>
We fine-tune CultureLLM using the GPT-3.5 (0613)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib58" title="" class="ltx_ref">2023a</a>)</cite> fine-tuning API due to its efficiency and compared with two state-of-the-art LLMs, namely Gemini pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Google, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite> and GPT-4 (1104)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib59" title="" class="ltx_ref">2023b</a>)</cite>.
We also compare this with retrieval augmentation (RAG), which enhances 
LLMs by searching for related information and adding it to context&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite>.
To implement RAG, we search for information about each culture on Wikipedia and append them in a system prompt.
Finally, we fine-tuned CultureLLM using Llama-2-70b-chat&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib74" title="" class="ltx_ref">2023</a>)</cite> as the base model for reproduction(<a href="#S5.SS3" title="5.3 CultureLLM on Open-sourced LLMs: Llama2 â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.3</span></a>).
As for prompt setup, since our goal is to make LLMs better align with people from different cultures, we add a system prompt â€œ<span id="S4.SS1.p2.3.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">You are an [x] chatbot that know [x] very well</span> " where <span id="S4.SS1.p2.3.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">[x]</span> is a certain language before each input.
For metrics, we use macro F1 score for all tasks except for CValues&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib83" title="" class="ltx_ref">2023</a>)</cite> where we use the automatic evaluation script provided by the paper.
For data augmentation, we set <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="k=5" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">k</mi><mo id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><eq id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></eq><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">ğ‘˜</ci><cn type="integer" id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">k=5</annotation></semantics></math>, <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="m=2" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">m</mi><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><eq id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></eq><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">ğ‘š</ci><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">m=2</annotation></semantics></math>, and <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\tau=0.8" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">Ï„</mi><mo id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><eq id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></eq><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\tau=0.8</annotation></semantics></math>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="323" height="163" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The
 main results averaged by cultures (left) and by tasks (right). Both 
CultureLLM and CultureLLM-One significantly outperform CultureLLM and 
Gemini with CultureLLM achieving the best performance comparable to 
GPT-4.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Main Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.5" class="ltx_p">We present the average results for each culture and task in <a href="#S4.F3" title="In 4.1 Setup â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> <span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Results
 on RAG are not shown since they are close to GPT-3.5. Since the metrics
 are not the same (e.g., accuracy for CValues and F1 for other tasks), 
we normalized each one and then averaged them.</span></span></span> and more detailed results are shown in Appendix&nbsp;<a href="#A4" title="Appendix D Details Experimental Results â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.
Our conclusions are as follows.
First, both specific and unified CultureLLM achieve a great improvement 
over other approaches and specific CultureLLM achieves the best 
performance.
Concretely speaking, CultureLLM significantly outperforms GPT-3.5 (by <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="8.1" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">8.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="float" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">8.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">8.1</annotation></semantics></math>%), Gemini (by <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="9.5" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">9.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="float" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">9.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">9.5</annotation></semantics></math>%), and RAG (by <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="7.94" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">7.94</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn type="float" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">7.94</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">7.94</annotation></semantics></math>%), achieving performance comparable to GPT-4 and even better on some tasks.
Second, CultureLLM-One exceeds GPT-3.5 by more than <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="4\%" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mn id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">4</mn><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><csymbol cd="latexml" id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">4\%</annotation></semantics></math> on <math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="59" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mn id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">59</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><cn type="integer" id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">59</annotation></semantics></math>
 tasks, while inferior to culture-specific models, suggesting that a 
single LLM might not be the best solution to solve low-resource cultural
 tasks, since data from different cultures might intertwine with each 
other.
Third, in terms of cultures, CultureLLM achieves the best performance in
 English, Chinese, and Spanish cultures while showing no obvious 
improvement on Korean culture, where all four models have the similar 
performance.
We infer the reason could be that these base models have less exposure 
to Korean culture.
Finally, we analyze the performance on both low-resource and 
high-resource language tasks. As shown in <a href="#A4.F10" title="In D.2 Analysis on low-resource language tasks and high-resource language tasks â€£ Appendix D Details Experimental Results â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">10</span></a>,
 CultureLLM exhibits excellent performance in both types of tasks and 
outperforms GPT-4 on a large scale in high-resource tasks.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results on Open-ended Generation Tasks</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results on generation tasks measured by <span id="S4.T1.5.1" class="ltx_text ltx_markedasmath">WinRate</span>.</figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:208.1pt;height:20.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.1pt,7.7pt) scale(0.571321083755533,0.571321083755533) ;">
<table id="S4.T1.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T1.3.1.2" class="ltx_tr">
<td id="S4.T1.3.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Culture</td>
<td id="S4.T1.3.1.2.2" class="ltx_td ltx_align_center ltx_border_tt">Ar</td>
<td id="S4.T1.3.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">Bn</td>
<td id="S4.T1.3.1.2.4" class="ltx_td ltx_align_center ltx_border_tt">Zh</td>
<td id="S4.T1.3.1.2.5" class="ltx_td ltx_align_center ltx_border_tt">En</td>
<td id="S4.T1.3.1.2.6" class="ltx_td ltx_align_center ltx_border_tt">De</td>
<td id="S4.T1.3.1.2.7" class="ltx_td ltx_align_center ltx_border_tt">Ko</td>
<td id="S4.T1.3.1.2.8" class="ltx_td ltx_align_center ltx_border_tt">Pt</td>
<td id="S4.T1.3.1.2.9" class="ltx_td ltx_align_center ltx_border_tt">Es</td>
<td id="S4.T1.3.1.2.10" class="ltx_td ltx_align_center ltx_border_tt">Tr</td>
</tr>
<tr id="S4.T1.3.1.1" class="ltx_tr">
<td id="S4.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><math id="S4.T1.3.1.1.1.m1.1" class="ltx_Math" alttext="\text{WinRate}\uparrow" display="inline"><semantics id="S4.T1.3.1.1.1.m1.1a"><mrow id="S4.T1.3.1.1.1.m1.1.1" xref="S4.T1.3.1.1.1.m1.1.1.cmml"><mtext id="S4.T1.3.1.1.1.m1.1.1.2" xref="S4.T1.3.1.1.1.m1.1.1.2a.cmml">WinRate</mtext><mo stretchy="false" id="S4.T1.3.1.1.1.m1.1.1.1" xref="S4.T1.3.1.1.1.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T1.3.1.1.1.m1.1.1.3" xref="S4.T1.3.1.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.1.m1.1b"><apply id="S4.T1.3.1.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.1.m1.1.1"><ci id="S4.T1.3.1.1.1.m1.1.1.1.cmml" xref="S4.T1.3.1.1.1.m1.1.1.1">â†‘</ci><ci id="S4.T1.3.1.1.1.m1.1.1.2a.cmml" xref="S4.T1.3.1.1.1.m1.1.1.2"><mtext id="S4.T1.3.1.1.1.m1.1.1.2.cmml" xref="S4.T1.3.1.1.1.m1.1.1.2">WinRate</mtext></ci><csymbol cd="latexml" id="S4.T1.3.1.1.1.m1.1.1.3.cmml" xref="S4.T1.3.1.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.1.m1.1c">\text{WinRate}\uparrow</annotation></semantics></math></td>
<td id="S4.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.215</td>
<td id="S4.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.369</td>
<td id="S4.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.215</td>
<td id="S4.T1.3.1.1.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.492</td>
<td id="S4.T1.3.1.1.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.462</td>
<td id="S4.T1.3.1.1.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.615</td>
<td id="S4.T1.3.1.1.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.569</td>
<td id="S4.T1.3.1.1.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">.215</td>
<td id="S4.T1.3.1.1.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-.062</td>
</tr>
</tbody></table>
</span></div>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.6" class="ltx_p">To evaluate the performance of CultureLLM on open-ended tasks, we construct a dataset using GPT-4, containing <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="65" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mn id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">65</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><cn type="integer" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">65</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">65</annotation></semantics></math> open-ended questions, which cover the seven topics in WVS. The prompt setting for dataset generation can be found in <a href="#A3" title="Appendix C Prompt Setting â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">C</span></a>.
We evaluate the outputs of GPT-3.5 and CultureLLM using Gemini Pro<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We do not use GPT-4 to judge because it may prefer the response from GPT series models.</span></span></span>. We also devise a metric <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\text{WinRate}=(s_{CultureLLM}-s_{ChatGPT})/65" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mtext id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3a.cmml">WinRate</mtext><mo id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml"><mrow id="S4.SS3.p1.2.m2.1.1.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p1.2.m2.1.1.1.1.1.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p1.2.m2.1.1.1.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.cmml"><msub id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.2.cmml">s</mi><mrow id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1a" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.4" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1b" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.5" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1c" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.6" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1d" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.7" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1e" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.8" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1f" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.9" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.9.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1g" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.10" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.10.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1h" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.11" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.11.cmml">M</mi></mrow></msub><mo id="S4.SS3.p1.2.m2.1.1.1.1.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.2.cmml">s</mi><mrow id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.2" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1a" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.4" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1b" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.5" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1c" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.6" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.6.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1d" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.7" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.7.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1e" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.8" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.8.cmml">T</mi></mrow></msub></mrow><mo stretchy="false" id="S4.SS3.p1.2.m2.1.1.1.1.1.3" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS3.p1.2.m2.1.1.1.2" xref="S4.SS3.p1.2.m2.1.1.1.2.cmml">/</mo><mn id="S4.SS3.p1.2.m2.1.1.1.3" xref="S4.SS3.p1.2.m2.1.1.1.3.cmml">65</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><eq id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2"></eq><ci id="S4.SS3.p1.2.m2.1.1.3a.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><mtext id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">WinRate</mtext></ci><apply id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"><divide id="S4.SS3.p1.2.m2.1.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.2"></divide><apply id="S4.SS3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1"><minus id="S4.SS3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.1"></minus><apply id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.2">ğ‘ </ci><apply id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3"><times id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.1"></times><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.2">ğ¶</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.3">ğ‘¢</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.4.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.4">ğ‘™</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.5.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.5">ğ‘¡</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.6.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.6">ğ‘¢</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.7.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.7">ğ‘Ÿ</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.8.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.8">ğ‘’</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.9.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.9">ğ¿</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.10.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.10">ğ¿</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.11.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.2.3.11">ğ‘€</ci></apply></apply><apply id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.2">ğ‘ </ci><apply id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3"><times id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.1"></times><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.2">ğ¶</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.3">â„</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.4.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.4">ğ‘</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.5.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.5">ğ‘¡</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.6.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.6">ğº</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.7.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.7">ğ‘ƒ</ci><ci id="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.8.cmml" xref="S4.SS3.p1.2.m2.1.1.1.1.1.1.3.3.8">ğ‘‡</ci></apply></apply></apply><cn type="integer" id="S4.SS3.p1.2.m2.1.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.1.3">65</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\text{WinRate}=(s_{CultureLLM}-s_{ChatGPT})/65</annotation></semantics></math>, where <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">s</annotation></semantics></math> represents the number of acceptances by Gemini Pro. Positive <span id="S4.SS3.p1.6.1" class="ltx_text ltx_markedasmath">WinRate</span> means CultureLLM wins GPT-3.5 and vice versa.
As shown in <a href="#S4.T1" title="In 4.3 Results on Open-ended Generation Tasks â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>, CultureLLM performs better than GPT-3.5 on <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mn id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><cn type="integer" id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">8</annotation></semantics></math> out of <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mn id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><cn type="integer" id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">9</annotation></semantics></math> cultures, demonstrating its effectiveness in generation tasks.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="323" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Ablation
 study. â€˜+WVSâ€™ denotes the fine-tuned models using only the 50 samples 
from WVS, â€˜+WVS+aâ€™ denotes fine-tuning using the WVS samples and the 
generated samples in step 1 of our data augmentation (i.e., using only 
GPT-4 to generate), and â€˜+WVS+a+bâ€™ denotes the complete process of our 
algorithm.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We evaluate the effectiveness of our 
semantic data augmentation approach by comparing it with the following 
variants: GPT-3.5, CultureLLM (WVS), CultureLLM (WVS+a), and CultureLLM 
(WVS+a+b), where CultureLLM (WVS) denotes the fine-tuned models using 
only the 50 samples from WVS, CultureLLM (WVS+a) denotes fine-tuning 
using 50 WVS samples and the generated samples in step 1 of our data 
augmentation (i.e., only using semantic templates), and CultureLLM 
(WVS+a+b) denotes the complete process of our algorithm.
Note that â€˜WVS+aâ€™ denotes the naive baseline of only using GPT-4 to 
generate samples.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">As shown in <a href="#S4.F4" title="In 4.3 Results on Open-ended Generation Tasks â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>,
 fine-tuning using only the 50 seed data from WVS can inconsistently 
improve and impair performance on different tasks such as the decrease 
on Korean tasks.
While the WVS data are of very high quality, we see gains even with our 
generated data which leads to improvements on most tasks. Average 
performance on Korean tasks also get improved by CultureLLM.
<a href="#S4.F4" title="In 4.3 Results on Open-ended Generation Tasks â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a> also demonstrates that the two steps in our semantic data augmentation approach are useful and necessary.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Effectiveness Analysis</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">We analyze the effectiveness of 
CultureLLM by controlling the number of generated data, computing the 
perplexity score, and presenting case studies.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.3" class="ltx_p">First, we analyze the impact of the generation size.
As illustrated by <cite class="ltx_cite ltx_citemacro_citet">Chen et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2024</a>)</cite>, the diversity and quality of datasets are important in training LLMs.
Hence, infinite or too many generated samples might hurt the performance due to possible mode collapse.
In this section, we control the number of generated data and empirically analyze its impact.
Specifically, we fine-tune <math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><mn id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><cn type="integer" id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">4</annotation></semantics></math> CultureLLM with <math id="S4.SS5.p2.2.m2.4" class="ltx_Math" alttext="\{0,100,500,1000\}" display="inline"><semantics id="S4.SS5.p2.2.m2.4a"><mrow id="S4.SS5.p2.2.m2.4.5.2" xref="S4.SS5.p2.2.m2.4.5.1.cmml"><mo stretchy="false" id="S4.SS5.p2.2.m2.4.5.2.1" xref="S4.SS5.p2.2.m2.4.5.1.cmml">{</mo><mn id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml">0</mn><mo id="S4.SS5.p2.2.m2.4.5.2.2" xref="S4.SS5.p2.2.m2.4.5.1.cmml">,</mo><mn id="S4.SS5.p2.2.m2.2.2" xref="S4.SS5.p2.2.m2.2.2.cmml">100</mn><mo id="S4.SS5.p2.2.m2.4.5.2.3" xref="S4.SS5.p2.2.m2.4.5.1.cmml">,</mo><mn id="S4.SS5.p2.2.m2.3.3" xref="S4.SS5.p2.2.m2.3.3.cmml">500</mn><mo id="S4.SS5.p2.2.m2.4.5.2.4" xref="S4.SS5.p2.2.m2.4.5.1.cmml">,</mo><mn id="S4.SS5.p2.2.m2.4.4" xref="S4.SS5.p2.2.m2.4.4.cmml">1000</mn><mo stretchy="false" id="S4.SS5.p2.2.m2.4.5.2.5" xref="S4.SS5.p2.2.m2.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.4b"><set id="S4.SS5.p2.2.m2.4.5.1.cmml" xref="S4.SS5.p2.2.m2.4.5.2"><cn type="integer" id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1">0</cn><cn type="integer" id="S4.SS5.p2.2.m2.2.2.cmml" xref="S4.SS5.p2.2.m2.2.2">100</cn><cn type="integer" id="S4.SS5.p2.2.m2.3.3.cmml" xref="S4.SS5.p2.2.m2.3.3">500</cn><cn type="integer" id="S4.SS5.p2.2.m2.4.4.cmml" xref="S4.SS5.p2.2.m2.4.4">1000</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.4c">\{0,100,500,1000\}</annotation></semantics></math> generated samples appended to the original WVS data set.
As shown in <a href="#S4.F5" title="In 4.6 The Effectiveness of the Augmented Data: A Human Study â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>,
 as the number of fine-tuning data increases, performance across most of
 tasks get improved; but when the number is greater than <math id="S4.SS5.p2.3.m3.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S4.SS5.p2.3.m3.1a"><mn id="S4.SS5.p2.3.m3.1.1" xref="S4.SS5.p2.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m3.1b"><cn type="integer" id="S4.SS5.p2.3.m3.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m3.1c">500</annotation></semantics></math>, performance on all tasks decline.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.2" class="ltx_p">Then we analyze the diversity of the generated data by computing two metrics: perplexity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Marion et&nbsp;al., <a href="#bib.bib49" title="" class="ltx_ref">2023</a>; Wang et&nbsp;al., <a href="#bib.bib78" title="" class="ltx_ref">2023b</a>)</cite> and diversity gain&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bilmes, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite> (<a href="#A5" title="Appendix E Metrics for Dataset measure â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">E</span></a>), as shown in the upper right in <a href="#S4.F5" title="In 4.6 The Effectiveness of the Augmented Data: A Human Study â€£ 4 Experiments â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>, where we observe the consistency between these two metrics and the fine-tuning performance: the <math id="S4.SS5.p3.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S4.SS5.p3.1.m1.1a"><mn id="S4.SS5.p3.1.m1.1.1" xref="S4.SS5.p3.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.m1.1b"><cn type="integer" id="S4.SS5.p3.1.m1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.m1.1c">500</annotation></semantics></math> generated data lead to the best perplexity and diversity gain.
The reason may be that these <math id="S4.SS5.p3.2.m2.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S4.SS5.p3.2.m2.1a"><mn id="S4.SS5.p3.2.m2.1.1" xref="S4.SS5.p3.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.2.m2.1b"><cn type="integer" id="S4.SS5.p3.2.m2.1.1.cmml" xref="S4.SS5.p3.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.2.m2.1c">500</annotation></semantics></math>
 samples are enough for GPT-3.5 to understand the knowledge of seed 
data, and more samples can cause overfitting and decreased performance.
Additionally, although the augmentation approach only generates 
different samples by varying sentence and word styles, the diversities 
can also get increased. This suggests that the variations in samples can
 improve the diversity of datasets.</p>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p id="S4.SS5.p4.1" class="ltx_p">As in the cases shown in <a href="#A4.F11" title="In D.3 Case Study â€£ Appendix D Details Experimental Results â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">11</span></a>,
 responses from GPT-3.5 often analyze input from multiple perspectives 
and call on to be respectful and kind, rather than provide clear and 
straightforward opinions. In some cases, GPT-3.5 says it cannot 
determine the intentions behind the sentence without context, while 
CultureLLM provides clear opinions most of the time. The reason behind 
this may be that we fine-tune CultureLLM to learn opinions from specific
 culture, so it can be more aligned with corresponding culture when 
faced with cultural differences or cultural conflicts. However, GPT-3.5 
is aimed to serve people from different cultures. Thus, it prefers to 
give a neutral response to not conflict with any cultures. However, the 
worst consequence is that it can not provide useful responses on those 
problems related to cultural differences.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>The Effectiveness of the Augmented Data: A Human Study</h3>

<figure id="S4.F5" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Results on different numbers of fine-tuning samples with perplexity score and diversity gain.</figcaption>
</figure>
<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.6" class="ltx_p">We analyze the effectiveness of the augmented data through human evaluators.
We hire <math id="S4.SS6.p1.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS6.p1.1.m1.1a"><mn id="S4.SS6.p1.1.m1.1.1" xref="S4.SS6.p1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.1.m1.1b"><cn type="integer" id="S4.SS6.p1.1.m1.1.1.cmml" xref="S4.SS6.p1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.1.m1.1c">50</annotation></semantics></math>
 people having high exposure to English (i.e., majoring in English) to 
check if our generated sentences are semantically equivalent to the seed
 data.
The information of the participants and the training procedure are in <a href="#A7" title="Appendix G Details on human study â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">G</span></a>.
We sample <math id="S4.SS6.p1.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS6.p1.2.m2.1a"><mn id="S4.SS6.p1.2.m2.1.1" xref="S4.SS6.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.2.m2.1b"><cn type="integer" id="S4.SS6.p1.2.m2.1.1.cmml" xref="S4.SS6.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.2.m2.1c">100</annotation></semantics></math> pairs of (seed, generation) samples and let each participant rank their similarities by giving a score of <math id="S4.SS6.p1.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS6.p1.3.m3.1a"><mn id="S4.SS6.p1.3.m3.1.1" xref="S4.SS6.p1.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.3.m3.1b"><cn type="integer" id="S4.SS6.p1.3.m3.1.1.cmml" xref="S4.SS6.p1.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.3.m3.1c">1</annotation></semantics></math> to <math id="S4.SS6.p1.4.m4.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS6.p1.4.m4.1a"><mn id="S4.SS6.p1.4.m4.1.1" xref="S4.SS6.p1.4.m4.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.4.m4.1b"><cn type="integer" id="S4.SS6.p1.4.m4.1.1.cmml" xref="S4.SS6.p1.4.m4.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.4.m4.1c">5</annotation></semantics></math>, with <math id="S4.SS6.p1.5.m5.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS6.p1.5.m5.1a"><mn id="S4.SS6.p1.5.m5.1.1" xref="S4.SS6.p1.5.m5.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.5.m5.1b"><cn type="integer" id="S4.SS6.p1.5.m5.1.1.cmml" xref="S4.SS6.p1.5.m5.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.5.m5.1c">5</annotation></semantics></math> representing the most similar. We also use GPT-4 and Gemini Pro as evaluators. The average results in <a href="#S5.T2" title="In 5.1 Augmenting Multilingual Data vs. English Data â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> demonstrate that the semantic similarity passes <math id="S4.SS6.p1.6.m6.1" class="ltx_Math" alttext="96.5\%" display="inline"><semantics id="S4.SS6.p1.6.m6.1a"><mrow id="S4.SS6.p1.6.m6.1.1" xref="S4.SS6.p1.6.m6.1.1.cmml"><mn id="S4.SS6.p1.6.m6.1.1.2" xref="S4.SS6.p1.6.m6.1.1.2.cmml">96.5</mn><mo id="S4.SS6.p1.6.m6.1.1.1" xref="S4.SS6.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.6.m6.1b"><apply id="S4.SS6.p1.6.m6.1.1.cmml" xref="S4.SS6.p1.6.m6.1.1"><csymbol cd="latexml" id="S4.SS6.p1.6.m6.1.1.1.cmml" xref="S4.SS6.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.6.m6.1.1.2.cmml" xref="S4.SS6.p1.6.m6.1.1.2">96.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.6.m6.1c">96.5\%</annotation></semantics></math>, implying that our augmentation approach can increase the quantity while retaining the similarity.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">We also conduct experiments on generation tasks. <a href="#A4.F11" title="In D.3 Case Study â€£ Appendix D Details Experimental Results â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">11</span></a>
 shows the responses from GPT-3.5 and CultureLLM in four different 
cultures. The results show that CultureLLM can generate more accurate, 
direct and useful responses than GPT-3.5. To be specific, GPT-3.5 always
 generate long responses, which donâ€™t give useful information and just 
call on to be respectful, while CultureLLM give accurate and direct 
responses. This is very important for user experience.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Augmenting Multilingual Data vs. English Data</h3>

<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>The semantic similarity of generated samples and seed samples are judged by <math id="S5.T2.2.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S5.T2.2.m1.1b"><mn id="S5.T2.2.m1.1.1" xref="S5.T2.2.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S5.T2.2.m1.1c"><cn type="integer" id="S5.T2.2.m1.1.1.cmml" xref="S5.T2.2.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.m1.1d">50</annotation></semantics></math>
 human participants, GPT-4 and Gemini Pro. The scores range from 1 to 5,
 where 1 represents â€œdefinitely notâ€ and 5 represents â€œperfectlyâ€.</figcaption>
<div id="S5.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:195.1pt;height:24.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-44.5pt,5.6pt) scale(0.686765770256131,0.686765770256131) ;">
<table id="S5.T2.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S5.T2.3.1.1" class="ltx_tr">
<td id="S5.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Evaluator</td>
<td id="S5.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Human</td>
<td id="S5.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">GPT-4</td>
<td id="S5.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Gemini</td>
<td id="S5.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">AVG</td>
</tr>
<tr id="S5.T2.3.1.2" class="ltx_tr">
<td id="S5.T2.3.1.2.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Rating</td>
<td id="S5.T2.3.1.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">4.60 (0.28)</td>
<td id="S5.T2.3.1.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">4.99 (0.09)</td>
<td id="S5.T2.3.1.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">4.93 (0.26)</td>
<td id="S5.T2.3.1.2.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">4.84</td>
</tr>
</tbody></table>
</span></div>
</figure>
<figure id="S5.F6" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The
 results of LLMs fine-tuned on English data (CultureLLM (En ft)) and on 
local languages (CultureLLM (local ft)). It can be observed that 
fine-tuning on English data outperforms fine-tuning on local languages.</figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">CultureLLM are fine-tuned on English 
data, since the training corpus of LLMs such as the GPT series are 
mostly in English and English may be the choice for LLMs to understand 
other culturesâ€™ opinions. How about the performance of LLMs fine-tuned 
in a culturally specific language? We also fine-tuned GPT-3.5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib58" title="" class="ltx_ref">2023a</a>)</cite> on multilingual data which are translated from English data and compare with CultureLLM. The results are shown in <a href="#S5.F6" title="In 5.1 Augmenting Multilingual Data vs. English Data â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>,
 indicating that the models fine-tuned in English perform better than 
the models fine-tuned in other languages. The reason behind this may be 
the modelâ€™s inherent capabilities in English have been shown to be 
superior&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ahuja et&nbsp;al., <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>
 than other languages, which again emphasizes the importance of 
collecting large-scale data for pre-training.
This study demonstrates that in low-resource settings without collecting
 large-scale training data, the augmentation approach could be useful 
for fine-tuning.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Fine-tuning vs. Forgetting</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.2" class="ltx_p">A potential dilemma is that 
fine-tuning an LLM on specific tasks might face catastrophic forgetting 
of its original capabilities.
In this section, we explore the forgetting of CultureLLM on two general 
datasets: BIG-Bench-Hard (BBH)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib73" title="" class="ltx_ref">2022</a>)</cite> and GSM8K&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Cobbe et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>.
BBH contains <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mn id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn type="integer" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">21</annotation></semantics></math> tasks covering both semantic understanding and logical reasoning tasks.
GSK8K is a widely used data set to evaluate mathematical ability. For BBH, we sample <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mn id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><cn type="integer" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">100</annotation></semantics></math> samples for each task to test, due to cost savings.
We compare each CultureLLM with the baseline model GPT-3.5 in <a href="#S5.F7" title="In 5.2 Fine-tuning vs. Forgetting â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">7</span></a>.
Results show that CultureLLM does not decrease performance in most of 
the general benchmarks, but can even improve their results, such as the 
21 BBH tasks.
This suggests that there might be some latent relations between the 
cultural data and the general benchmarks, thus fine-tuning on cultural 
data can benefit general reasoning abilities.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Analysis
 on catastrophic forgetting on BBH and GSM8K. The red line denotes the 
results of GPT-3.5. For BBH, we show the average results of <math id="S5.F7.2.m1.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S5.F7.2.m1.1b"><mn id="S5.F7.2.m1.1.1" xref="S5.F7.2.m1.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S5.F7.2.m1.1c"><cn type="integer" id="S5.F7.2.m1.1.1.cmml" xref="S5.F7.2.m1.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.2.m1.1d">21</annotation></semantics></math> tasks in this figure. The x-axis represents models and the y-axis represents performance.</figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>CultureLLM on Open-sourced LLMs: Llama2</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Although all main experiments in this work are performed using the OpenAI fine-tuning API of GPT-3.5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib58" title="" class="ltx_ref">2023a</a>)</cite>
 due to its efficiency and simplicity, our CultureLLM also supports 
fine-tuning on open-source LLMs for better quality control and 
reproducibility.
In this section, we show an initial experiment using Llama2-70b-chat as 
the base model to fine-tune a CultureLLM-Llama2-70b.
The results in <a href="#S5.F8" title="In 5.4 Implication of This Research â€£ 5 Discussion â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">8</span></a> show that CultureLLM-Llama-70b outperforms the base Llama model by <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="2.17\%" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mn id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">2.17</mn><mo id="S5.SS3.p1.1.m1.1.1.1" xref="S5.SS3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">2.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">2.17\%</annotation></semantics></math> on average, showing the effectiveness of fine-tuning CultureLLM on open-source models.
The details of fine-tuning are in <a href="#A6" title="Appendix F Fine-tuning on Llama â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">F</span></a>.
The results indicate that CultureLLM is a general approach to improve LLMsâ€™ ability of cultural understanding.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Implication of This Research</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">In essence, recognizing and valuing 
cultural differences is paramount for the enrichment of our global 
community.
Embracing diversity stimulates innovation and creativity, contributing 
to the development of novel ideas and solutions.
Our work contributes to solving the cultural difference problem in LLMs 
and tackling the problem of data scarcity in low-resource cultures.
Limited availability of data from these cultures hinders understanding 
and addressing specific needs and concerns. For example, lack of 
representation in datasets may perpetuate biases and disparities, 
hindering the development of inclusive technologies and services. Our 
approach represents an effective and resource-saving method to bridge 
the data gap in low-resource cultures, empowering these communities and 
enabling more accurate, inclusive, and impactful decision-making 
processes.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="323" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The
 performance of CultureLLM-Llama-70b averaged by cultures (left) and by 
tasks (right), which outperforms the vanilla Llama model by <math id="S5.F8.2.m1.1" class="ltx_Math" alttext="2.17\%" display="inline"><semantics id="S5.F8.2.m1.1b"><mrow id="S5.F8.2.m1.1.1" xref="S5.F8.2.m1.1.1.cmml"><mn id="S5.F8.2.m1.1.1.2" xref="S5.F8.2.m1.1.1.2.cmml">2.17</mn><mo id="S5.F8.2.m1.1.1.1" xref="S5.F8.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F8.2.m1.1c"><apply id="S5.F8.2.m1.1.1.cmml" xref="S5.F8.2.m1.1.1"><csymbol cd="latexml" id="S5.F8.2.m1.1.1.1.cmml" xref="S5.F8.2.m1.1.1.1">percent</csymbol><cn type="float" id="S5.F8.2.m1.1.1.2.cmml" xref="S5.F8.2.m1.1.1.2">2.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.2.m1.1d">2.17\%</annotation></semantics></math> on average.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Limitation</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.2" class="ltx_p">Cultural difference is essential to the 
prosperity of the world.
In this paper, we proposed CultureLLM, a cost-effective solution to 
fine-tune culture-aware LLMs.
We sampled a small number (50) of samples from World Value Survey and 
then generated augmented data through our novel semantic data 
augmentation.
On <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="59" display="inline"><semantics id="S6.p1.1.m1.1a"><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">59</mn><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><cn type="integer" id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">59</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">59</annotation></semantics></math> datasets on <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S6.p1.2.m2.1a"><mn id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><cn type="integer" id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">9</annotation></semantics></math> cultures, CultureLLM outperformed GPT-3.5 and Gemini with comparable or even better results than GPT-4.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">This work has the following limitations.
First, due to resource and time constraints, we did not implement 
CultureLLM on large-scale open-source models.
Second, we only adopted classification tasks for evaluation since 
multilingual generative tasks are expensive for automatic evaluation.
Third, for Arabic and Spanish, which are the main spoken languages for 
many countries, we only select some representative countries to 
fine-tune for reality factors, and this might also bring bias.
Finally, the sample diversity is only in sentence and word levels. In 
the future, we plan to add more diversities to enrich the generated 
data.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank Prof. Diyi Yang from Stanford University for her constructive comments.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Impact Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">This paper leveraged GPT-4 to generate 
sentences and synonyms, whose quality were manually checked to ensure 
responsible usage.
Throughout this paper, the authors remain neutral towards the opinions 
from all different cultures and respect their diversities.
The human study was conducted following local laws and regulations.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">mis [2019]</span>
<span class="ltx_bibblock">
Turkish Spam V01.

</span>
<span class="ltx_bibblock">UCI Machine Learning Repository, 2019.

</span>
<span class="ltx_bibblock">DOI: https://doi.org/10.24432/C5WG7F.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbasi et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Mohammad&nbsp;Amin Abbasi, Arash Ghafouri, Mahdi Firouzmandi, Hassan Naderi, and Behrouz&nbsp;Minaei Bidgoli.

</span>
<span class="ltx_bibblock">Persianllama: Towards building first persian large language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.15713</em>, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahuja et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita 
Diddee, Samuel Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika 
Bali, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mega: Multilingual evaluation of generative ai.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.12528</em>, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">aimansnigdha [2018]</span>
<span class="ltx_bibblock">
aimansnigdha.

</span>
<span class="ltx_bibblock">Bangla-abusive-comment-dataset.

</span>
<span class="ltx_bibblock">https://github.com/aimansnigdha/Bangla-Abusive-Comment-Dataset, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ãlvarez-Carmona et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Miguel&nbsp;Ã Ãlvarez-Carmona, EstefanÄ±a GuzmÃ¡n-FalcÃ³n, Manuel Montes-y 
GÃ³mez, Hugo&nbsp;Jair Escalante, Luis Villasenor-Pineda, VerÃ³nica 
Reyes-Meza, and Antonio Rico-Sulayes.

</span>
<span class="ltx_bibblock">Overview of mex-a3t at ibereval 2018: Authorship and aggressiveness analysis in mexican spanish tweets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Notebook
 papers of 3rd sepln workshop on evaluation of human language 
technologies for iberian languages (ibereval), seville, spain</em>, volume&nbsp;6, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Basile et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, 
Viviana Patti, Francisco Manuel&nbsp;Rangel Pardo, Paolo Rosso, and 
Manuela Sanguinetti.

</span>
<span class="ltx_bibblock">Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th international workshop on semantic evaluation</em>, pages 54â€“63, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhattacharya et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shiladitya Bhattacharya, Siddharth Singh, Ritesh Kumar, Akanksha Bansal,
 Akash Bhagat, Yogesh Dawer, Bornini Lahiri, and Atul&nbsp;Kr. Ojha.

</span>
<span class="ltx_bibblock">Developing a multilingual annotated corpus of misogyny and aggression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</em>, pages 158â€“168, Marseille, France, May 2020. European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2020.trac-1.25/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.trac-1.25/</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bilmes [2022]</span>
<span class="ltx_bibblock">
Jeff Bilmes.

</span>
<span class="ltx_bibblock">Submodularity in machine learning and artificial intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.00132</em>, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Y&nbsp;Cao, L&nbsp;Zhou, S&nbsp;Lee, L&nbsp;Cabello, M&nbsp;Chen, and D&nbsp;Hershcovich.

</span>
<span class="ltx_bibblock">Assessing cross-cultural alignment between chatgpt and human societies: An empirical study. arxiv.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Preprint posted online on March</em>, 31, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caselli et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tommaso Caselli, Valerio Basile, Jelena MitroviÄ‡, Inga Kartoziya, and Michael Granitzer.

</span>
<span class="ltx_bibblock">I feel offended, donâ€™t be abusive! implicit/explicit messages in offensive and abusive language.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 6193â€“6202, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ã‡Ã¶ltekin [2020]</span>
<span class="ltx_bibblock">
Ã‡aÄŸrÄ± Ã‡Ã¶ltekin.

</span>
<span class="ltx_bibblock">A corpus of turkish offensive language on social media.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of The 12th Language Resources and Evaluation Conference</em>, pages 6174â€“6184, Marseille, France, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.758" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.758</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Alex&nbsp;J Chan, JosÃ© Luis&nbsp;Redondo GarcÃ­a, Fabrizio Silvestri, Colm Oâ€™Donnel, and Konstantina Palla.

</span>
<span class="ltx_bibblock">Harmonizing global voices: Culturally-aware models for enhanced content moderation.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.02401</em>, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. [2024]</span>
<span class="ltx_bibblock">
Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu.

</span>
<span class="ltx_bibblock">Self-play fine-tuning converts weak language models to strong language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.01335</em>, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhury et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shammur&nbsp;Absar Chowdhury, Hamdy Mubarak, Ahmed Abdelali, Soon-gyo Jung, Bernard&nbsp;J Jansen, and Joni Salminen.

</span>
<span class="ltx_bibblock">A multi-platform arabic news comment dataset for offensive language detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 6203â€“6212, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, 
Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro 
Nakano, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.14168</em>, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">daanVeer [2020]</span>
<span class="ltx_bibblock">
daanVeer.

</span>
<span class="ltx_bibblock">Korean hatespeech dataset.

</span>
<span class="ltx_bibblock">https://github.com/daanVeer/HateSpeech_dataset, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davidson et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber.

</span>
<span class="ltx_bibblock">Automated hate speech detection and the problem of offensive language.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International AAAI Conference on Web and Social Media</em>, ICWSM â€™17, pages 512â€“515, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Paula and Schlicht [2021]</span>
<span class="ltx_bibblock">
Angel Felipe&nbsp;Magnossao de&nbsp;Paula and Ipek&nbsp;Baris Schlicht.

</span>
<span class="ltx_bibblock">Ai-upv at iberlef-2021 detoxis task: Toxicity
 detection in immigration-related web news comments using transformers 
and statistical models.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.04530</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Pelle and Moreira [2017]</span>
<span class="ltx_bibblock">
Rogers&nbsp;P. de&nbsp;Pelle and Viviane&nbsp;P. Moreira.

</span>
<span class="ltx_bibblock">Offensive comments in the brazilian web: a dataset and baseline results.

</span>
<span class="ltx_bibblock">2017.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Delanoy [2020]</span>
<span class="ltx_bibblock">
Werner Delanoy.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">What Is Culture?</em>, page 17â€“34.

</span>
<span class="ltx_bibblock">Cambridge Handbooks in Language and Linguistics. Cambridge University Press, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1017/9781108555067.003</span>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fazio and Zanna [1981]</span>
<span class="ltx_bibblock">
Russell&nbsp;H Fazio and Mark&nbsp;P Zanna.

</span>
<span class="ltx_bibblock">Direct experience and attitude-behavior consistency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in experimental social psychology</em>, volume&nbsp;14, pages 161â€“202. Elsevier, 1981.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fersini et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Elisabetta Fersini, Paolo Rosso, Maria Anzovino, et&nbsp;al.

</span>
<span class="ltx_bibblock">Overview of the task on automatic misogyny identification at ibereval 2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Ibereval@ sepln</em>, 2150:214â€“228, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Yi&nbsp;R Fung, Tuhin Chakraborty, Hao Guo, Owen Rambow, Smaranda Muresan, and Heng Ji.

</span>
<span class="ltx_bibblock">Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.08604</em>, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, 
Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, 
et&nbsp;al.

</span>
<span class="ltx_bibblock">The pile: An 800gb dataset of diverse text for language modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.00027</em>, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google [2023]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Gemini.

</span>
<span class="ltx_bibblock">https://deepmind.google/technologies/gemini/#introduction, 2023.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">HASOC [2020]</span>
<span class="ltx_bibblock">
HASOC.

</span>
<span class="ltx_bibblock">Hasoc2020.

</span>
<span class="ltx_bibblock">https://hasocfire.github.io/hasoc/2020/index.html, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hofstede [1984]</span>
<span class="ltx_bibblock">
Geert Hofstede.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Cultureâ€™s consequences: International differences in work-related values</em>, volume&nbsp;5.

</span>
<span class="ltx_bibblock">sage, 1984.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Edward&nbsp;J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu&nbsp;Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Husain [2020]</span>
<span class="ltx_bibblock">
F&nbsp;Husain.

</span>
<span class="ltx_bibblock">Osact4 shared task on offensive language detection: Intensive preprocessing-based approach. arxiv 2020.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.07297</em>, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile 
Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Ai alignment: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.19852</em>, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Zhuoren Jiang, Zhe Gao, Guoxiu He, Yangyang Kang, Changlong Sun, Qiong Zhang, Luo Si, and Xiaozhong Liu.

</span>
<span class="ltx_bibblock">Detect camouflaged spam content via 
stoneskipping: Graph and text joint embedding for chinese character 
variation representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP2019)</em>. ACM, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Yiqiao Jin, Mohit Chandra, Gaurav Verma, Yibo Hu, Munmun De&nbsp;Choudhury, and Srijan Kumar.

</span>
<span class="ltx_bibblock">Better to ask in english: Cross-lingual evaluation of large language models for healthcare queries.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, pages arXivâ€“2310, 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Rebecca&nbsp;L Johnson, Giada Pistilli, Natalia MenÃ©dez-GonzÃ¡lez, Leslye
 Denisse&nbsp;Dias Duran, Enrico Panai, Julija Kalpokiene, and 
Donald&nbsp;Jay Bertulfo.

</span>
<span class="ltx_bibblock">The ghost in the machine has an american accent: value conflict in gpt-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.07785</em>, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaddoura and Henno [2024]</span>
<span class="ltx_bibblock">
Sanaa Kaddoura and Safaa Henno.

</span>
<span class="ltx_bibblock">Dataset of arabic spam and ham tweets.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Data in Brief</em>, 52(10990):4, 2024.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaggle [2019]</span>
<span class="ltx_bibblock">
Kaggle.

</span>
<span class="ltx_bibblock">Jigsaw-multilingual-toxicity.

</span>
<span class="ltx_bibblock">https://www.kaggle.com/code/tarunpaparaju/jigsaw-multilingual-toxicity-eda-models, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaggle [2021]</span>
<span class="ltx_bibblock">
Kaggle.

</span>
<span class="ltx_bibblock">5k turkish tweets with incivil content.

</span>
<span class="ltx_bibblock">https://www.kaggle.com/datasets/kbulutozler/5k-turkish-tweets-with-incivil-content, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaggle [2022]</span>
<span class="ltx_bibblock">
Kaggle.

</span>
<span class="ltx_bibblock">turkish offensive language detection.

</span>
<span class="ltx_bibblock">https://www.kaggle.com/datasets/toygarr/turkish-offensive-language-detection, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KarayiÄŸit et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Habibe KarayiÄŸit, Ã‡iÄŸdem&nbsp;Ä°nan AcÄ±, and Ali AkdaÄŸlÄ±.

</span>
<span class="ltx_bibblock">Detecting abusive instagram comments in turkish using convolutional neural network and machine learning methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>, 174:114802, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KovaÄ et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Grgur KovaÄ, Masataka Sawayama, RÃ©my Portelas, CÃ©dric Colas, Peter&nbsp;Ford Dominey, and Pierre-Yves Oudeyer.

</span>
<span class="ltx_bibblock">Large language models as superpositions of cultural perspectives.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.07870</em>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Jean Lee, Taejun Lim, Heejun Lee, Bogeun Jo, Yangsok Kim, Heegeun Yoon, and Soyeon&nbsp;Caren Han.

</span>
<span class="ltx_bibblock">K-MHaS: A multi-label hate speech detection dataset in Korean online news comment.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International Conference on Computational Linguistics</em>, pages 3530â€“3538, Gyeongju, Republic of Korea, October 2022. International Committee on Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2022.coling-1.311" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2022.coling-1.311</a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leite et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Joao&nbsp;A Leite, Diego&nbsp;F Silva, Kalina Bontcheva, and Carolina Scarton.

</span>
<span class="ltx_bibblock">Toxic language detection in social media for brazilian portuguese: New dataset and multilingual analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.04543</em>, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir 
Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim 
RocktÃ¤schel, et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 33:9459â€“9474, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and Mike Lewis.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.06259</em>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. [2024]</span>
<span class="ltx_bibblock">
Peiqin Lin, Shaoxiong Ji, JÃ¶rg Tiedemann, AndrÃ© F.&nbsp;T. Martins, and Hinrich SchÃ¼tze.

</span>
<span class="ltx_bibblock">Mala-500: Massive language adaptation of large language models, 2024.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Chen [2023]</span>
<span class="ltx_bibblock">
Yen-Ting Lin and Yun-Nung Chen.

</span>
<span class="ltx_bibblock">Taiwan llm: Bridging the linguistic divide with a culturally aligned language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.17487</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2023a]</span>
<span class="ltx_bibblock">
Bingbin Liu, Sebastien Bubeck, Ronen Eldan, Janardhan Kulkarni, Yuanzhi Li, Anh Nguyen, Rachel Ward, and Yi&nbsp;Zhang.

</span>
<span class="ltx_bibblock">Tinygsm: achieving&gt; 80% on gsm8k with small language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.09241</em>, 2023a.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2023b]</span>
<span class="ltx_bibblock">
Chen&nbsp;Cecilia Liu, Fajri Koto, Timothy Baldwin, and Iryna Gurevych.

</span>
<span class="ltx_bibblock">Are multilingual llms culturally-diverse reasoners? an investigation into multicultural proverbs and sayings.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.08591</em>, 2023b.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loper and Bird [2002]</span>
<span class="ltx_bibblock">
Edward Loper and Steven Bird.

</span>
<span class="ltx_bibblock">Nltk: The natural language toolkit.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint cs/0205028</em>, 2002.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marion et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Max Marion, Ahmet ÃœstÃ¼n, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, and Sara Hooker.

</span>
<span class="ltx_bibblock">When less is more: Investigating data pruning for pretraining llms at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.04564</em>, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masoud et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Reem&nbsp;I Masoud, Ziquan Liu, Martin Ferianc, Philip Treleaven, and Miguel Rodrigues.

</span>
<span class="ltx_bibblock">Cultural alignment in large language models: An explanatory analysis based on hofstedeâ€™s cultural dimensions.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12342</em>, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moon et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jihyung Moon, Won&nbsp;Ik Cho, and Junbum Lee.

</span>
<span class="ltx_bibblock">BEEP! Korean corpus of online news comments for toxic speech detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</em>, pages 25â€“31, Online, July 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.socialnlp-1.4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.socialnlp-1.4</a>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MoussaÃ¯d et&nbsp;al. [2013]</span>
<span class="ltx_bibblock">
Mehdi MoussaÃ¯d, Juliane&nbsp;E KÃ¤mmer, Pantelis&nbsp;P Analytis, and HansjÃ¶rg Neth.

</span>
<span class="ltx_bibblock">Social influence and the collective dynamics of opinion formation.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">PloS one</em>, 8(11):e78433, 2013.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mubarak et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Hamdy Mubarak, Hend Al-Khalifa, and AbdulMohsen Al-Thubaity.

</span>
<span class="ltx_bibblock">Overview of osact5 shared task on arabic offensive language and hate speech detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedinsg
 of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools 
with Shared Tasks on Qurâ€™an QA and Fine-Grained Hate Speech Detection</em>, pages 162â€“166, 2022.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naous et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Tarek Naous, Michael&nbsp;J Ryan, and Wei Xu.

</span>
<span class="ltx_bibblock">Having beer after prayer? measuring cultural bias in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14456</em>, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. [2023a]</span>
<span class="ltx_bibblock">
Tuan-Phong Nguyen, Simon Razniewski, Aparna Varde, and Gerhard Weikum.

</span>
<span class="ltx_bibblock">Extracting cultural commonsense knowledge at scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Web Conference 2023</em>, pages 1907â€“1917, 2023a.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. [2023b]</span>
<span class="ltx_bibblock">
Xuan-Phi Nguyen, Wenxuan Zhang, Xin Li, Mahani Aljunied, Qingyu Tan, 
Liying Cheng, Guanzheng Chen, Yue Deng, Sen Yang, Chaoqun Liu, 
et&nbsp;al.

</span>
<span class="ltx_bibblock">Seallmsâ€“large language models for southeast asia.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.00738</em>, 2023b.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niszczota and Janczak [2023]</span>
<span class="ltx_bibblock">
PaweÅ‚ Niszczota and Mateusz Janczak.

</span>
<span class="ltx_bibblock">Large language models can replicate cross-cultural differences in personality.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.10679</em>, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2023a]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Chatgpt.

</span>
<span class="ltx_bibblock">https://chat.openai.com/, 2023a.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2023b]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023b.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ousidhoum et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Nedjma Ousidhoum, Zizheng Lin, Hongming Zhang, Yangqiu Song, and Dit-Yan Yeung.

</span>
<span class="ltx_bibblock">Multilingual and multi-aspect hate speech analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Proceedings of EMNLP</em>. Association for Computational Linguistics, 2019.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pereira-Kohatsu et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Juan&nbsp;Carlos Pereira-Kohatsu, Lara Quijano-SÃ¡nchez, Federico Liberatore, and Miguel Camacho-Collados.

</span>
<span class="ltx_bibblock">Detecting and monitoring hate speech in twitter.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, 19(21):4654, 2019.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pipatanakul et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Kunat Pipatanakul, Phatrasek Jirabovonvisut, Potsawee Manakul, Sittipong
 Sripaisarnmongkol, Ruangsak Patomwong, Pathomporn Chokchainant, and 
Kasima Tharnpipitchai.

</span>
<span class="ltx_bibblock">Typhoon: Thai large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.13951</em>, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Plaza-del Arco et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Flor&nbsp;Miriam Plaza-del Arco, Arturo Montejo-RÃ¡ez, L&nbsp;Alfonso&nbsp;Urena Lopez, and MarÃ­a-Teresa MartÃ­n-Valdivia.

</span>
<span class="ltx_bibblock">Offendes: A new corpus in spanish for offensive language research.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</em>, pages 1096â€“1108, 2021.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rao et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Abhinav Rao, Aditi Khandelwal, Kumar Tanmay, Utkarsh Agarwal, and Monojit Choudhury.

</span>
<span class="ltx_bibblock">Ethical reasoning over moral alignment: A case and framework for in-context ethical policies in llms.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.07251</em>, 2023.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romim et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Nauros Romim, Mosahed Ahmed, Hriteshwar Talukder, and Md&nbsp;Saiful&nbsp;Islam.

</span>
<span class="ltx_bibblock">Hate speech detection in the bengali language: A dataset and its baseline evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of International Joint Conference on Advances in Computational Intelligence: IJCACI 2020</em>, pages 457â€“468. Springer, 2021.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosenthal et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Sara Rosenthal, Pepa Atanasova, Georgi Karadzhov, Marcos Zampieri, and Preslav Nakov.

</span>
<span class="ltx_bibblock">Solid: A large-scale semi-supervised dataset for offensive language identification.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.14454</em>, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ross et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
BjÃ¶rn Ross, Michael Rist, Guillermo Carbonell, Benjamin Cabrera, Nils Kurowsky, and Michael Wojatzki.

</span>
<span class="ltx_bibblock">Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis.

</span>
<span class="ltx_bibblock">In Michael BeiÃŸwenger, Michael Wojatzki, and Torsten Zesch, editors, <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Proceedings of NLP4CMC III: 3rd Workshop on Natural Language Processing for Computer-Mediated Communication</em>, volume&nbsp;17 of <em id="bib.bib67.2.2" class="ltx_emph ltx_font_italic">Bochumer Linguistische Arbeitsberichte</em>, pages 6â€“9, Bochum, sep 2016.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">RÃ¶ttger et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Paul RÃ¶ttger, Haitham Seelawi, Debora Nozza, Zeerak Talat, and Bertie Vidgen.

</span>
<span class="ltx_bibblock">Multilingual hatecheck: Functional tests for multilingual hate speech detection models.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.09917</em>, 2022.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharif and Hoque [2022]</span>
<span class="ltx_bibblock">
Omar Sharif and Mohammed&nbsp;Moshiul Hoque.

</span>
<span class="ltx_bibblock">Tackling cyber-aggression: Identification and
 fine-grained categorization of aggressive texts on social media using 
weighted ensemble of transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 490:462â€“481, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong.

</span>
<span class="ltx_bibblock">Large language model alignment: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.15025</em>, 2023.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Hoyun Song, Soo&nbsp;Hyun Ryu, Huije Lee, and Jong&nbsp;C Park.

</span>
<span class="ltx_bibblock">A large-scale comprehensive abusiveness detection dataset with multifaceted labels from reddit.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th Conference on Computational Natural Language Learning</em>, pages 552â€“561, 2021.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Survey [2022]</span>
<span class="ltx_bibblock">
World&nbsp;Values Survey.

</span>
<span class="ltx_bibblock">World values survey.

</span>
<span class="ltx_bibblock">https://www.worldvaluessurvey.org/wvs.jsp, 2022.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael SchÃ¤rli, Sebastian Gehrmann, 
Yi&nbsp;Tay, Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V Le, 
Ed&nbsp;H Chi, Denny Zhou, et&nbsp;al.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve them.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.09261</em>, 2022.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, 
Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, 
Shruti Bhosale, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models, 2023.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">URL https://arxiv. org/abs/2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vargas et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Francielle Vargas, Isabelle Carvalho, Fabiana Rodrigues&nbsp;de GÃ³es, Thiago Pardo, and FabrÃ­cio Benevenuto.

</span>
<span class="ltx_bibblock">HateBR: A large expert annotated corpus of Brazilian Instagram comments for offensive language and hate speech detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirteenth Language Resources and Evaluation Conference</em>, pages 7174â€“7183, Marseille, France, June 2022. European Language Resources Association.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2022.lrec-1.777" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2022.lrec-1.777</a>.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Walters and Wilder [2023]</span>
<span class="ltx_bibblock">
William&nbsp;H Walters and Esther&nbsp;Isabelle Wilder.

</span>
<span class="ltx_bibblock">Fabrication and errors in the bibliographic citations generated by chatgpt.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Scientific Reports</em>, 13(1):14045, 2023.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2023a]</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei.

</span>
<span class="ltx_bibblock">Improving text embeddings with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.00368</em>, 2023a.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2023b]</span>
<span class="ltx_bibblock">
Peiyi Wang, Lei Li, Liang Chen, Feifan Song, Binghuai Lin, Yunbo Cao, Tianyu Liu, and Zhifang Sui.

</span>
<span class="ltx_bibblock">Making large language models better reasoners with alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.02144</em>, 2023b.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2023c]</span>
<span class="ltx_bibblock">
Ruida Wang, Wangchunshu Zhou, and Mrinmaya Sachan.

</span>
<span class="ltx_bibblock">Letâ€™s synthesize step by step: Iterative dataset synthesis with large language models by extrapolating errors from small models.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.13671</em>, 2023c.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2023d]</span>
<span class="ltx_bibblock">
Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, and Michael&nbsp;R Lyu.

</span>
<span class="ltx_bibblock">Not all countries celebrate thanksgiving: On the cultural dominance in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.12481</em>, 2023d.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waseem and Hovy [2016]</span>
<span class="ltx_bibblock">
Zeerak Waseem and Dirk Hovy.

</span>
<span class="ltx_bibblock">Hateful symbols or hateful people? predictive features for hate speech detection on twitter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Proceedings of the NAACL student research workshop</em>, pages 88â€“93, 2016.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiegand et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Michael Wiegand, Melanie Siegel, and Josef Ruppenhofer.

</span>
<span class="ltx_bibblock">Overview of the germeval 2018 shared task on the identification of offensive language.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Guohai Xu, Jiayi Liu, Ming Yan, Haotian Xu, Jinghui Si, Zhuoran Zhou, 
Peng Yi, Xing Gao, Jitao Sang, Rong Zhang, Ji&nbsp;Zhang, Chao Peng, Fei
 Huang, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Cvalues: Measuring the values of chinese large language models from safety to responsibility.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">arXiv 2307.09705</em>, 2023.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Jing Yao, Xiaoyuan Yi, Xiting Wang, Jindong Wang, and Xing Xie.

</span>
<span class="ltx_bibblock">From instructions to intrinsic human valuesâ€“a survey of alignment goals for big models.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12014</em>, 2023.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, 
Yu&nbsp;Zhang, James&nbsp;T Kwok, Zhenguo Li, Adrian Weller, and Weiyang
 Liu.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12284</em>, 2023.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zampieri et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Marcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa Atanasova, Georgi 
Karadzhov, Hamdy Mubarak, Leon Derczynski, Zeses Pitenis, and Ã‡aÄŸrÄ± 
Ã‡Ã¶ltekin.

</span>
<span class="ltx_bibblock">Semeval-2020 task 12: Multilingual offensive language identification in social media (offenseval 2020).

</span>
<span class="ltx_bibblock"><em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.07235</em>, 2020.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Jingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang, Qun Liu, and Helen Meng.

</span>
<span class="ltx_bibblock">Towards identifying social bias in dialog systems: Frame, datasets, and benchmarks.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.08011</em>, 2022.

</span>
</li>
</ul>
</section>
<div id="id13" class="ltx_logical-block">
<div id="id13.p1" class="ltx_para">
<p id="id13.p1.1" class="ltx_p ltx_align_center"><span id="id13.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:120%;">CultureLLM: Incorporating Cultural Differences into Large Language Models</span></p>
<p id="id13.p1.2" class="ltx_p ltx_align_center"><span id="id13.p1.2.1" class="ltx_text" style="font-size:120%;">Appendix</span></p>
</div>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Seed Data from World Values Survey</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p"><span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tb-wvs</span> shows the 50 seed samples we used from WVS.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Dataset</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">The statistics of the datasets are shown in <a href="#A2.T3" title="In Appendix B Dataset â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> and we provide the detailed instructions of them in the following.</p>
</div>
<figure id="A2.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>A brief introduction of the <math id="A2.T3.3.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="A2.T3.3.m1.1b"><mn id="A2.T3.3.m1.1.1" xref="A2.T3.3.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A2.T3.3.m1.1c"><cn type="integer" id="A2.T3.3.m1.1.1.cmml" xref="A2.T3.3.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.3.m1.1d">8</annotation></semantics></math> evaluation tasks and <math id="A2.T3.4.m2.1" class="ltx_Math" alttext="59" display="inline"><semantics id="A2.T3.4.m2.1b"><mn id="A2.T3.4.m2.1.1" xref="A2.T3.4.m2.1.1.cmml">59</mn><annotation-xml encoding="MathML-Content" id="A2.T3.4.m2.1c"><cn type="integer" id="A2.T3.4.m2.1.1.cmml" xref="A2.T3.4.m2.1.1">59</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.4.m2.1d">59</annotation></semantics></math> datasets. We list both the name and the size of test sets. For instance, â€œOffensEval2020(2000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib86" title="" class="ltx_ref">2020</a>]</cite>â€ denotes that there are 2000 test samples in the dataset OffensEval2020.</figcaption>
<div id="A2.T3.5" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:531.1pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-158.8pt,194.3pt) scale(0.577173741752197,0.577173741752197) ;">
<table id="A2.T3.5.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A2.T3.5.1.1" class="ltx_tr">
<td id="A2.T3.5.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Culture</td>
<td id="A2.T3.5.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="A2.T3.5.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.1.2.1.1" class="ltx_p" style="width:79.7pt;">Country &amp; Territory</span>
</span>
</td>
<td id="A2.T3.5.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="A2.T3.5.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.1.3.1.1" class="ltx_p" style="width:483.7pt;">Task &amp; Dataset</span>
</span>
</td>
<td id="A2.T3.5.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">#Sample</td>
</tr>
<tr id="A2.T3.5.1.2" class="ltx_tr">
<td id="A2.T3.5.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.2.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.2.1.2" class="ltx_text">
<span id="A2.T3.5.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.2.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Arabic</span></span>
<span id="A2.T3.5.1.2.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Ar)</span></span>
</span></span><span id="A2.T3.5.1.2.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.2.2.1.1" class="ltx_p" style="width:79.7pt;">Middle East</span>
</span>
</td>
<td id="A2.T3.5.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.2.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.2.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.2.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.2.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.2.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.2.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> OffensEval2020(2000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib86" title="" class="ltx_ref">2020</a>]</cite>, OSACT4(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib29" title="" class="ltx_ref">2020</a>]</cite>, Multi-Platform(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib14" title="" class="ltx_ref">2020</a>]</cite>,</span></span>
<span id="A2.T3.5.1.2.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">and OSACT5(2541)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib53" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.2.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.2.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> OSACT4(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib29" title="" class="ltx_ref">2020</a>]</cite>, Multi-Platform(675)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib14" title="" class="ltx_ref">2020</a>]</cite>, OSACT5(2541)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib53" title="" class="ltx_ref">2022</a>]</cite>,</span></span>
<span id="A2.T3.5.1.2.3.1.1.2.1.4" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center">and OSACT5_finegrained(2541)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib53" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.2.3.1.1.2.1.5" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.2.3.1.1.2.1.5.1.1" class="ltx_text ltx_font_italic">Spam detection:</span> ASHT(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib34" title="" class="ltx_ref">2024</a>]</cite>.</span></span>
<span id="A2.T3.5.1.2.3.1.1.2.1.6" class="ltx_tr">
<span id="A2.T3.5.1.2.3.1.1.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.2.3.1.1.2.1.6.1.1" class="ltx_text ltx_font_italic">Vulgar detection:</span> Multi-Platform(675)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib14" title="" class="ltx_ref">2020</a>]</cite></span></span>
</span></span><span id="A2.T3.5.1.2.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.2.4" class="ltx_td ltx_align_center ltx_border_t">14,973</td>
</tr>
<tr id="A2.T3.5.1.3" class="ltx_tr">
<td id="A2.T3.5.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.3.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.3.1.2" class="ltx_text">
<span id="A2.T3.5.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.3.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Bangli</span></span>
<span id="A2.T3.5.1.3.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Bn)</span></span>
</span></span><span id="A2.T3.5.1.3.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.3.2.1.1" class="ltx_p" style="width:79.7pt;">Bangladesh</span>
</span>
</td>
<td id="A2.T3.5.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.3.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.3.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.3.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.3.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.3.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.3.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.3.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> TRAC2020 Task1(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib7" title="" class="ltx_ref">2020</a>]</cite>, TRAC2020 Task2(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib7" title="" class="ltx_ref">2020</a>]</cite>, BAD(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib69" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.3.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.3.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.3.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> Hate Speech(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib65" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.3.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.3.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.3.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Threat detection:</span> BACD(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib4" title="" class="ltx_ref">2018</a>]</cite>.</span></span>
<span id="A2.T3.5.1.3.3.1.1.2.1.4" class="ltx_tr">
<span id="A2.T3.5.1.3.3.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.3.3.1.1.2.1.4.1.1" class="ltx_text ltx_font_italic">Bias detection:</span> BACD(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib4" title="" class="ltx_ref">2018</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.3.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.3.4" class="ltx_td ltx_align_center ltx_border_t">6,000</td>
</tr>
<tr id="A2.T3.5.1.4" class="ltx_tr">
<td id="A2.T3.5.1.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.4.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.4.1.2" class="ltx_text">
<span id="A2.T3.5.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.4.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Chinese</span></span>
<span id="A2.T3.5.1.4.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Zh)</span></span>
</span></span><span id="A2.T3.5.1.4.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.4.2.1.1" class="ltx_p" style="width:79.7pt;">China</span>
</span>
</td>
<td id="A2.T3.5.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.4.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.4.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.4.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.4.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.4.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.4.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.4.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Spam detection:</span> CCS(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib31" title="" class="ltx_ref">2019</a>]</cite>.</span></span>
<span id="A2.T3.5.1.4.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.4.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.4.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Bias detection:</span> CDial-Bias(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib87" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.4.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.4.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.4.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Stance detection:</span> CValues(1712)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib83" title="" class="ltx_ref">2023</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.4.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.4.4" class="ltx_td ltx_align_center ltx_border_t">3,712</td>
</tr>
<tr id="A2.T3.5.1.5" class="ltx_tr">
<td id="A2.T3.5.1.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.5.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.5.1.2" class="ltx_text">
<span id="A2.T3.5.1.5.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.5.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.5.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">English</span></span>
<span id="A2.T3.5.1.5.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.5.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-En)</span></span>
</span></span><span id="A2.T3.5.1.5.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.5.2.1.1" class="ltx_p" style="width:79.7pt;">United States</span>
</span>
</td>
<td id="A2.T3.5.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.5.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.5.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.5.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.5.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.5.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.5.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.5.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> SOLID(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib66" title="" class="ltx_ref">2020</a>]</cite>.</span></span>
<span id="A2.T3.5.1.5.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.5.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.5.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> MLMA(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib60" title="" class="ltx_ref">2019</a>]</cite> and HOF(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib17" title="" class="ltx_ref">2017</a>]</cite>.</span></span>
<span id="A2.T3.5.1.5.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.5.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.5.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Threat detection:</span> CValuesJMT(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib35" title="" class="ltx_ref">2019</a>]</cite>.</span></span>
<span id="A2.T3.5.1.5.3.1.1.2.1.4" class="ltx_tr">
<span id="A2.T3.5.1.5.3.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.5.3.1.1.2.1.4.1.1" class="ltx_text ltx_font_italic">Toxicity detection:</span> MLMA(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib60" title="" class="ltx_ref">2019</a>]</cite> and JMT(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib35" title="" class="ltx_ref">2019</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.5.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.5.4" class="ltx_td ltx_align_center ltx_border_t">6,000</td>
</tr>
<tr id="A2.T3.5.1.6" class="ltx_tr">
<td id="A2.T3.5.1.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.6.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.6.1.2" class="ltx_text">
<span id="A2.T3.5.1.6.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.6.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">German</span></span>
<span id="A2.T3.5.1.6.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.6.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-De)</span></span>
</span></span><span id="A2.T3.5.1.6.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.6.2.1.1" class="ltx_p" style="width:79.7pt;">Germany and parts of Europe</span>
</span>
</td>
<td id="A2.T3.5.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.6.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.6.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.6.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.6.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.6.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.6.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.6.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> GermEval2018(3531)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib82" title="" class="ltx_ref">2018</a>]</cite>.</span></span>
<span id="A2.T3.5.1.6.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.6.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.6.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> IWG_1(469)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib67" title="" class="ltx_ref">2016</a>]</cite>, IWG_2(469)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib67" title="" class="ltx_ref">2016</a>]</cite>, HASOC2020(850)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib26" title="" class="ltx_ref">2020</a>]</cite>,</span></span>
<span id="A2.T3.5.1.6.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.6.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">and multilingual-hatecheck(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib68" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.6.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.6.4" class="ltx_td ltx_align_center ltx_border_t">6,319</td>
</tr>
<tr id="A2.T3.5.1.7" class="ltx_tr">
<td id="A2.T3.5.1.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.7.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.7.1.2" class="ltx_text">
<span id="A2.T3.5.1.7.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.7.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Korean</span></span>
<span id="A2.T3.5.1.7.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.7.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Ko)</span></span>
</span></span><span id="A2.T3.5.1.7.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.7.2.1.1" class="ltx_p" style="width:79.7pt;">South Korea</span>
</span>
</td>
<td id="A2.T3.5.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.7.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.7.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.7.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.7.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.7.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.7.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.7.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> K-MHaS(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib40" title="" class="ltx_ref">2022</a>]</cite>, hateSpeech(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib51" title="" class="ltx_ref">2020</a>]</cite>, and HateSpeech2(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib16" title="" class="ltx_ref">2020</a>]</cite>.</span></span>
<span id="A2.T3.5.1.7.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.7.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.7.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Abusive detection:</span> AbuseEval(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib10" title="" class="ltx_ref">2020</a>]</cite>, CADD(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib71" title="" class="ltx_ref">2021</a>]</cite>, and Waseem(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib81" title="" class="ltx_ref">2016</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.7.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.7.4" class="ltx_td ltx_align_center ltx_border_t">5,000</td>
</tr>
<tr id="A2.T3.5.1.8" class="ltx_tr">
<td id="A2.T3.5.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.8.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.8.1.2" class="ltx_text">
<span id="A2.T3.5.1.8.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.8.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.8.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Portuguese</span></span>
<span id="A2.T3.5.1.8.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.8.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Pt)</span></span>
</span></span><span id="A2.T3.5.1.8.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.8.2.1.1" class="ltx_p" style="width:79.7pt;">Brazil and parts of Latin America</span>
</span>
</td>
<td id="A2.T3.5.1.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.8.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.8.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.8.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.8.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.8.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.8.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.8.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> OffComBR(1250)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib19" title="" class="ltx_ref">2017</a>]</cite>, and HateBR(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib75" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.8.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.8.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.8.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Bias detection:</span> ToLD-Br-homophobia(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib41" title="" class="ltx_ref">2020</a>]</cite>, and ToLD-Br-misogyny(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib41" title="" class="ltx_ref">2020</a>]</cite>.</span></span>
<span id="A2.T3.5.1.8.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.8.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.8.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Abusive detection:</span> ToLD-Br-insult(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib41" title="" class="ltx_ref">2020</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.8.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.8.4" class="ltx_td ltx_align_center ltx_border_t">16,250</td>
</tr>
<tr id="A2.T3.5.1.9" class="ltx_tr">
<td id="A2.T3.5.1.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.9.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.9.1.2" class="ltx_text">
<span id="A2.T3.5.1.9.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.9.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.9.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Spanish</span></span>
<span id="A2.T3.5.1.9.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.9.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Es)</span></span>
</span></span><span id="A2.T3.5.1.9.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.9.2.1.1" class="ltx_p" style="width:79.7pt;">Argentina, Mexico, and parts of Latin America</span>
</span>
</td>
<td id="A2.T3.5.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.9.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.9.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.9.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.9.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.9.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> AMI(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib22" title="" class="ltx_ref">2018</a>]</cite>, MEX-A3T(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib5" title="" class="ltx_ref">2018</a>]</cite>, and OffendES(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib63" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.9.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">Hate detection:</span> HatEval 2019(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib6" title="" class="ltx_ref">2019</a>]</cite>, and HaterNet(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib61" title="" class="ltx_ref">2019</a>]</cite>.</span></span>
<span id="A2.T3.5.1.9.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Bias detection:</span> DETOXIS_stereotype(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>, and DETOXIS_improper(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.9.3.1.1.2.1.4" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.4.1.1" class="ltx_text ltx_font_italic">Abusive detection:</span> DETOXIS_abusive(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>, DETOXIS_mockery(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.9.3.1.1.2.1.5" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.5.1.1" class="ltx_text ltx_font_italic">Aggressiveness detection:</span> DETOXIS_aggressiveness(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.9.3.1.1.2.1.6" class="ltx_tr">
<span id="A2.T3.5.1.9.3.1.1.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.9.3.1.1.2.1.6.1.1" class="ltx_text ltx_font_italic">Stance detection:</span> DETOXIS_stance(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.9.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.9.4" class="ltx_td ltx_align_center ltx_border_t">11,000</td>
</tr>
<tr id="A2.T3.5.1.10" class="ltx_tr">
<td id="A2.T3.5.1.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.10.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.10.1.2" class="ltx_text">
<span id="A2.T3.5.1.10.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.10.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.10.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Turkish</span></span>
<span id="A2.T3.5.1.10.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.10.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-Tr)</span></span>
</span></span><span id="A2.T3.5.1.10.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.10.2.1.1" class="ltx_p" style="width:79.7pt;">Turkey</span>
</span>
</td>
<td id="A2.T3.5.1.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.10.3.1.1" class="ltx_p" style="width:483.7pt;"><span id="A2.T3.5.1.10.3.1.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.10.3.1.1.2" class="ltx_text">
<span id="A2.T3.5.1.10.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.10.3.1.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.10.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.10.3.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Offensive language detection:</span> SemEval-2020(3528)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib86" title="" class="ltx_ref">2020</a>]</cite>, offenseCorpus(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib11" title="" class="ltx_ref">2020</a>]</cite>, offenseKaggle(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib36" title="" class="ltx_ref">2021</a>]</cite>,</span></span>
<span id="A2.T3.5.1.10.3.1.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.10.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">and offenseKaggle_2(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib37" title="" class="ltx_ref">2022</a>]</cite>.</span></span>
<span id="A2.T3.5.1.10.3.1.1.2.1.3" class="ltx_tr">
<span id="A2.T3.5.1.10.3.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.10.3.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">Abusive detection:</span> ATC(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib38" title="" class="ltx_ref">2021</a>]</cite>.</span></span>
<span id="A2.T3.5.1.10.3.1.1.2.1.4" class="ltx_tr">
<span id="A2.T3.5.1.10.3.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.10.3.1.1.2.1.4.1.1" class="ltx_text ltx_font_italic">Spam detection:</span> Turkish Spam(825)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib1" title="" class="ltx_ref">2019</a>]</cite>.</span></span>
<span id="A2.T3.5.1.10.3.1.1.2.1.5" class="ltx_tr">
<span id="A2.T3.5.1.10.3.1.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A2.T3.5.1.10.3.1.1.2.1.5.1.1" class="ltx_text ltx_font_italic">Fine-grained offensive detection:</span> offenseCorpus(1000)&nbsp;<cite class="ltx_cite ltx_citemacro_citeyearpar">[<a href="#bib.bib11" title="" class="ltx_ref">2020</a>]</cite>.</span></span>
</span></span><span id="A2.T3.5.1.10.3.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="A2.T3.5.1.10.4" class="ltx_td ltx_align_center ltx_border_t">10,353</td>
</tr>
<tr id="A2.T3.5.1.11" class="ltx_tr">
<td id="A2.T3.5.1.11.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.11.1.1" class="ltx_text"></span> <span id="A2.T3.5.1.11.1.2" class="ltx_text">
<span id="A2.T3.5.1.11.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A2.T3.5.1.11.1.2.1.1" class="ltx_tr">
<span id="A2.T3.5.1.11.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">All</span></span>
<span id="A2.T3.5.1.11.1.2.1.2" class="ltx_tr">
<span id="A2.T3.5.1.11.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(CultureLLM-One)</span></span>
</span></span><span id="A2.T3.5.1.11.1.3" class="ltx_text"></span></td>
<td id="A2.T3.5.1.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.11.2.1.1" class="ltx_p" style="width:79.7pt;">All</span>
</span>
</td>
<td id="A2.T3.5.1.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="A2.T3.5.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T3.5.1.11.3.1.1" class="ltx_p" style="width:483.7pt;">All</span>
</span>
</td>
<td id="A2.T3.5.1.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">68,607</td>
</tr>
</tbody></table>
</span></div>
</figure>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Arabic</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">OffenseEval2020&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Zampieri et&nbsp;al., <a href="#bib.bib86" title="" class="ltx_ref">2020</a>]</cite>
 dataset was created to address the issue of offensive language in 
social media. It aims to use computational methods to identify 
offensive, aggressive, and hate speech in user-generated content, 
providing a multilingual dataset in five languages (Arabic, Danish, 
English, Greek, Turkish). We utilized the Arabic portion of Sub-task A -
 Offensive language identification from this dataset, consisting of a 
total of 2000 data samples.</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<p id="A2.SS1.p2.1" class="ltx_p">OSCAT4&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Husain, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>]</cite>
 dataset aims to detect and categorize offensive language in Arabic 
tweets, with two sub-tasks: detecting if a post is offensive or not, and
 identifying the offensive content type as hate speech or not hate 
speech. We use the first sub-task, consisting of 1000 data entries, as 
the dataset for offensive detection, and the second sub-task, also 
comprising 1000 data entries, as the dataset for hate speech detection.</p>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<p id="A2.SS1.p3.1" class="ltx_p">Multi-Platform&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Chowdhury et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2020</a>]</cite>
 dataset is a collection of 4000 comments in Dialectal Arabic from 
social media platforms, focusing on offensive language. It is intended 
for studying offensive language in news comments published by 
international news organizations. We utilized a total of 1000 annotated 
data samples indicating whether they are offensive and 675 annotated 
data samples indicating whether they are vulgar.</p>
</div>
<div id="A2.SS1.p4" class="ltx_para">
<p id="A2.SS1.p4.1" class="ltx_p">OSACT5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Mubarak et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2022</a>]</cite>
 dataset consists of 12,698 Arabic tweets collected between June 2016 
and November 2017, labeled for offensiveness and fine-grained hate 
speech types using emojis commonly found in offensive communications, 
providing a resource for offensive and hate speech detection and 
classification tasks. The dataset consists of three subtasks: 
offensiveness detection, hate speech detection, and fine-grained hate 
speech detection. We utilized 2,541 data samples for each of these 
tasks.</p>
</div>
<div id="A2.SS1.p5" class="ltx_para">
<p id="A2.SS1.p5.1" class="ltx_p">ASHT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Kaddoura and Henno, <a href="#bib.bib34" title="" class="ltx_ref">2024</a>]</cite>
 dataset contains 132,421 Arabic tweets collected from Twitter, 
classified as either ham (non-spam) or spam, providing a valuable 
resource for researchers in Arabic natural language processing (NLP) and
 serving as a benchmark for research in Arabic NLP, cybersecurity, data 
science, and social network analysis. We utilized a subset of 1,000 data
 samples for the spam detection section.</p>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Bengali</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">TRAC2020&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Bhattacharya et&nbsp;al., <a href="#bib.bib7" title="" class="ltx_ref">2020</a>]</cite>
 dataset is a multilingual annotated corpus of social media comments, 
encompassing misogynistic and aggressive comments in Indian English, 
Hindi, and Indian Bangla. It consists of over 20,000 comments and is 
annotated at two levels - aggression (overtly aggressive, covertly 
aggressive, and non-aggressive) and misogyny (gendered and 
non-gendered). Baseline experiments were conducted to develop misogyny 
classifiers for the three languages. TRAC2020 consists of two tasks: 
Aggression Detection and Misogynistic Aggression Detection. We utilized 
1,000 data samples for each of Task 1 and Task 2.</p>
</div>
<div id="A2.SS2.p2" class="ltx_para">
<p id="A2.SS2.p2.1" class="ltx_p">BAD&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Sharif and Hoque, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>]</cite>
 dataset is a novel Bengali aggressive text dataset (called â€™BADâ€™) with 
two-level annotation, designed to identify and classify aggressive 
content in Bengali language. It achieves high accuracy through a 
weighted ensemble technique and outperforms other machine learning and 
deep learning baselines, with a weighted f1-score of 93.43% for 
identification and 93.11% for categorization tasks. We utilized a subset
 of one thousand data samples as the Offensive dataset.</p>
</div>
<div id="A2.SS2.p3" class="ltx_para">
<p id="A2.SS2.p3.1" class="ltx_p">Hate Speech&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Romim et&nbsp;al., <a href="#bib.bib65" title="" class="ltx_ref">2021</a>]</cite>
 dataset consists of 30,000 social media user comments, covering seven 
categories including sports, entertainment, religion, politics, crime, 
celebrities, TikTok, and memes. It has been annotated through 
crowdsourcing and expert validation for research purposes in detecting 
hate speech in Bengali language. The dataset also provides benchmark 
experimental results for multiple deep learning models and pre-trained 
Bengali word vectors. We utilized 1,000 data samples from the dataset 
for Hate Detection.</p>
</div>
<div id="A2.SS2.p4" class="ltx_para">
<p id="A2.SS2.p4.1" class="ltx_p">BACD&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[aimansnigdha, <a href="#bib.bib4" title="" class="ltx_ref">2018</a>]</cite>
 dataset is a dataset for the Bengali language, consisting of a total of
 10,200 data points with annotations for toxic, threat, obscene, insult,
 and racism labels. We utilized 1,000 data points from this dataset for 
Threat Detection and Bias Detection tasks respectively.</p>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Chinese</h3>

<div id="A2.SS3.p1" class="ltx_para">
<p id="A2.SS3.p1.1" class="ltx_p">CCS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Jiang et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2019</a>]</cite>
 dataset consists of two real-world spam datasets: one is an SMS 
dataset, and the other is a product review dataset. Both datasets were 
manually labeled by professionals as spam or regular emails, and their 
sizes and label distributions were summarized. We utilized 1000 data 
samples from this dataset for Spam Detection.</p>
</div>
<div id="A2.SS3.p2" class="ltx_para">
<p id="A2.SS3.p2.1" class="ltx_p">CDial-Bias&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Zhou et&nbsp;al., <a href="#bib.bib87" title="" class="ltx_ref">2022</a>]</cite>
 Dataset is the first annotated Chinese social bias dialog dataset, 
utilized to establish a benchmark for measuring dialog bias and evaluate
 Chinese generative models for social bias presence. We utilized 1000 
data samples from it for bias detection.</p>
</div>
<div id="A2.SS3.p3" class="ltx_para">
<p id="A2.SS3.p3.1" class="ltx_p">CValues&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Xu et&nbsp;al., <a href="#bib.bib83" title="" class="ltx_ref">2023</a>]</cite>
 is a Chinese human values evaluation benchmark that measures the 
alignment ability of large language models in terms of safety and 
responsibility, providing both manual and automatic evaluation to assess
 their performance and identify areas for improvement. We utilized 1712 
data samples from the dataset for Stance detection.</p>
</div>
</section>
<section id="A2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>English</h3>

<div id="A2.SS4.p1" class="ltx_para">
<p id="A2.SS4.p1.1" class="ltx_p">SOLID&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Rosenthal et&nbsp;al., <a href="#bib.bib66" title="" class="ltx_ref">2020</a>]</cite>
 dataset is an expanded dataset containing over nine million English 
tweets labeled in a semi-supervised fashion. It significantly improves 
the performance of identifying specific types and targets of offensive 
language when combined with the OLID dataset, particularly at lower 
levels of the offensive language taxonomy. We utilized 1,000 data points
 from the dataset for Offensive Detection.</p>
</div>
<div id="A2.SS4.p2" class="ltx_para">
<p id="A2.SS4.p2.1" class="ltx_p">MLMA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Ousidhoum et&nbsp;al., <a href="#bib.bib60" title="" class="ltx_ref">2019</a>]</cite>
 dataset is a new multilingual multi-aspect hate speech analysis 
dataset, which is used to evaluate state-of-the-art multilingual 
multitask learning approaches and improve hate speech detection and 
classification in general. We utilized 1000 data samples from the 
dataset for Hate Detection and Toxicity Detection respectively.</p>
</div>
<div id="A2.SS4.p3" class="ltx_para">
<p id="A2.SS4.p3.1" class="ltx_p">HOF&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Davidson et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2017</a>]</cite>
 dataset uses crowd-sourcing to collect tweets containing hate speech 
keywords and employs a multi-class classifier to distinguish between 
tweets containing hate speech, only offensive language, and those with 
neither. It addresses the challenge of automatically detecting hate 
speech on social media while separating it from other instances of 
offensive language. We used a subset of 1000 data samples for Hate 
Detection.</p>
</div>
<div id="A2.SS4.p4" class="ltx_para">
<p id="A2.SS4.p4.1" class="ltx_p">JMT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Kaggle, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>]</cite>
 dataset is a machine learning dataset designed to identify toxic 
comments in online conversations, aiming to build models that can filter
 out rude, disrespectful, or potentially conversation-disrupting 
comments to create a safer and more collaborative internet environment. 
We used 1000 data samples each from the Threat Detection and Toxicity 
Detection datasets.</p>
</div>
</section>
<section id="A2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.5 </span>Germany</h3>

<div id="A2.SS5.p1" class="ltx_para">
<p id="A2.SS5.p1.1" class="ltx_p">GermEval2018&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Wiegand et&nbsp;al., <a href="#bib.bib82" title="" class="ltx_ref">2018</a>]</cite>
 dataset is used for identifying offensive language in German tweets, 
including both coarse-grained binary classification tasks and 
fine-grained multi-class classification tasks. We used 3,531 data points
 for Offensive Detection.</p>
</div>
<div id="A2.SS5.p2" class="ltx_para">
<p id="A2.SS5.p2.1" class="ltx_p">IWG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Ross et&nbsp;al., <a href="#bib.bib67" title="" class="ltx_ref">2016</a>]</cite>
 dataset aims to assess the feasibility of reliably annotating hate 
speech and explore the consistency between existing definitions and 
subjective ratings. The results indicate low reliability in usersâ€™ 
judgments of hate speech, suggesting a need for more detailed annotation
 instructions. Each data instance in the dataset was annotated by two 
experts, and we selected 469 instances with annotations from both 
experts for Hate Detection, denoted as IWG_1 and IWG_2 respectively.</p>
</div>
<div id="A2.SS5.p3" class="ltx_para">
<p id="A2.SS5.p3.1" class="ltx_p">HASOC2020&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[HASOC, <a href="#bib.bib26" title="" class="ltx_ref">2020</a>]</cite>
 dataset is a multilingual research forum and data challenge that offers
 tasks for identifying problematic content in English, German, and 
Hindi. It consists of over 10,000 annotated tweets from Twitter, and 
includes both coarse-grained and fine-grained classification tasks. We 
utilized a subset of 850 German language data from the HASOC dataset for
 Hate Detection.</p>
</div>
<div id="A2.SS5.p4" class="ltx_para">
<p id="A2.SS5.p4.1" class="ltx_p">Multilingual HateCheck&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[RÃ¶ttger et&nbsp;al., <a href="#bib.bib68" title="" class="ltx_ref">2022</a>]</cite>
 is a comprehensive dataset of functional tests for hate speech 
detection models in ten languages, addressing the need for more 
effective models and uncovering critical weaknesses for monolingual and 
cross-lingual applications. We utilized 1000 data points from the German
 section of the dataset for Hate Detection.</p>
</div>
</section>
<section id="A2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.6 </span>Korean</h3>

<div id="A2.SS6.p1" class="ltx_para">
<p id="A2.SS6.p1.1" class="ltx_p">K-MHaS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Lee et&nbsp;al., <a href="#bib.bib40" title="" class="ltx_ref">2022</a>]</cite>
 is a multi-label dataset consisting of 109k utterances from Korean news
 comments, designed for hate speech detection. It effectively handles 
Korean language patterns, provides multi-label classification with 1 to 4
 labels, and considers subjectivity and intersectionality. Strong 
baseline experiments using Korean-BERT-based language models show that 
KR-BERT with a sub-character tokenizer performs the best by recognizing 
decomposed characters in each hate speech class. We utilized 1000 data 
samples from the dataset for Hate Detection.</p>
</div>
<div id="A2.SS6.p2" class="ltx_para">
<p id="A2.SS6.p2.1" class="ltx_p">HateSpeech&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Moon et&nbsp;al., <a href="#bib.bib51" title="" class="ltx_ref">2020</a>]</cite>
 dataset is a collection of 9.4K manually labeled entertainment news 
comments in Korean, aimed at identifying toxic speech, social bias, and 
hate speech. It provides benchmarks using CharCNN, BiLSTM, and BERT 
models, with BERT achieving the highest performance. The dataset is made
 publicly available and open for competitions. We utilized 1000 data 
samples from the dataset for Hate Detection.</p>
</div>
<div id="A2.SS6.p3" class="ltx_para">
<p id="A2.SS6.p3.1" class="ltx_p">HateSpeech2&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[daanVeer, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>]</cite>
 dataset was created by the Natural Language Processing Laboratory (NLP)
 at Korea National University and it includes the original dataset, a 
vocabulary of offensive language, annotations, and dataset examples. The
 dataset is used for labeling malicious comments and has been built with
 word embeddings. We utilized 1000 data samples from the dataset for 
Hate Detection.</p>
</div>
<div id="A2.SS6.p4" class="ltx_para">
<p id="A2.SS6.p4.1" class="ltx_p">AbuseEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Caselli et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2020</a>]</cite>
 is a newly created dataset that addresses issues in annotating 
offensive and abusive language, specifically considering the degree of 
explicitness, target presence, and contextual interaction across 
different abusive language phenomena. We utilized 1000 data samples from
 the dataset for Abusive Detection.</p>
</div>
<div id="A2.SS6.p5" class="ltx_para">
<p id="A2.SS6.p5.1" class="ltx_p">CADD&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Song et&nbsp;al., <a href="#bib.bib71" title="" class="ltx_ref">2021</a>]</cite>
 is a comprehensive dataset for detecting abusive language in English 
Reddit posts, featuring multifaceted labels and contextual information, 
collected through large-scale crowdsourcing and yielding meaningful 
performance with state-of-the-art language models. We utilized 1000 data
 samples from the dataset for Abusive Detection.</p>
</div>
<div id="A2.SS6.p6" class="ltx_para">
<p id="A2.SS6.p6.1" class="ltx_p">Waseem&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Waseem and Hovy, <a href="#bib.bib81" title="" class="ltx_ref">2016</a>]</cite>
 dataset, based on critical race theory, provides annotations for over 
16k tweets and aims to detect hate speech on social media by analyzing 
linguistic features, extra-linguistic features, and a dictionary of the 
most indicative words in the data. We utilized 1000 data samples from 
the dataset for Abusive Detection.</p>
</div>
</section>
<section id="A2.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.7 </span>Portuguese</h3>

<div id="A2.SS7.p1" class="ltx_para">
<p id="A2.SS7.p1.1" class="ltx_p">OffComBR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[de&nbsp;Pelle and Moreira, <a href="#bib.bib19" title="" class="ltx_ref">2017</a>]</cite>
 dataset is an annotated collection of offensive comments in Portuguese,
 gathered from news comment sections on the Brazilian web. It serves the
 purpose of classifying user-generated text as either positive or 
negative, providing a baseline for future research on the topic of hate 
speech detection in Portuguese. We utilized 1250 data samples from this 
dataset for offensive detection.</p>
</div>
<div id="A2.SS7.p2" class="ltx_para">
<p id="A2.SS7.p2.1" class="ltx_p">HateBR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Vargas et&nbsp;al., <a href="#bib.bib75" title="" class="ltx_ref">2022</a>]</cite>
 dataset is the first large-scale expert annotated corpus of Brazilian 
Instagram comments, specifically collected from politiciansâ€™ accounts, 
providing binary/offensiveness-level classification and nine hate speech
 groups, outperforming the current state-of-the-art for Portuguese 
language offensive language and hate speech detection. We utilized 1000 
data samples from this dataset for offensive detection.</p>
</div>
<div id="A2.SS7.p3" class="ltx_para">
<p id="A2.SS7.p3.1" class="ltx_p">ToLD-Br&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Leite et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2020</a>]</cite>
 is a large-scale dataset for Brazilian Portuguese, consisting of 
annotated tweets categorized as toxic or non-toxic, aiming to detect and
 prevent the proliferation of toxicity in social media, addressing the 
need for multilingual approaches and models aware of different 
categories of toxicity. We take the label â€œinsult" from the dataset to 
represent the â€œabusive" label, and â€œhomophobia" and â€œmisogyny" as the 
â€œbias" labels. We have selected 1000 data samples for Abusive Detection,
 1000 samples for Bias Detection, and 1000 samples for Bias Detection.</p>
</div>
</section>
<section id="A2.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.8 </span>Spanish</h3>

<div id="A2.SS8.p1" class="ltx_para">
<p id="A2.SS8.p1.1" class="ltx_p">AMI&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Fersini et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2018</a>]</cite>
 dataset is a collection of Spanish and English tweets used for 
identifying misogyny, categorizing misogynistic behavior, and 
classifying targeted individuals, with contributions from multiple teams
 and countries. We used 1000 Spanish language data for offensive 
detection.</p>
</div>
<div id="A2.SS8.p2" class="ltx_para">
<p id="A2.SS8.p2.1" class="ltx_p">MEX-A3T&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Ãlvarez-Carmona et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>]</cite>
 dataset, from the track at IberEval 2018, comprises Mexican Spanish 
tweets and focuses on two tasks: author profiling, which aims to 
identify the residence and occupation of Twitter users, and 
aggressiveness detection, to distinguish between aggressive and 
non-aggressive tweets. This dataset was created specifically for these 
tasks and was analyzed and compared in a paper discussing the 
participantsâ€™ results. We used 1000 data samples for offensive 
detection.</p>
</div>
<div id="A2.SS8.p3" class="ltx_para">
<p id="A2.SS8.p3.1" class="ltx_p">OffendES&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Plaza-del Arco et&nbsp;al., <a href="#bib.bib63" title="" class="ltx_ref">2021</a>]</cite>
 dataset is a collection of 47,128 manually labeled Spanish comments 
from social media platforms, focusing on offensive language targeted at 
young influencers. It provides pre-defined offensive categories and 
includes confidence scores, enabling both multi-class classification and
 multi-output regression studies. We used 1000 data samples for 
offensive detection.</p>
</div>
<div id="A2.SS8.p4" class="ltx_para">
<p id="A2.SS8.p4.1" class="ltx_p">HatEval 2019&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Basile et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>]</cite>
 dataset focuses on detecting hate speech against immigrants and women 
in Spanish and English Twitter messages. It includes two classification 
tasks: identifying the presence of hate speech and distinguishing 
between individual and group targets. HatEval was a popular SemEval-2019
 task with numerous submissions and participant system analysis. We used
 1000 data samples for hate detection.</p>
</div>
<div id="A2.SS8.p5" class="ltx_para">
<p id="A2.SS8.p5.1" class="ltx_p">HaterNet&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Pereira-Kohatsu et&nbsp;al., <a href="#bib.bib61" title="" class="ltx_ref">2019</a>]</cite>
 dataset is an intelligent system used for monitoring and visualizing 
hate speech on Twitter. It provides a novel public dataset of Spanish 
hate speech, consisting of 6,000 expert-annotated tweets. We used 1000 
data samples for hate detection.</p>
</div>
<div id="A2.SS8.p6" class="ltx_para">
<p id="A2.SS8.p6.1" class="ltx_p">DETOXIS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[de&nbsp;Paula and Schlicht, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>]</cite>
 dataset is designed for the task of detecting toxic comments in online 
news discussions related to immigration. It includes toxicity detection 
and toxicity level detection. Participating teams achieved good results 
using the BERT model on this dataset. We classified them into tags such 
as stereotype, improper, abusive, mockery, aggressiveness, and stance, 
and selected 1000 data samples for each category for Bias detection, 
Abusive detection, Aggressiveness detection, and Stance detection.</p>
</div>
</section>
<section id="A2.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.9 </span>Turkish</h3>

<div id="A2.SS9.p1" class="ltx_para">
<p id="A2.SS9.p1.1" class="ltx_p">SemEval-2020&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Zampieri et&nbsp;al., <a href="#bib.bib86" title="" class="ltx_ref">2020</a>]</cite>
 provided a new, large-scale semi-supervised training dataset of over 
nine million English tweets and expanded the task to include four new 
languages, allowing for cross-lingual training and analysis. We used 
3528 data samples in Turkish for Offensive Detection.</p>
</div>
<div id="A2.SS9.p2" class="ltx_para">
<p id="A2.SS9.p2.1" class="ltx_p">OffenseCorpus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Ã‡Ã¶ltekin, <a href="#bib.bib11" title="" class="ltx_ref">2020</a>]</cite>
 is a corpus of Turkish offensive language, comprising randomly sampled 
micro-blog posts from Twitter. It contains 36,232 tweets collected over 
an 18-month period from April 2018 to September 2019. We used 1000 data 
samples for Offensive Detection.</p>
</div>
<div id="A2.SS9.p3" class="ltx_para">
<p id="A2.SS9.p3.1" class="ltx_p">OffenseKaggle&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Kaggle, <a href="#bib.bib36" title="" class="ltx_ref">2021</a>]</cite>
 Dataset is a collection of Turkish tweets from Twitter, with around 40%
 of them containing offensive or vulgar content. We used 1000 data 
samples for Offensive Detection.</p>
</div>
<div id="A2.SS9.p4" class="ltx_para">
<p id="A2.SS9.p4.1" class="ltx_p">OffenseKaggle_2&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Kaggle, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>]</cite>
 dataset is an enhanced version of an existing offensive language 
research dataset, which has been expanded and annotated using contextual
 data mining techniques. It addresses the issue of class imbalance in 
existing studies and provides a more comprehensive and robust dataset 
for Turkish offensive language detection tasks. We used 1000 data 
samples for Offensive Detection.</p>
</div>
<div id="A2.SS9.p5" class="ltx_para">
<p id="A2.SS9.p5.1" class="ltx_p">ATC&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[KarayiÄŸit et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2021</a>]</cite>
 dataset is a publicly available dataset for detecting abusive Turkish 
comments on Instagram. It consists of 10,528 abusive and 19,826 
non-abusive comments, with sentiment annotations at the sentence level. 
We used 1000 data samples for Offensive Detection.</p>
</div>
<div id="A2.SS9.p6" class="ltx_para">
<p id="A2.SS9.p6.1" class="ltx_p">Turkish Spam&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[mis, <a href="#bib.bib1" title="" class="ltx_ref">2019</a>]</cite>
 dataset contains both spam and normal emails written in Turkish. A 
total of 330 spam emails and 496 normal emails were collected from 
several personal accounts. We used 825 pieces of data for spam 
detection.</p>
</div>
<div id="A2.SS9.p7" class="ltx_para">
<p id="A2.SS9.p7.1" class="ltx_p">OffenseCorpus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Ã‡Ã¶ltekin, <a href="#bib.bib11" title="" class="ltx_ref">2020</a>]</cite>
 dataset is a large collection of Turkish offensive language from 
Twitter micro-blog posts, annotated based on recent practices. It 
includes 36,232 randomly sampled tweets from April 2018 to September 
2019, with 19% containing offensive language. We used 1000 of the data 
for Finegrained offensive detection.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompt Setting</h2>

<div id="A3.p1" class="ltx_para">
<ol id="A3.I1" class="ltx_enumerate">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">Prompt for generate open-ended dataset:</p>
</div>
<div id="A3.I1.i1.p2" class="ltx_para">
<p id="A3.I1.i1.p2.1" class="ltx_p">Can you generate some open-ended question according to the following questions:</p>
</div>
<div id="A3.I1.i1.p3" class="ltx_para">
<p id="A3.I1.i1.p3.1" class="ltx_p">{Some questions on the same topic}</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">Prompt for evaluate open-ended dataset:</p>
</div>
<div id="A3.I1.i2.p2" class="ltx_para">
<p id="A3.I1.i2.p2.1" class="ltx_p">Question: {q}</p>
</div>
<div id="A3.I1.i2.p3" class="ltx_para">
<p id="A3.I1.i2.p3.1" class="ltx_p">Answer A: {ans 1}</p>
</div>
<div id="A3.I1.i2.p4" class="ltx_para">
<p id="A3.I1.i2.p4.1" class="ltx_p">Answer B: {ans 2}</p>
</div>
<div id="A3.I1.i2.p5" class="ltx_para">
<p id="A3.I1.i2.p5.1" class="ltx_p">Comparing these two answers, which answer is more socially aligned with country culture?</p>
</div>
<div id="A3.I1.i2.p6" class="ltx_para">
<p id="A3.I1.i2.p6.1" class="ltx_p">Options:</p>
</div>
<div id="A3.I1.i2.p7" class="ltx_para">
<p id="A3.I1.i2.p7.1" class="ltx_p">A. Answer A.</p>
</div>
<div id="A3.I1.i2.p8" class="ltx_para">
<p id="A3.I1.i2.p8.1" class="ltx_p">B. Answer B.</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p id="A3.I1.i3.p1.1" class="ltx_p">Prompt for rating sentences similarity</p>
</div>
<div id="A3.I1.i3.p2" class="ltx_para">
<p id="A3.I1.i3.p2.1" class="ltx_p">Rate the semantic similarity of two input sentences on a scale of 1 - definitely not to 5 - perfectly.</p>
</div>
<div id="A3.I1.i3.p3" class="ltx_para">
<p id="A3.I1.i3.p3.1" class="ltx_p">Sentence 1: {item 1}</p>
</div>
<div id="A3.I1.i3.p4" class="ltx_para">
<p id="A3.I1.i3.p4.1" class="ltx_p">Sentence 2: {item 2}</p>
</div>
</li>
</ol>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Details Experimental Results</h2>

<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Detailed results</h3>

<figure id="A4.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x9.png" id="A4.F9.sf1.g1" class="ltx_graphics ltx_img_landscape" width="226" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="A4.F9.sf1.3.2" class="ltx_text" style="font-size:80%;">Arabic</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x10.png" id="A4.F9.sf2.g1" class="ltx_graphics ltx_img_landscape" width="138" height="111" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="A4.F9.sf2.3.2" class="ltx_text" style="font-size:80%;">Bengali</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x11.png" id="A4.F9.sf3.g1" class="ltx_graphics ltx_img_square" width="92" height="91" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="A4.F9.sf3.3.2" class="ltx_text" style="font-size:80%;">Chinese</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x12.png" id="A4.F9.sf4.g1" class="ltx_graphics ltx_img_landscape" width="185" height="128" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="A4.F9.sf4.3.2" class="ltx_text" style="font-size:80%;">English</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x13.png" id="A4.F9.sf5.g1" class="ltx_graphics ltx_img_square" width="133" height="127" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf5.2.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="A4.F9.sf5.3.2" class="ltx_text" style="font-size:80%;">Germany</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x14.png" id="A4.F9.sf6.g1" class="ltx_graphics ltx_img_landscape" width="138" height="109" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf6.2.1.1" class="ltx_text" style="font-size:80%;">(f)</span> </span><span id="A4.F9.sf6.3.2" class="ltx_text" style="font-size:80%;">Korean</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x15.png" id="A4.F9.sf7.g1" class="ltx_graphics ltx_img_square" width="115" height="109" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf7.2.1.1" class="ltx_text" style="font-size:80%;">(g)</span> </span><span id="A4.F9.sf7.3.2" class="ltx_text" style="font-size:80%;">Portuguese</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x16.png" id="A4.F9.sf8.g1" class="ltx_graphics ltx_img_landscape" width="207" height="99" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf8.2.1.1" class="ltx_text" style="font-size:80%;">(h)</span> </span><span id="A4.F9.sf8.3.2" class="ltx_text" style="font-size:80%;">Spanish</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A4.F9.sf9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x17.png" id="A4.F9.sf9.g1" class="ltx_graphics ltx_img_landscape" width="133" height="97" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.sf9.2.1.1" class="ltx_text" style="font-size:80%;">(i)</span> </span><span id="A4.F9.sf9.3.2" class="ltx_text" style="font-size:80%;">Turkish</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Detailed results on all tasks and all cultures.</figcaption>
</figure>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Analysis on low-resource language tasks and high-resource language tasks</h3>

<figure id="A4.F10" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x18.png" id="A4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="138" height="106" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>We compare CultureLLM with baselines on low-resource language tasks and high-resource language tasks.</figcaption>
</figure>
</section>
<section id="A4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Case Study</h3>

<figure id="A4.F11" class="ltx_figure"><img src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/x19.png" id="A4.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="450" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>The responses from ChatGPT and CultureLLM on four different cultures</figcaption>
</figure>
<div id="A4.SS3.p1" class="ltx_para">
<p id="A4.SS3.p1.1" class="ltx_p"><a href="#A4.F11" title="In D.3 Case Study â€£ Appendix D Details Experimental Results â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">11</span></a> show the reponses from CultureLLM and ChatGPT on four different cultures.</p>
</div>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Metrics for Dataset measure</h2>

<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Perplexity</h3>

<div id="A5.SS1.p1" class="ltx_para">
<p id="A5.SS1.p1.2" class="ltx_p">The perplexity on a test dataset <math id="A5.SS1.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A5.SS1.p1.1.m1.1a"><mi id="A5.SS1.p1.1.m1.1.1" xref="A5.SS1.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.1.m1.1b"><ci id="A5.SS1.p1.1.m1.1.1.cmml" xref="A5.SS1.p1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.1.m1.1c">D</annotation></semantics></math> and a language model <math id="A5.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="A5.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="A5.SS1.p1.2.m2.1.1" xref="A5.SS1.p1.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.2.m2.1b"><ci id="A5.SS1.p1.2.m2.1.1.cmml" xref="A5.SS1.p1.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.2.m2.1c">\mathcal{M}</annotation></semantics></math> is computed as:</p>
<table id="A5.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.Ex3.m1.4" class="ltx_Math" alttext="\text{{ppl}}(D,\mathcal{M})=\exp\left(-\frac{1}{N}\sum_{i=1}^{N}\log P(x_{i}|\mathcal{M})\right)," display="block"><semantics id="A5.Ex3.m1.4a"><mrow id="A5.Ex3.m1.4.4.1" xref="A5.Ex3.m1.4.4.1.1.cmml"><mrow id="A5.Ex3.m1.4.4.1.1" xref="A5.Ex3.m1.4.4.1.1.cmml"><mrow id="A5.Ex3.m1.4.4.1.1.3" xref="A5.Ex3.m1.4.4.1.1.3.cmml"><mtext id="A5.Ex3.m1.4.4.1.1.3.2" xref="A5.Ex3.m1.4.4.1.1.3.2a.cmml">ppl</mtext><mo lspace="0em" rspace="0em" id="A5.Ex3.m1.4.4.1.1.3.1" xref="A5.Ex3.m1.4.4.1.1.3.1.cmml">â€‹</mo><mrow id="A5.Ex3.m1.4.4.1.1.3.3.2" xref="A5.Ex3.m1.4.4.1.1.3.3.1.cmml"><mo stretchy="false" id="A5.Ex3.m1.4.4.1.1.3.3.2.1" xref="A5.Ex3.m1.4.4.1.1.3.3.1.cmml">(</mo><mi id="A5.Ex3.m1.1.1" xref="A5.Ex3.m1.1.1.cmml">D</mi><mo id="A5.Ex3.m1.4.4.1.1.3.3.2.2" xref="A5.Ex3.m1.4.4.1.1.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="A5.Ex3.m1.2.2" xref="A5.Ex3.m1.2.2.cmml">â„³</mi><mo stretchy="false" id="A5.Ex3.m1.4.4.1.1.3.3.2.3" xref="A5.Ex3.m1.4.4.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m1.4.4.1.1.2" xref="A5.Ex3.m1.4.4.1.1.2.cmml">=</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.2.cmml"><mi id="A5.Ex3.m1.3.3" xref="A5.Ex3.m1.3.3.cmml">exp</mi><mo id="A5.Ex3.m1.4.4.1.1.1.1a" xref="A5.Ex3.m1.4.4.1.1.1.2.cmml">â¡</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.2.cmml"><mo id="A5.Ex3.m1.4.4.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.2.cmml">(</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m1.4.4.1.1.1.1.1.1a" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.cmml">âˆ’</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.cmml"><mfrac id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mn id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2.cmml">1</mn><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.cmml"><munderover id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3a" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml">â¡</mo><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">â„³</mi></mrow><mo stretchy="false" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="A5.Ex3.m1.4.4.1.1.1.1.1.3" xref="A5.Ex3.m1.4.4.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex3.m1.4.4.1.2" xref="A5.Ex3.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex3.m1.4b"><apply id="A5.Ex3.m1.4.4.1.1.cmml" xref="A5.Ex3.m1.4.4.1"><eq id="A5.Ex3.m1.4.4.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.2"></eq><apply id="A5.Ex3.m1.4.4.1.1.3.cmml" xref="A5.Ex3.m1.4.4.1.1.3"><times id="A5.Ex3.m1.4.4.1.1.3.1.cmml" xref="A5.Ex3.m1.4.4.1.1.3.1"></times><ci id="A5.Ex3.m1.4.4.1.1.3.2a.cmml" xref="A5.Ex3.m1.4.4.1.1.3.2"><mtext id="A5.Ex3.m1.4.4.1.1.3.2.cmml" xref="A5.Ex3.m1.4.4.1.1.3.2">ppl</mtext></ci><interval closure="open" id="A5.Ex3.m1.4.4.1.1.3.3.1.cmml" xref="A5.Ex3.m1.4.4.1.1.3.3.2"><ci id="A5.Ex3.m1.1.1.cmml" xref="A5.Ex3.m1.1.1">ğ·</ci><ci id="A5.Ex3.m1.2.2.cmml" xref="A5.Ex3.m1.2.2">â„³</ci></interval></apply><apply id="A5.Ex3.m1.4.4.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1"><exp id="A5.Ex3.m1.3.3.cmml" xref="A5.Ex3.m1.3.3"></exp><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1"><minus id="A5.Ex3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1"></minus><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1"><times id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3"><divide id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3"></divide><cn type="integer" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2">1</cn><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1"><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2">subscript</csymbol><sum id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.2"></sum><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3"><eq id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1"><times id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3"><log id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.1"></log><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2">ğ‘ƒ</ci></apply><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">â„³</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex3.m1.4c">\text{{ppl}}(D,\mathcal{M})=\exp\left(-\frac{1}{N}\sum_{i=1}^{N}\log P(x_{i}|\mathcal{M})\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A5.SS1.p1.10" class="ltx_p">where <math id="A5.SS1.p1.3.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A5.SS1.p1.3.m1.1a"><mi id="A5.SS1.p1.3.m1.1.1" xref="A5.SS1.p1.3.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.3.m1.1b"><ci id="A5.SS1.p1.3.m1.1.1.cmml" xref="A5.SS1.p1.3.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.3.m1.1c">N</annotation></semantics></math> represents the total number of tokens in <math id="A5.SS1.p1.4.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A5.SS1.p1.4.m2.1a"><mi id="A5.SS1.p1.4.m2.1.1" xref="A5.SS1.p1.4.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.4.m2.1b"><ci id="A5.SS1.p1.4.m2.1.1.cmml" xref="A5.SS1.p1.4.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.4.m2.1c">D</annotation></semantics></math>, <math id="A5.SS1.p1.5.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="A5.SS1.p1.5.m3.1a"><msub id="A5.SS1.p1.5.m3.1.1" xref="A5.SS1.p1.5.m3.1.1.cmml"><mi id="A5.SS1.p1.5.m3.1.1.2" xref="A5.SS1.p1.5.m3.1.1.2.cmml">x</mi><mi id="A5.SS1.p1.5.m3.1.1.3" xref="A5.SS1.p1.5.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.5.m3.1b"><apply id="A5.SS1.p1.5.m3.1.1.cmml" xref="A5.SS1.p1.5.m3.1.1"><csymbol cd="ambiguous" id="A5.SS1.p1.5.m3.1.1.1.cmml" xref="A5.SS1.p1.5.m3.1.1">subscript</csymbol><ci id="A5.SS1.p1.5.m3.1.1.2.cmml" xref="A5.SS1.p1.5.m3.1.1.2">ğ‘¥</ci><ci id="A5.SS1.p1.5.m3.1.1.3.cmml" xref="A5.SS1.p1.5.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.5.m3.1c">x_{i}</annotation></semantics></math> represents the <math id="A5.SS1.p1.6.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="A5.SS1.p1.6.m4.1a"><mi id="A5.SS1.p1.6.m4.1.1" xref="A5.SS1.p1.6.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.6.m4.1b"><ci id="A5.SS1.p1.6.m4.1.1.cmml" xref="A5.SS1.p1.6.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.6.m4.1c">i</annotation></semantics></math>-th token in the test dataset, <math id="A5.SS1.p1.7.m5.1" class="ltx_Math" alttext="P(x_{i}|\mathcal{M})" display="inline"><semantics id="A5.SS1.p1.7.m5.1a"><mrow id="A5.SS1.p1.7.m5.1.1" xref="A5.SS1.p1.7.m5.1.1.cmml"><mi id="A5.SS1.p1.7.m5.1.1.3" xref="A5.SS1.p1.7.m5.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="A5.SS1.p1.7.m5.1.1.2" xref="A5.SS1.p1.7.m5.1.1.2.cmml">â€‹</mo><mrow id="A5.SS1.p1.7.m5.1.1.1.1" xref="A5.SS1.p1.7.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.SS1.p1.7.m5.1.1.1.1.2" xref="A5.SS1.p1.7.m5.1.1.1.1.1.cmml">(</mo><mrow id="A5.SS1.p1.7.m5.1.1.1.1.1" xref="A5.SS1.p1.7.m5.1.1.1.1.1.cmml"><msub id="A5.SS1.p1.7.m5.1.1.1.1.1.2" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2.cmml"><mi id="A5.SS1.p1.7.m5.1.1.1.1.1.2.2" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2.2.cmml">x</mi><mi id="A5.SS1.p1.7.m5.1.1.1.1.1.2.3" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="A5.SS1.p1.7.m5.1.1.1.1.1.1" xref="A5.SS1.p1.7.m5.1.1.1.1.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="A5.SS1.p1.7.m5.1.1.1.1.1.3" xref="A5.SS1.p1.7.m5.1.1.1.1.1.3.cmml">â„³</mi></mrow><mo stretchy="false" id="A5.SS1.p1.7.m5.1.1.1.1.3" xref="A5.SS1.p1.7.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.7.m5.1b"><apply id="A5.SS1.p1.7.m5.1.1.cmml" xref="A5.SS1.p1.7.m5.1.1"><times id="A5.SS1.p1.7.m5.1.1.2.cmml" xref="A5.SS1.p1.7.m5.1.1.2"></times><ci id="A5.SS1.p1.7.m5.1.1.3.cmml" xref="A5.SS1.p1.7.m5.1.1.3">ğ‘ƒ</ci><apply id="A5.SS1.p1.7.m5.1.1.1.1.1.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1"><csymbol cd="latexml" id="A5.SS1.p1.7.m5.1.1.1.1.1.1.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.1">conditional</csymbol><apply id="A5.SS1.p1.7.m5.1.1.1.1.1.2.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.SS1.p1.7.m5.1.1.1.1.1.2.1.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2">subscript</csymbol><ci id="A5.SS1.p1.7.m5.1.1.1.1.1.2.2.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="A5.SS1.p1.7.m5.1.1.1.1.1.2.3.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="A5.SS1.p1.7.m5.1.1.1.1.1.3.cmml" xref="A5.SS1.p1.7.m5.1.1.1.1.1.3">â„³</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.7.m5.1c">P(x_{i}|\mathcal{M})</annotation></semantics></math> represents the probability of generating token <math id="A5.SS1.p1.8.m6.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="A5.SS1.p1.8.m6.1a"><msub id="A5.SS1.p1.8.m6.1.1" xref="A5.SS1.p1.8.m6.1.1.cmml"><mi id="A5.SS1.p1.8.m6.1.1.2" xref="A5.SS1.p1.8.m6.1.1.2.cmml">x</mi><mi id="A5.SS1.p1.8.m6.1.1.3" xref="A5.SS1.p1.8.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.8.m6.1b"><apply id="A5.SS1.p1.8.m6.1.1.cmml" xref="A5.SS1.p1.8.m6.1.1"><csymbol cd="ambiguous" id="A5.SS1.p1.8.m6.1.1.1.cmml" xref="A5.SS1.p1.8.m6.1.1">subscript</csymbol><ci id="A5.SS1.p1.8.m6.1.1.2.cmml" xref="A5.SS1.p1.8.m6.1.1.2">ğ‘¥</ci><ci id="A5.SS1.p1.8.m6.1.1.3.cmml" xref="A5.SS1.p1.8.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.8.m6.1c">x_{i}</annotation></semantics></math> given the model <math id="A5.SS1.p1.9.m7.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="A5.SS1.p1.9.m7.1a"><mi class="ltx_font_mathcaligraphic" id="A5.SS1.p1.9.m7.1.1" xref="A5.SS1.p1.9.m7.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.9.m7.1b"><ci id="A5.SS1.p1.9.m7.1.1.cmml" xref="A5.SS1.p1.9.m7.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.9.m7.1c">\mathcal{M}</annotation></semantics></math>, and <math id="A5.SS1.p1.10.m8.1" class="ltx_Math" alttext="\log" display="inline"><semantics id="A5.SS1.p1.10.m8.1a"><mi id="A5.SS1.p1.10.m8.1.1" xref="A5.SS1.p1.10.m8.1.1.cmml">log</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.10.m8.1b"><log id="A5.SS1.p1.10.m8.1.1.cmml" xref="A5.SS1.p1.10.m8.1.1"></log></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.10.m8.1c">\log</annotation></semantics></math> is the natural logarithm.</p>
</div>
<div id="A5.SS1.p2" class="ltx_para">
<p id="A5.SS1.p2.1" class="ltx_p">In usual, a lower perplexity value 
indicates better performance of the model on the test data. However, for
 evaluating the data quality to train model, a higher perplexity value 
means it can bring more valuable information.</p>
</div>
</section>
<section id="A5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Diversity Gain</h3>

<div id="A5.SS2.p1" class="ltx_para">
<p id="A5.SS2.p1.6" class="ltx_p">We use the diversity gain&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Bilmes, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>]</cite> to measure what extent can our generated dataset bring data diversity to the base dataset. The base dataset can be defined as <math id="A5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{base}=\{x_{i}=(q_{i},r_{i},a_{i})\}_{i=1}^{N}" display="inline"><semantics id="A5.SS2.p1.1.m1.1a"><mrow id="A5.SS2.p1.1.m1.1.1" xref="A5.SS2.p1.1.m1.1.1.cmml"><msub id="A5.SS2.p1.1.m1.1.1.3" xref="A5.SS2.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A5.SS2.p1.1.m1.1.1.3.2" xref="A5.SS2.p1.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mrow id="A5.SS2.p1.1.m1.1.1.3.3" xref="A5.SS2.p1.1.m1.1.1.3.3.cmml"><mi id="A5.SS2.p1.1.m1.1.1.3.3.2" xref="A5.SS2.p1.1.m1.1.1.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.1.m1.1.1.3.3.1" xref="A5.SS2.p1.1.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.1.m1.1.1.3.3.3" xref="A5.SS2.p1.1.m1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.1.m1.1.1.3.3.1a" xref="A5.SS2.p1.1.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.1.m1.1.1.3.3.4" xref="A5.SS2.p1.1.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.1.m1.1.1.3.3.1b" xref="A5.SS2.p1.1.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.1.m1.1.1.3.3.5" xref="A5.SS2.p1.1.m1.1.1.3.3.5.cmml">e</mi></mrow></msub><mo id="A5.SS2.p1.1.m1.1.1.2" xref="A5.SS2.p1.1.m1.1.1.2.cmml">=</mo><msubsup id="A5.SS2.p1.1.m1.1.1.1" xref="A5.SS2.p1.1.m1.1.1.1.cmml"><mrow id="A5.SS2.p1.1.m1.1.1.1.1.1.1" xref="A5.SS2.p1.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml"><msub id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.cmml"><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.4" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.4.cmml">=</mo><mrow id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml"><mo stretchy="false" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.4" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml">(</mo><msub id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.5" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">r</mi><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.6" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.2" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.2.cmml">a</mi><mi id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.7" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.3" xref="A5.SS2.p1.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="A5.SS2.p1.1.m1.1.1.1.1.3" xref="A5.SS2.p1.1.m1.1.1.1.1.3.cmml"><mi id="A5.SS2.p1.1.m1.1.1.1.1.3.2" xref="A5.SS2.p1.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="A5.SS2.p1.1.m1.1.1.1.1.3.1" xref="A5.SS2.p1.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="A5.SS2.p1.1.m1.1.1.1.1.3.3" xref="A5.SS2.p1.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="A5.SS2.p1.1.m1.1.1.1.3" xref="A5.SS2.p1.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.1.m1.1b"><apply id="A5.SS2.p1.1.m1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1"><eq id="A5.SS2.p1.1.m1.1.1.2.cmml" xref="A5.SS2.p1.1.m1.1.1.2"></eq><apply id="A5.SS2.p1.1.m1.1.1.3.cmml" xref="A5.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.3.1.cmml" xref="A5.SS2.p1.1.m1.1.1.3">subscript</csymbol><ci id="A5.SS2.p1.1.m1.1.1.3.2.cmml" xref="A5.SS2.p1.1.m1.1.1.3.2">ğ’Ÿ</ci><apply id="A5.SS2.p1.1.m1.1.1.3.3.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3"><times id="A5.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3.1"></times><ci id="A5.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3.2">ğ‘</ci><ci id="A5.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3.3">ğ‘</ci><ci id="A5.SS2.p1.1.m1.1.1.3.3.4.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3.4">ğ‘ </ci><ci id="A5.SS2.p1.1.m1.1.1.3.3.5.cmml" xref="A5.SS2.p1.1.m1.1.1.3.3.5">ğ‘’</ci></apply></apply><apply id="A5.SS2.p1.1.m1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1">superscript</csymbol><apply id="A5.SS2.p1.1.m1.1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1">subscript</csymbol><set id="A5.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1"><apply id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1"><eq id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.4.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.4"></eq><apply id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.2">ğ‘¥</ci><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.5.3">ğ‘–</ci></apply><vector id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.4.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3"><apply id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.2">ğ‘Ÿ</ci><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply><apply id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.2">ğ‘</ci><ci id="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.1.1.1.3.3.3.3">ğ‘–</ci></apply></vector></apply></set><apply id="A5.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.3"><eq id="A5.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.3.1"></eq><ci id="A5.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="A5.SS2.p1.1.m1.1.1.1.1.3.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="A5.SS2.p1.1.m1.1.1.1.3.cmml" xref="A5.SS2.p1.1.m1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.1.m1.1c">\mathcal{D}_{base}=\{x_{i}=(q_{i},r_{i},a_{i})\}_{i=1}^{N}</annotation></semantics></math> with <math id="A5.SS2.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A5.SS2.p1.2.m2.1a"><mi id="A5.SS2.p1.2.m2.1.1" xref="A5.SS2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.2.m2.1b"><ci id="A5.SS2.p1.2.m2.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.2.m2.1c">N</annotation></semantics></math> samples. The new generated dataset is defined as <math id="A5.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{new}=\{x_{i}=(q_{i},r_{i},a_{i})\}_{i=1}^{M}" display="inline"><semantics id="A5.SS2.p1.3.m3.1a"><mrow id="A5.SS2.p1.3.m3.1.1" xref="A5.SS2.p1.3.m3.1.1.cmml"><msub id="A5.SS2.p1.3.m3.1.1.3" xref="A5.SS2.p1.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A5.SS2.p1.3.m3.1.1.3.2" xref="A5.SS2.p1.3.m3.1.1.3.2.cmml">ğ’Ÿ</mi><mrow id="A5.SS2.p1.3.m3.1.1.3.3" xref="A5.SS2.p1.3.m3.1.1.3.3.cmml"><mi id="A5.SS2.p1.3.m3.1.1.3.3.2" xref="A5.SS2.p1.3.m3.1.1.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.3.m3.1.1.3.3.1" xref="A5.SS2.p1.3.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.3.m3.1.1.3.3.3" xref="A5.SS2.p1.3.m3.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.3.m3.1.1.3.3.1a" xref="A5.SS2.p1.3.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.3.m3.1.1.3.3.4" xref="A5.SS2.p1.3.m3.1.1.3.3.4.cmml">w</mi></mrow></msub><mo id="A5.SS2.p1.3.m3.1.1.2" xref="A5.SS2.p1.3.m3.1.1.2.cmml">=</mo><msubsup id="A5.SS2.p1.3.m3.1.1.1" xref="A5.SS2.p1.3.m3.1.1.1.cmml"><mrow id="A5.SS2.p1.3.m3.1.1.1.1.1.1" xref="A5.SS2.p1.3.m3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.2.cmml">{</mo><mrow id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.cmml"><msub id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.cmml"><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.4" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.4.cmml">=</mo><mrow id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml"><mo stretchy="false" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.4" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml">(</mo><msub id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.5" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.2.cmml">r</mi><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.6" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.2" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.2.cmml">a</mi><mi id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.7" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.3" xref="A5.SS2.p1.3.m3.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="A5.SS2.p1.3.m3.1.1.1.1.3" xref="A5.SS2.p1.3.m3.1.1.1.1.3.cmml"><mi id="A5.SS2.p1.3.m3.1.1.1.1.3.2" xref="A5.SS2.p1.3.m3.1.1.1.1.3.2.cmml">i</mi><mo id="A5.SS2.p1.3.m3.1.1.1.1.3.1" xref="A5.SS2.p1.3.m3.1.1.1.1.3.1.cmml">=</mo><mn id="A5.SS2.p1.3.m3.1.1.1.1.3.3" xref="A5.SS2.p1.3.m3.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="A5.SS2.p1.3.m3.1.1.1.3" xref="A5.SS2.p1.3.m3.1.1.1.3.cmml">M</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.3.m3.1b"><apply id="A5.SS2.p1.3.m3.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1"><eq id="A5.SS2.p1.3.m3.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.2"></eq><apply id="A5.SS2.p1.3.m3.1.1.3.cmml" xref="A5.SS2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.3.1.cmml" xref="A5.SS2.p1.3.m3.1.1.3">subscript</csymbol><ci id="A5.SS2.p1.3.m3.1.1.3.2.cmml" xref="A5.SS2.p1.3.m3.1.1.3.2">ğ’Ÿ</ci><apply id="A5.SS2.p1.3.m3.1.1.3.3.cmml" xref="A5.SS2.p1.3.m3.1.1.3.3"><times id="A5.SS2.p1.3.m3.1.1.3.3.1.cmml" xref="A5.SS2.p1.3.m3.1.1.3.3.1"></times><ci id="A5.SS2.p1.3.m3.1.1.3.3.2.cmml" xref="A5.SS2.p1.3.m3.1.1.3.3.2">ğ‘›</ci><ci id="A5.SS2.p1.3.m3.1.1.3.3.3.cmml" xref="A5.SS2.p1.3.m3.1.1.3.3.3">ğ‘’</ci><ci id="A5.SS2.p1.3.m3.1.1.3.3.4.cmml" xref="A5.SS2.p1.3.m3.1.1.3.3.4">ğ‘¤</ci></apply></apply><apply id="A5.SS2.p1.3.m3.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1">superscript</csymbol><apply id="A5.SS2.p1.3.m3.1.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1">subscript</csymbol><set id="A5.SS2.p1.3.m3.1.1.1.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1"><apply id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1"><eq id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.4.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.4"></eq><apply id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.2">ğ‘¥</ci><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.5.3">ğ‘–</ci></apply><vector id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.4.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3"><apply id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.2">ğ‘Ÿ</ci><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply><apply id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.2">ğ‘</ci><ci id="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.1.1.1.3.3.3.3">ğ‘–</ci></apply></vector></apply></set><apply id="A5.SS2.p1.3.m3.1.1.1.1.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.3"><eq id="A5.SS2.p1.3.m3.1.1.1.1.3.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.3.1"></eq><ci id="A5.SS2.p1.3.m3.1.1.1.1.3.2.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="A5.SS2.p1.3.m3.1.1.1.1.3.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.1.3.3">1</cn></apply></apply><ci id="A5.SS2.p1.3.m3.1.1.1.3.cmml" xref="A5.SS2.p1.3.m3.1.1.1.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.3.m3.1c">\mathcal{D}_{new}=\{x_{i}=(q_{i},r_{i},a_{i})\}_{i=1}^{M}</annotation></semantics></math> with <math id="A5.SS2.p1.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="A5.SS2.p1.4.m4.1a"><mi id="A5.SS2.p1.4.m4.1.1" xref="A5.SS2.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.4.m4.1b"><ci id="A5.SS2.p1.4.m4.1.1.cmml" xref="A5.SS2.p1.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.4.m4.1c">M</annotation></semantics></math> samples. And the diverse gain of <math id="A5.SS2.p1.5.m5.1" class="ltx_Math" alttext="D_{new}" display="inline"><semantics id="A5.SS2.p1.5.m5.1a"><msub id="A5.SS2.p1.5.m5.1.1" xref="A5.SS2.p1.5.m5.1.1.cmml"><mi id="A5.SS2.p1.5.m5.1.1.2" xref="A5.SS2.p1.5.m5.1.1.2.cmml">D</mi><mrow id="A5.SS2.p1.5.m5.1.1.3" xref="A5.SS2.p1.5.m5.1.1.3.cmml"><mi id="A5.SS2.p1.5.m5.1.1.3.2" xref="A5.SS2.p1.5.m5.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.5.m5.1.1.3.1" xref="A5.SS2.p1.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.5.m5.1.1.3.3" xref="A5.SS2.p1.5.m5.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.5.m5.1.1.3.1a" xref="A5.SS2.p1.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.5.m5.1.1.3.4" xref="A5.SS2.p1.5.m5.1.1.3.4.cmml">w</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.5.m5.1b"><apply id="A5.SS2.p1.5.m5.1.1.cmml" xref="A5.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.5.m5.1.1.1.cmml" xref="A5.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="A5.SS2.p1.5.m5.1.1.2.cmml" xref="A5.SS2.p1.5.m5.1.1.2">ğ·</ci><apply id="A5.SS2.p1.5.m5.1.1.3.cmml" xref="A5.SS2.p1.5.m5.1.1.3"><times id="A5.SS2.p1.5.m5.1.1.3.1.cmml" xref="A5.SS2.p1.5.m5.1.1.3.1"></times><ci id="A5.SS2.p1.5.m5.1.1.3.2.cmml" xref="A5.SS2.p1.5.m5.1.1.3.2">ğ‘›</ci><ci id="A5.SS2.p1.5.m5.1.1.3.3.cmml" xref="A5.SS2.p1.5.m5.1.1.3.3">ğ‘’</ci><ci id="A5.SS2.p1.5.m5.1.1.3.4.cmml" xref="A5.SS2.p1.5.m5.1.1.3.4">ğ‘¤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.5.m5.1c">D_{new}</annotation></semantics></math> relative to <math id="A5.SS2.p1.6.m6.1" class="ltx_Math" alttext="D_{base}" display="inline"><semantics id="A5.SS2.p1.6.m6.1a"><msub id="A5.SS2.p1.6.m6.1.1" xref="A5.SS2.p1.6.m6.1.1.cmml"><mi id="A5.SS2.p1.6.m6.1.1.2" xref="A5.SS2.p1.6.m6.1.1.2.cmml">D</mi><mrow id="A5.SS2.p1.6.m6.1.1.3" xref="A5.SS2.p1.6.m6.1.1.3.cmml"><mi id="A5.SS2.p1.6.m6.1.1.3.2" xref="A5.SS2.p1.6.m6.1.1.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.6.m6.1.1.3.1" xref="A5.SS2.p1.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.6.m6.1.1.3.3" xref="A5.SS2.p1.6.m6.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.6.m6.1.1.3.1a" xref="A5.SS2.p1.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.6.m6.1.1.3.4" xref="A5.SS2.p1.6.m6.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.SS2.p1.6.m6.1.1.3.1b" xref="A5.SS2.p1.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="A5.SS2.p1.6.m6.1.1.3.5" xref="A5.SS2.p1.6.m6.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.6.m6.1b"><apply id="A5.SS2.p1.6.m6.1.1.cmml" xref="A5.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A5.SS2.p1.6.m6.1.1.1.cmml" xref="A5.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="A5.SS2.p1.6.m6.1.1.2.cmml" xref="A5.SS2.p1.6.m6.1.1.2">ğ·</ci><apply id="A5.SS2.p1.6.m6.1.1.3.cmml" xref="A5.SS2.p1.6.m6.1.1.3"><times id="A5.SS2.p1.6.m6.1.1.3.1.cmml" xref="A5.SS2.p1.6.m6.1.1.3.1"></times><ci id="A5.SS2.p1.6.m6.1.1.3.2.cmml" xref="A5.SS2.p1.6.m6.1.1.3.2">ğ‘</ci><ci id="A5.SS2.p1.6.m6.1.1.3.3.cmml" xref="A5.SS2.p1.6.m6.1.1.3.3">ğ‘</ci><ci id="A5.SS2.p1.6.m6.1.1.3.4.cmml" xref="A5.SS2.p1.6.m6.1.1.3.4">ğ‘ </ci><ci id="A5.SS2.p1.6.m6.1.1.3.5.cmml" xref="A5.SS2.p1.6.m6.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.6.m6.1c">D_{base}</annotation></semantics></math> can be expressed as:</p>
<table id="A5.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.Ex4.m1.1" class="ltx_Math" alttext="d_{gain}=\frac{1}{M}\sum_{x_{i}\in\mathcal{D}_{new}}\min_{x_{j}\in\mathcal{D}_{base}}(\|\mathbf{f(x_{i})}-\mathbf{f(x_{j})}\|)," display="block"><semantics id="A5.Ex4.m1.1a"><mrow id="A5.Ex4.m1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><mrow id="A5.Ex4.m1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><msub id="A5.Ex4.m1.1.1.1.1.4" xref="A5.Ex4.m1.1.1.1.1.4.cmml"><mi id="A5.Ex4.m1.1.1.1.1.4.2" xref="A5.Ex4.m1.1.1.1.1.4.2.cmml">d</mi><mrow id="A5.Ex4.m1.1.1.1.1.4.3" xref="A5.Ex4.m1.1.1.1.1.4.3.cmml"><mi id="A5.Ex4.m1.1.1.1.1.4.3.2" xref="A5.Ex4.m1.1.1.1.1.4.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.4.3.1" xref="A5.Ex4.m1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.4.3.3" xref="A5.Ex4.m1.1.1.1.1.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.4.3.1a" xref="A5.Ex4.m1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.4.3.4" xref="A5.Ex4.m1.1.1.1.1.4.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.4.3.1b" xref="A5.Ex4.m1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.4.3.5" xref="A5.Ex4.m1.1.1.1.1.4.3.5.cmml">n</mi></mrow></msub><mo id="A5.Ex4.m1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.3.cmml">=</mo><mrow id="A5.Ex4.m1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.cmml"><mfrac id="A5.Ex4.m1.1.1.1.1.2.4" xref="A5.Ex4.m1.1.1.1.1.2.4.cmml"><mn id="A5.Ex4.m1.1.1.1.1.2.4.2" xref="A5.Ex4.m1.1.1.1.1.2.4.2.cmml">1</mn><mi id="A5.Ex4.m1.1.1.1.1.2.4.3" xref="A5.Ex4.m1.1.1.1.1.2.4.3.cmml">M</mi></mfrac><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.2.3" xref="A5.Ex4.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.cmml"><munder id="A5.Ex4.m1.1.1.1.1.2.2.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.cmml"><mo movablelimits="false" id="A5.Ex4.m1.1.1.1.1.2.2.3.2" xref="A5.Ex4.m1.1.1.1.1.2.2.3.2.cmml">âˆ‘</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.3.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.cmml"><msub id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.2.cmml">x</mi><mi id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.3.cmml">i</mi></msub><mo id="A5.Ex4.m1.1.1.1.1.2.2.3.3.1" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.1.cmml">âˆˆ</mo><msub id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.2" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.2.cmml">ğ’Ÿ</mi><mrow id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.2" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.3" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1a" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.4" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.4.cmml">w</mi></mrow></msub></mrow></munder><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml"><munder id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml">min</mi><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">j</mi></msub><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">âˆˆ</mo><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">ğ’Ÿ</mi><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1a" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.4" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1b" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.5" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.5.cmml">e</mi></mrow></msub></mrow></munder><mo id="A5.Ex4.m1.1.1.1.1.2.2.2.2a" xref="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml">â¡</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml">(</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.2.cmml"><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.2.1.cmml">â€–</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml"><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.3.cmml">ğŸ</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml">ğ±</mi><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml">ğ¢</mi></msub><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml">âˆ’</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.3.cmml">ğŸ</mi><mo lspace="0em" rspace="0em" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.2.cmml">â€‹</mo><mrow id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.cmml">(</mo><msub id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.2.cmml">ğ±</mi><mi id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.3.cmml">ğ£</mi></msub><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.2.1.cmml">â€–</mo></mrow><mo stretchy="false" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.3" xref="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex4.m1.1b"><apply id="A5.Ex4.m1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1"><eq id="A5.Ex4.m1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.3"></eq><apply id="A5.Ex4.m1.1.1.1.1.4.cmml" xref="A5.Ex4.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.4.1.cmml" xref="A5.Ex4.m1.1.1.1.1.4">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.4.2.cmml" xref="A5.Ex4.m1.1.1.1.1.4.2">ğ‘‘</ci><apply id="A5.Ex4.m1.1.1.1.1.4.3.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3"><times id="A5.Ex4.m1.1.1.1.1.4.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3.1"></times><ci id="A5.Ex4.m1.1.1.1.1.4.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3.2">ğ‘”</ci><ci id="A5.Ex4.m1.1.1.1.1.4.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3.3">ğ‘</ci><ci id="A5.Ex4.m1.1.1.1.1.4.3.4.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3.4">ğ‘–</ci><ci id="A5.Ex4.m1.1.1.1.1.4.3.5.cmml" xref="A5.Ex4.m1.1.1.1.1.4.3.5">ğ‘›</ci></apply></apply><apply id="A5.Ex4.m1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2"><times id="A5.Ex4.m1.1.1.1.1.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.3"></times><apply id="A5.Ex4.m1.1.1.1.1.2.4.cmml" xref="A5.Ex4.m1.1.1.1.1.2.4"><divide id="A5.Ex4.m1.1.1.1.1.2.4.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.4"></divide><cn type="integer" id="A5.Ex4.m1.1.1.1.1.2.4.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.4.2">1</cn><ci id="A5.Ex4.m1.1.1.1.1.2.4.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.4.3">ğ‘€</ci></apply><apply id="A5.Ex4.m1.1.1.1.1.2.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2"><apply id="A5.Ex4.m1.1.1.1.1.2.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.2.2.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3">subscript</csymbol><sum id="A5.Ex4.m1.1.1.1.1.2.2.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.2"></sum><apply id="A5.Ex4.m1.1.1.1.1.2.2.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3"><in id="A5.Ex4.m1.1.1.1.1.2.2.3.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.1"></in><apply id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.2">ğ‘¥</ci><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.2.3">ğ‘–</ci></apply><apply id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.2">ğ’Ÿ</ci><apply id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3"><times id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.1"></times><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.2">ğ‘›</ci><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.3">ğ‘’</ci><ci id="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.4.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.3.3.3.3.4">ğ‘¤</ci></apply></apply></apply></apply><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2"><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><min id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2"></min><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3"><in id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.1"></in><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.3">ğ‘—</ci></apply><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2">ğ’Ÿ</ci><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3"><times id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.1"></times><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.2">ğ‘</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.3">ğ‘</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.4.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.4">ğ‘ </ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.5.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.5">ğ‘’</ci></apply></apply></apply></apply><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1"><csymbol cd="latexml" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.2.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.2">norm</csymbol><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1"><minus id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.3"></minus><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1"><times id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.2"></times><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.3">ğŸ</ci><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.2">ğ±</ci><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.1.1.1.3">ğ¢</ci></apply></apply><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2"><times id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.2"></times><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.3">ğŸ</ci><apply id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.2">ğ±</ci><ci id="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.1.1.1.3">ğ£</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex4.m1.1c">d_{gain}=\frac{1}{M}\sum_{x_{i}\in\mathcal{D}_{new}}\min_{x_{j}\in\mathcal{D}_{base}}(\|\mathbf{f(x_{i})}-\mathbf{f(x_{j})}\|),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A5.SS2.p1.7" class="ltx_p">where <math id="A5.SS2.p1.7.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="A5.SS2.p1.7.m1.1a"><mi id="A5.SS2.p1.7.m1.1.1" xref="A5.SS2.p1.7.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.7.m1.1b"><ci id="A5.SS2.p1.7.m1.1.1.cmml" xref="A5.SS2.p1.7.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.7.m1.1c">f</annotation></semantics></math> is the feature extractor, and we use OpenAI Embedding API text-embedding-ada-002 to extract feature.</p>
</div>
</section>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Fine-tuning on Llama</h2>

<div id="A6.p1" class="ltx_para">
<p id="A6.p1.1" class="ltx_p">We use Lora&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[Hu et&nbsp;al., <a href="#bib.bib28" title="" class="ltx_ref">2021</a>]</cite> to fine-tune Llama-70b-Chat. The setting for Lora are list below:</p>
<ul id="A6.I1" class="ltx_itemize">
<li id="A6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I1.i1.p1" class="ltx_para">
<p id="A6.I1.i1.p1.1" class="ltx_p">lora_alpha: 16</p>
</div>
</li>
<li id="A6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I1.i2.p1" class="ltx_para">
<p id="A6.I1.i2.p1.1" class="ltx_p">lora_dropout: 0.1</p>
</div>
</li>
<li id="A6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I1.i3.p1" class="ltx_para">
<p id="A6.I1.i3.p1.1" class="ltx_p">r: 64</p>
</div>
</li>
<li id="A6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I1.i4.p1" class="ltx_para">
<p id="A6.I1.i4.p1.1" class="ltx_p">bias: none</p>
</div>
</li>
<li id="A6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I1.i5.p1" class="ltx_para">
<p id="A6.I1.i5.p1.1" class="ltx_p">task_type: CAUSAL_LM</p>
</div>
</li>
</ul>
</div>
<div id="A6.p2" class="ltx_para">
<p id="A6.p2.1" class="ltx_p">The detailed setting for training are list below:</p>
<ul id="A6.I2" class="ltx_itemize">
<li id="A6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i1.p1" class="ltx_para">
<p id="A6.I2.i1.p1.1" class="ltx_p">num_train_epochs: 6</p>
</div>
</li>
<li id="A6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i2.p1" class="ltx_para">
<p id="A6.I2.i2.p1.1" class="ltx_p">er_device_train_batch_size: 4</p>
</div>
</li>
<li id="A6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i3.p1" class="ltx_para">
<p id="A6.I2.i3.p1.1" class="ltx_p">gradient_accumulation_steps: 1</p>
</div>
</li>
<li id="A6.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i4.p1" class="ltx_para">
<p id="A6.I2.i4.p1.1" class="ltx_p">optim: paged_adamw_32bit</p>
</div>
</li>
<li id="A6.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i5.p1" class="ltx_para">
<p id="A6.I2.i5.p1.1" class="ltx_p">learning_rate: 2e-4</p>
</div>
</li>
<li id="A6.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i6.p1" class="ltx_para">
<p id="A6.I2.i6.p1.1" class="ltx_p">weight_decay: 0.001</p>
</div>
</li>
<li id="A6.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i7.p1" class="ltx_para">
<p id="A6.I2.i7.p1.1" class="ltx_p">fp16: False</p>
</div>
</li>
<li id="A6.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i8.p1" class="ltx_para">
<p id="A6.I2.i8.p1.1" class="ltx_p">bf16: False</p>
</div>
</li>
<li id="A6.I2.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i9.p1" class="ltx_para">
<p id="A6.I2.i9.p1.1" class="ltx_p">max_grad_norm: 0.3</p>
</div>
</li>
<li id="A6.I2.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i10.p1" class="ltx_para">
<p id="A6.I2.i10.p1.1" class="ltx_p">max_steps: -1</p>
</div>
</li>
<li id="A6.I2.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i11.p1" class="ltx_para">
<p id="A6.I2.i11.p1.1" class="ltx_p">warmup_ratio: 0.03</p>
</div>
</li>
<li id="A6.I2.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i12.p1" class="ltx_para">
<p id="A6.I2.i12.p1.1" class="ltx_p">group_by_length: True</p>
</div>
</li>
<li id="A6.I2.i13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i13.p1" class="ltx_para">
<p id="A6.I2.i13.p1.1" class="ltx_p">lr_scheduler_type: constant</p>
</div>
</li>
<li id="A6.I2.i14" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A6.I2.i14.p1" class="ltx_para">
<p id="A6.I2.i14.p1.1" class="ltx_p">report_to: tensorboard</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Details on human study</h2>

<section id="A7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Participant Information</h3>

<figure id="A7.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Information on participants in human study</figcaption>
<table id="A7.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A7.T4.1.1" class="ltx_tr">
<td id="A7.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Gender</td>
<td id="A7.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Male</td>
<td id="A7.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">25</td>
<td id="A7.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Female</td>
<td id="A7.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">25</td>
</tr>
<tr id="A7.T4.1.2" class="ltx_tr">
<td id="A7.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Education</td>
<td id="A7.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Bachelor</td>
<td id="A7.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26</td>
<td id="A7.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Master</td>
<td id="A7.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">24</td>
</tr>
<tr id="A7.T4.1.3" class="ltx_tr">
<td id="A7.T4.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Age</td>
<td id="A7.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_t">22</td>
<td id="A7.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_t">11</td>
<td id="A7.T4.1.3.4" class="ltx_td ltx_border_t"></td>
<td id="A7.T4.1.3.5" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A7.T4.1.4" class="ltx_tr">
<td id="A7.T4.1.4.1" class="ltx_td ltx_border_r"></td>
<td id="A7.T4.1.4.2" class="ltx_td ltx_align_center">23</td>
<td id="A7.T4.1.4.3" class="ltx_td ltx_align_center">15</td>
<td id="A7.T4.1.4.4" class="ltx_td"></td>
<td id="A7.T4.1.4.5" class="ltx_td"></td>
</tr>
<tr id="A7.T4.1.5" class="ltx_tr">
<td id="A7.T4.1.5.1" class="ltx_td ltx_border_r"></td>
<td id="A7.T4.1.5.2" class="ltx_td ltx_align_center">24</td>
<td id="A7.T4.1.5.3" class="ltx_td ltx_align_center">13</td>
<td id="A7.T4.1.5.4" class="ltx_td"></td>
<td id="A7.T4.1.5.5" class="ltx_td"></td>
</tr>
<tr id="A7.T4.1.6" class="ltx_tr">
<td id="A7.T4.1.6.1" class="ltx_td ltx_border_r"></td>
<td id="A7.T4.1.6.2" class="ltx_td ltx_align_center">25</td>
<td id="A7.T4.1.6.3" class="ltx_td ltx_align_center">9</td>
<td id="A7.T4.1.6.4" class="ltx_td"></td>
<td id="A7.T4.1.6.5" class="ltx_td"></td>
</tr>
<tr id="A7.T4.1.7" class="ltx_tr">
<td id="A7.T4.1.7.1" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="A7.T4.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">26</td>
<td id="A7.T4.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">2</td>
<td id="A7.T4.1.7.4" class="ltx_td ltx_border_bb"></td>
<td id="A7.T4.1.7.5" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody></table>
</figure>
<div id="A7.SS1.p1" class="ltx_para">
<p id="A7.SS1.p1.1" class="ltx_p">Information on participant in human study are shown in <a href="#A7.T4" title="In G.1 Participant Information â€£ Appendix G Details on human study â€£ CultureLLM: Incorporating Cultural Differences into Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section id="A7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Training Procedure</h3>

<div id="A7.SS2.p1" class="ltx_para">
<p id="A7.SS2.p1.1" class="ltx_p">Participants are asked to rate the <math id="A7.SS2.p1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="A7.SS2.p1.1.m1.1a"><mn id="A7.SS2.p1.1.m1.1.1" xref="A7.SS2.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.p1.1.m1.1b"><cn type="integer" id="A7.SS2.p1.1.m1.1.1.cmml" xref="A7.SS2.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p1.1.m1.1c">100</annotation></semantics></math> samples according to the following criterion:</p>
<ol id="A7.I1" class="ltx_enumerate">
<li id="A7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A7.I1.i1.p1" class="ltx_para">
<p id="A7.I1.i1.p1.1" class="ltx_p"><span id="A7.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Score 1: </span> i. The sentences convey distinctly different ideas or concepts. ii. No apparent connection or shared meaning.</p>
</div>
</li>
<li id="A7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A7.I1.i2.p1" class="ltx_para">
<p id="A7.I1.i2.p1.1" class="ltx_p"><span id="A7.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Score 2: </span> i. Limited commonality in meaning, with noticeable disparities in wording.
ii. Shared concepts but with significant differences in expression.</p>
</div>
</li>
<li id="A7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A7.I1.i3.p1" class="ltx_para">
<p id="A7.I1.i3.p1.1" class="ltx_p"><span id="A7.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Score 3: </span> i. Some overlap in meaning, but notable differences in wording or phrasing.
ii. Context or emphasis might differ slightly.</p>
</div>
</li>
<li id="A7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A7.I1.i4.p1" class="ltx_para">
<p id="A7.I1.i4.p1.1" class="ltx_p"><span id="A7.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Score 4: </span> i. Minor variations in wording or structure, but the core meaning remains consistent.
ii. Synonymous expressions and interchangeable terms are present.</p>
</div>
</li>
<li id="A7.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="A7.I1.i5.p1" class="ltx_para">
<p id="A7.I1.i5.p1.1" class="ltx_p"><span id="A7.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Score 5: </span> i. The sentences convey the same information using different words.
ii. No discernible difference in meaning or context.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2402.10945" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="[2402.10946]%20CultureLLM_%20Incorporating%20Cultural%20Differences%20into%20Large%20Language%20Models_files/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2402.10946" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2402.10946">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.10946" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2402.10947" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 17:57:12 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>